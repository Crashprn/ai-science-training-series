{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J1tOS7oWba4s"
   },
   "source": [
    "# Large language models (LLMs): Part II\n",
    "\n",
    "Author: Archit Vasan , including materials on LLMs by Varuni Sastri, and discussion/editorial work by Taylor Childers, Carlo Graziani, Bethany Lusch, and Venkat Vishwanath (Argonne)\n",
    "\n",
    "Inspiration from the blog posts \"The Illustrated Transformer\" and \"The Illustrated GPT2\" by Jay Alammar, highly recommended reading.\n",
    "\n",
    "Before you begin, make sure that you have your environment set up and your repo refreshed, as described in previous lessons, and reviewed in the accompanying 'Readme.md' file. Make sure that you select the kernel 'datascience/conda-2023-01-10' at the top-left of the Jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "1. Training and inference using Hugging Face\n",
    "2. Elements of an LLM\n",
    "3. Attention mechanisms\n",
    "4. Positional encoding\n",
    "5. Output layers\n",
    "6. Training loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HTTP_PROXY\"]=\"http://proxy-01.pub.alcf.anl.gov:3128\"\n",
    "os.environ[\"HTTPS_PROXY\"]=\"http://proxy-01.pub.alcf.anl.gov:3128\"\n",
    "os.environ[\"http_proxy\"]=\"http://proxy-01.pub.alcf.anl.gov:3128\"\n",
    "os.environ[\"https_proxy\"]=\"http://proxy-01.pub.alcf.anl.gov:3128\"\n",
    "os.environ[\"ftp_proxy\"]=\"http://proxy-01.pub.alcf.anl.gov:3128\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM training and inference using HuggingFace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/hf-logo-with-title.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "HuggingFace is a platform and community that provides open-source library tools and resources like pre-trained models and datasets.\n",
    "Refer to the following links for more information :\n",
    "\n",
    "https://huggingface.co/docs/hub/index\n",
    "\n",
    "https://huggingface.co/docs/transformers/en/index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Warning: _Large Language Models are only as good as their training data. They have no ethics, no judgement, or editing ability. We will be using some pretrained models from Hugging Face which used wide samples of internet hosted text. The datasets have not been strictly filtered to restrict all malign content so the generated text may be surprisingly dark or questionable. They do not reflect our core values and are only used for demonstration purposes._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference\n",
    "\n",
    "We can use the Huggingface pipeline with a pretrained GPT2 model to generate text given a prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/cgrogan/.cache/huggingface/hub/models--openai-community--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"openai-community/gpt2\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.26.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/cgrogan/.cache/huggingface/hub/models--openai-community--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"openai-community/gpt2\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.26.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at /home/cgrogan/.cache/huggingface/hub/models--openai-community--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/model.safetensors\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at openai-community/gpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
      "loading configuration file generation_config.json from cache at /home/cgrogan/.cache/huggingface/hub/models--openai-community--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/cgrogan/.cache/huggingface/hub/models--openai-community--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"openai-community/gpt2\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.26.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "loading file vocab.json from cache at /home/cgrogan/.cache/huggingface/hub/models--openai-community--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/vocab.json\n",
      "loading file merges.txt from cache at /home/cgrogan/.cache/huggingface/hub/models--openai-community--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/merges.txt\n",
      "loading file tokenizer.json from cache at /home/cgrogan/.cache/huggingface/hub/models--openai-community--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /home/cgrogan/.cache/huggingface/hub/models--openai-community--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /home/cgrogan/.cache/huggingface/hub/models--openai-community--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"openai-community/gpt2\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.26.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"do_sample\": true,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"max_length\": 50,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "/soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages/transformers/generation/utils.py:1186: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"My dog really wanted to live longer than it did, so she wasn't going to have to deal\"},\n",
       " {'generated_text': \"My dog really wanted to learn how to use his pups' paws to move across a long metal\"},\n",
       " {'generated_text': 'My dog really wanted to touch that little girl. I think she\\'s really cute,\" he says.'},\n",
       " {'generated_text': 'My dog really wanted to be around me. She loved me, I thought, and I gave.'},\n",
       " {'generated_text': 'My dog really wanted to help me because I have some trouble with arthritis and was scared to go over'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer,AutoModelForCausalLM, AutoConfig\n",
    "input_text = \"My dog really wanted to\"\n",
    "from transformers import pipeline\n",
    "generator = pipeline(\"text-generation\", model=\"openai-community/gpt2\")\n",
    "generator(input_text, max_length=20, num_return_sequences=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will cover  evaluation metrics,as well as safe and responsibilities practices when using LLMs in **Session 8**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also load in our own dataset and train a model with this data as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: accelerate in /home/cgrogan/.local/lib/python3.10/site-packages (0.28.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from accelerate) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from accelerate) (21.3)\n",
      "Requirement already satisfied: psutil in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from accelerate) (5.9.4)\n",
      "Requirement already satisfied: pyyaml in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from accelerate) (6.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from accelerate) (1.13.0a0+git49444c3)\n",
      "Requirement already satisfied: huggingface-hub in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from accelerate) (0.12.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/cgrogan/.local/lib/python3.10/site-packages (from accelerate) (0.4.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.0.9)\n",
      "Requirement already satisfied: typing-extensions in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.4.0)\n",
      "Requirement already satisfied: filelock in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from huggingface-hub->accelerate) (3.9.0)\n",
      "Requirement already satisfied: requests in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.28.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.64.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2022.12.7)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextDataset,DataCollatorForLanguageModeling\n",
    "\n",
    "def load_dataset(train_path,test_path,tokenizer):\n",
    "    train_dataset = TextDataset(\n",
    "          tokenizer=tokenizer,\n",
    "          file_path=train_path,\n",
    "          block_size=128) \n",
    "    test_dataset = TextDataset(\n",
    "          tokenizer=tokenizer,\n",
    "          file_path=test_path,\n",
    "          block_size=128)   \n",
    "    data_collator = DataCollatorForLanguageModeling(\n",
    "        tokenizer=tokenizer, mlm=False,\n",
    "    )\n",
    "    return train_dataset,test_dataset,data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/cgrogan/.cache/huggingface/hub/models--openai-community--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"openai-community/gpt2\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.26.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "loading file vocab.json from cache at /home/cgrogan/.cache/huggingface/hub/models--openai-community--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/vocab.json\n",
      "loading file merges.txt from cache at /home/cgrogan/.cache/huggingface/hub/models--openai-community--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/merges.txt\n",
      "loading file tokenizer.json from cache at /home/cgrogan/.cache/huggingface/hub/models--openai-community--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /home/cgrogan/.cache/huggingface/hub/models--openai-community--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /home/cgrogan/.cache/huggingface/hub/models--openai-community--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"openai-community/gpt2\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.26.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/cgrogan/.cache/huggingface/hub/models--openai-community--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"openai-community/gpt2\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.26.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at /home/cgrogan/.cache/huggingface/hub/models--openai-community--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/model.safetensors\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at openai-community/gpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
      "loading configuration file generation_config.json from cache at /home/cgrogan/.cache/huggingface/hub/models--openai-community--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "/soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages/transformers/data/datasets/language_modeling.py:54: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ü§ó Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
      "  warnings.warn(\n",
      "Loading features from cached file dataset/cached_lm_GPT2TokenizerFast_128_train_input.txt [took 0.006 s]\n",
      "Loading features from cached file dataset/cached_lm_GPT2TokenizerFast_128_test_input.txt [took 0.002 s]\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer,AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"openai-community/gpt2\")\n",
    "\n",
    "train_dataset,test_dataset,data_collator = load_dataset('dataset/train_input.txt','dataset/test_input.txt', tokenizer)\n",
    "\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./gpt2\", #The output directory\n",
    "    overwrite_output_dir=True, #overwrite the content of the output directory\n",
    "    num_train_epochs=3, # number of training epochs\n",
    "    per_device_train_batch_size=32, # batch size for training\n",
    "    per_device_eval_batch_size=64,  # batch size for evaluation\n",
    "    eval_steps = 40, # Number of update steps between two evaluations.\n",
    "    save_steps=80, # after # steps model is saved \n",
    "    warmup_steps=50,# number of warmup steps for learning rate scheduler\n",
    "    prediction_loss_only=True,\n",
    "    )\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is going on below the hood?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two components that are \"black-boxes\" here:\n",
    "1. The method for tokenization\n",
    "2. The model that generates novel text.\n",
    "\n",
    "Carlo Graziani already gave a great explanation of tokenization last week and how this affects embeddings (https://github.com/argonne-lcf/ai-science-training-series/blob/main/04_intro_to_llms/Sequential_Data_Models.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today we will take a closer look at how the model is designed to deal with language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look inside GPT2! GPT2 incorporates the `GPT2LMHeadModel` architecture so let's inspect this more closely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/cgrogan/.cache/huggingface/hub/models--openai-community--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/config.json\n",
      "Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.26.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at /home/cgrogan/.cache/huggingface/hub/models--openai-community--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/model.safetensors\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at openai-community/gpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
      "loading configuration file generation_config.json from cache at /home/cgrogan/.cache/huggingface/hub/models--openai-community--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2LMHeadModel(\n",
      "  (transformer): GPT2Model(\n",
      "    (wte): Embedding(50257, 768)\n",
      "    (wpe): Embedding(1024, 768)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (2): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (3): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (4): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (5): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (6): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (7): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (8): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (9): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (10): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (11): GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "model = GPT2LMHeadModel.from_pretrained('openai-community/gpt2')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General elements of an LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT-2 is an example of the popular Transformer architecture. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cig2mvfguetQ"
   },
   "source": [
    "<img src=\"images/decoder_only_block.png\" alt=\"Drawing\" style=\"width: 200px;\"/>\n",
    "Image credit: https://arxiv.org/pdf/1706.03762.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gray section in this figure is the Transfomer Decoder and it is the main mechanism GPT2 uses to encode context of language into its predictions.\n",
    "\n",
    "<img src=\"images/transformer-decoder-intro.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "Image credit: https://jalammar.github.io/illustrated-gpt2/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Transformer-Decoder is composed of Decoder blocks stacked ontop of each other where each contains two types of layers: \n",
    "1. Masked Self-Attention and \n",
    "2. Feed Forward Neural Networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have already discussed Feed Forward Neural Networks in detail in the other lectures in this series. To review this, please look at https://github.com/argonne-lcf/ai-science-training-series/blob/main/02_intro_neural_networks/01_introduction_mnist.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lecture, we will \n",
    "* First, discuss attention mechanisms at length as this is arguably the greatest contribution by Transformers.\n",
    "* Second, extend the discussion from last week (https://github.com/argonne-lcf/ai-science-training-series/blob/main/04_intro_to_llms/Sequential_Data_Models.ipynb) on embedding input data while taking into account position.\n",
    "* Third, discuss outputting real text/sequences from the models.\n",
    "* Fourth, build a training loop for a mini-LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's set up all the imports we will need**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device is: cuda\n"
     ]
    }
   ],
   "source": [
    "## IMPORTS\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)\n",
    "# hyperparameters\n",
    "batch_size = 16 # how many independent sequences will we process in parallel?\n",
    "block_size = 32 # what is the maximum context length for predictions?\n",
    "max_iters = 5000\n",
    "eval_interval = 100\n",
    "learning_rate = 1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embd = 64\n",
    "n_head = 4 ## so head_size = 16\n",
    "n_layer = 4\n",
    "dropout = 0.0\n",
    "# ------------\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "print(f\"Device is: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BowLYFlCrDrr"
   },
   "source": [
    "## Attention mechanisms\n",
    "\n",
    "Suppose the following sentence is an input sentence we want to translate using an LLM:\n",
    "\n",
    "`‚ÄùThe animal didn't cross the street because it was too tired‚Äù`\n",
    "\n",
    "Last week, Carlo mentioned that the Transformer learns an embedding of all words allowing interpretation of meanings of words.\n",
    "\n",
    "<img src=\"images/viz-bert-voc-verbs.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "So, if the model did a good job in token embedding, it will \"know\" what all the words in this sentence mean. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But to understand a full sentence, the model also need to understand what each word means in relation to other words.\n",
    "\n",
    "For example, when we read the sentence:\n",
    "`‚ÄùThe animal didn't cross the street because it was too tired‚Äù`\n",
    "we know intuitively that the word `\"it\"` refers to `\"animal\"`, the state for `\"it\"` is `\"tired\"`, and the associated action is `\"didn't cross\"`.\n",
    "\n",
    "However, the model needs a way to learn all of this information in a simple yet generalizable way.\n",
    "What makes Transformers particularly powerful compared to earlier sequential architectures is how it encodes context with the **self-attention mechanism**.\n",
    "\n",
    "As the model processes each word in the input sequence, attention looks at other positions in the input sequence for clues to a better understanding for this word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/transformer_self-attention_visualization.png\" alt=\"Drawing\" style=\"width: 300px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UGbAi0cJ7x3a"
   },
   "source": [
    "Image credit: https://jalammar.github.io/illustrated-transformer/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Self-attention mechanisms use 3 vectors to encode the context of a word in a sequence with another word:\n",
    "1. Query: the word representation we score other words against using the other word's keys\n",
    "2. Key: labels for the words in a sequence that we match against the query\n",
    "3. Value: actual word representation. We will use the queries and keys to score the word's relevance to the query, and multiply this by the value. \n",
    "\n",
    "An analogy provided by Jay Alammar is thinking about attention as choosing a file from a file cabinet according to information on a post-it note. You can use the post-it note (query) to identify the folder (key) that most matches the topic you are looking up. Then you access the contents of the file (value) according to its relevance to your query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/self-attention-example-folders-3.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "Image credit: https://jalammar.github.io/illustrated-gpt2/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our models, we can encode queries, keys, and values using simple linear layers with the same size (`sequence length, head_size`). During the training process, these layers will be updated to best encode context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 32 # channels\n",
    "head_size = 16\n",
    "\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jzf9VE_AqWeR"
   },
   "source": [
    "The algorithm for self-attention is as follows:\n",
    "\n",
    "1. Generate query, key and value vectors for each word\n",
    "2. Calculate a score for each word in the input sentence against each other.\n",
    "3. Divide the scores by the square root of the dimension of the key vectors to stabilize the gradients. This is then passed through a softmax operation.\n",
    "4. Multiply each value vector by the softmax score.\n",
    "5. Sum up the weighted value vectors to produce the output.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/self-attention-output.png\" alt=\"Drawing\" style=\"width: 450px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yOwm-NkXA8U3"
   },
   "source": [
    "Image credit: https://jalammar.github.io/illustrated-transformer/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how attention is performed in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,32 # batch, time, channels\n",
    "x = torch.randn(B,T,C)\n",
    "\n",
    "# Here we want the wei to be data dependent - ie gather info from the past but in a data dependant way\n",
    "\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "k = key(x)   # (B, T, 16) # each token here (totally B*T) produce a key and query in parallel and independently\n",
    "q = query(x) # (B, T, 16)\n",
    "v = value(x)\n",
    "\n",
    "wei =  q @ k.transpose(-2, -1) * head_size**-0.5 # (B, T, 16) @ (B, 16, T) ---> (B, T, T). #\n",
    "wei = F.softmax(wei, dim=-1) # exponentiate and normalize giving a nice distibution that sums to 1 and\n",
    "                             # now it tells us that in a data dependent manner how much of info to aggregate from\n",
    "\n",
    "out = wei @ v # aggregate the attention scores and value vector.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0618, -0.0091, -0.3488,  0.3208,  0.2971, -0.1573, -0.0561,  0.1068,\n",
      "          0.0368,  0.0139, -0.0017,  0.3110,  0.1404, -0.0158,  0.1853,  0.4290],\n",
      "        [ 0.1578, -0.0971, -0.4256,  0.3538,  0.3621, -0.2392, -0.0536,  0.1759,\n",
      "          0.1115,  0.0282, -0.0649,  0.3641,  0.1928,  0.0261,  0.2162,  0.3758],\n",
      "        [ 0.1293,  0.0759, -0.2946,  0.2292,  0.2215, -0.0710, -0.0107,  0.1616,\n",
      "         -0.0930, -0.0877,  0.0567,  0.1899,  0.0311, -0.0894,  0.0309,  0.5471],\n",
      "        [ 0.1247,  0.1400, -0.2436,  0.1819,  0.1976,  0.0338, -0.0028,  0.1124,\n",
      "         -0.1477, -0.0748,  0.0650,  0.1392, -0.0314, -0.0989,  0.0613,  0.5433],\n",
      "        [ 0.0667,  0.1845, -0.2135,  0.2813,  0.2064,  0.0873,  0.0084,  0.2055,\n",
      "         -0.1130, -0.1466,  0.0459,  0.1923, -0.0275, -0.1107,  0.0065,  0.4674],\n",
      "        [ 0.1924,  0.1693, -0.1568,  0.2284,  0.1620,  0.0737,  0.0443,  0.2519,\n",
      "         -0.1912, -0.1979,  0.0832,  0.0713, -0.0826, -0.0848, -0.1047,  0.6089],\n",
      "        [ 0.1184,  0.0884, -0.2652,  0.2560,  0.1840,  0.0284, -0.0621,  0.1181,\n",
      "         -0.0880,  0.0104,  0.1123,  0.1850,  0.0369, -0.0730,  0.0663,  0.5242],\n",
      "        [ 0.1243,  0.0453, -0.3412,  0.2709,  0.2335, -0.0948, -0.0421,  0.2143,\n",
      "         -0.0330, -0.0313,  0.0520,  0.2378,  0.1084, -0.0959,  0.0300,  0.4707]],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(out[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4lwyFlxKW6oA"
   },
   "source": [
    "### Multi-head attention\n",
    "\n",
    "In practice, multiple attention heads are used which\n",
    "1. Expands the model‚Äôs ability to focus on different positions and prevent the attention to be dominated by the word itself.\n",
    "2. Have multiple ‚Äúrepresentation subspaces‚Äù. Have multiple sets of Query/Key/Value weight matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/transformer_multi-headed_self-attention-recap.png\" alt=\"Drawing\" style=\"width: 700px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6oHsezdVBIaf"
   },
   "source": [
    "Image credit: https://jalammar.github.io/illustrated-transformer/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's see attention mechanisms in action!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use the powerful visualization tool bertviz, which allows an interactive experience of the attention mechanisms. Normally these mechanisms are abstracted away but this will allow us to inspect our model in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: bertviz in /home/cgrogan/.local/lib/python3.10/site-packages (1.4.0)\n",
      "Requirement already satisfied: transformers>=2.0 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from bertviz) (4.26.0)\n",
      "Requirement already satisfied: torch>=1.0 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from bertviz) (1.13.0a0+git49444c3)\n",
      "Requirement already satisfied: tqdm in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from bertviz) (4.64.1)\n",
      "Requirement already satisfied: boto3 in /home/cgrogan/.local/lib/python3.10/site-packages (from bertviz) (1.34.66)\n",
      "Requirement already satisfied: requests in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from bertviz) (2.28.1)\n",
      "Requirement already satisfied: regex in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from bertviz) (2022.10.31)\n",
      "Requirement already satisfied: sentencepiece in /home/cgrogan/.local/lib/python3.10/site-packages (from bertviz) (0.2.0)\n",
      "Requirement already satisfied: typing-extensions in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from torch>=1.0->bertviz) (4.4.0)\n",
      "Requirement already satisfied: filelock in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from transformers>=2.0->bertviz) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from transformers>=2.0->bertviz) (0.12.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from transformers>=2.0->bertviz) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from transformers>=2.0->bertviz) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from transformers>=2.0->bertviz) (6.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from transformers>=2.0->bertviz) (0.13.2)\n",
      "Requirement already satisfied: botocore<1.35.0,>=1.34.66 in /home/cgrogan/.local/lib/python3.10/site-packages (from boto3->bertviz) (1.34.66)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/cgrogan/.local/lib/python3.10/site-packages (from boto3->bertviz) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /home/cgrogan/.local/lib/python3.10/site-packages (from boto3->bertviz) (0.10.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from requests->bertviz) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from requests->bertviz) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from requests->bertviz) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from requests->bertviz) (2022.12.7)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from botocore<1.35.0,>=1.34.66->boto3->bertviz) (2.8.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from packaging>=20.0->transformers>=2.0->bertviz) (3.0.9)\n",
      "Requirement already satisfied: six>=1.5 in /soft/datascience/conda/2023-01-10/mconda3/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.66->boto3->bertviz) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install bertviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load in the model, GPT2 and look at the attention mechanisms. \n",
    "\n",
    "**Hint... click on the different blocks in the visualization to see the attention**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\"></script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "      \n",
       "        <div id=\"bertviz-300f38de2d1b4e66a8cc391d887f8db3\" style=\"font-family:'Helvetica Neue', Helvetica, Arial, sans-serif;\">\n",
       "            <span style=\"user-select:none\">\n",
       "                \n",
       "            </span>\n",
       "            <div id='vis'></div>\n",
       "        </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "/**\n",
       " * @fileoverview Transformer Visualization D3 javascript code.\n",
       " *\n",
       " * Based on: https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/visualization/attention.js\n",
       " *\n",
       " * Change log:\n",
       " *\n",
       " * 02/01/19  Jesse Vig   Initial implementation\n",
       " * 12/31/20  Jesse Vig   Support multiple visualizations in single notebook.\n",
       " * 01/19/21  Jesse Vig   Support light/dark modes\n",
       " * 02/06/21  Jesse Vig   Move require config from separate jupyter notebook step\n",
       " * 05/03/21  Jesse Vig   Adjust visualization height dynamically\n",
       " * 03/23/22  Daniel SC   Update requirement URLs for d3 and jQuery (source of bug not allowing end result to be displayed on browsers)\n",
       " **/\n",
       "\n",
       "require.config({\n",
       "  paths: {\n",
       "      d3: 'https://cdnjs.cloudflare.com/ajax/libs/d3/5.7.0/d3.min',\n",
       "    jquery: 'https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.0/jquery.min',\n",
       "  }\n",
       "});\n",
       "\n",
       "requirejs(['jquery', 'd3'], function($, d3) {\n",
       "\n",
       "        const params = {\"attention\": [{\"name\": null, \"attn\": [[[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.961219847202301, 0.038780149072408676, 0.0, 0.0, 0.0, 0.0], [0.7466979026794434, 0.11987314373254776, 0.1334289014339447, 0.0, 0.0, 0.0], [0.5885030031204224, 0.13792067766189575, 0.212137371301651, 0.06143897399306297, 0.0, 0.0], [0.6570857763290405, 0.08996301889419556, 0.12751281261444092, 0.08361563086509705, 0.041822850704193115, 0.0], [0.2728874385356903, 0.11203353852033615, 0.1663985401391983, 0.08467111736536026, 0.16952736675739288, 0.19448210299015045]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.010616563260555267, 0.9893833994865417, 0.0, 0.0, 0.0, 0.0], [0.0024677535984665155, 0.008448007516562939, 0.9890841841697693, 0.0, 0.0, 0.0], [0.0001232847134815529, 0.0018733182223513722, 0.013126976788043976, 0.9848763942718506, 0.0, 0.0], [0.0010669564362615347, 0.001136627048254013, 0.003034998197108507, 0.0015735096530988812, 0.9931879043579102, 0.0], [0.00019791982776951045, 0.0010528112761676311, 0.0015437351539731026, 0.0009642760851420462, 3.4924432839034125e-05, 0.9962062835693359]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.47578439116477966, 0.524215579032898, 0.0, 0.0, 0.0, 0.0], [0.5906045436859131, 0.2486611008644104, 0.16073434054851532, 0.0, 0.0, 0.0], [0.5529289841651917, 0.18856702744960785, 0.14457571506500244, 0.11392831057310104, 0.0, 0.0], [0.45094072818756104, 0.16486799716949463, 0.17318038642406464, 0.11748014390468597, 0.09353074431419373, 0.0], [0.4257245659828186, 0.1732865273952484, 0.15651953220367432, 0.07022649794816971, 0.0808701142668724, 0.09337282180786133]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6133623123168945, 0.38663768768310547, 0.0, 0.0, 0.0, 0.0], [0.06098509579896927, 0.03253461793065071, 0.9064802527427673, 0.0, 0.0, 0.0], [0.006717085838317871, 0.0004012881254311651, 0.7572958469390869, 0.23558568954467773, 0.0, 0.0], [0.03722766041755676, 0.002948855282738805, 0.10081092268228531, 0.04142269119620323, 0.8175898790359497, 0.0], [0.04989781975746155, 0.00030758307548239827, 0.0024198265746235847, 0.0034334994852542877, 0.0006823898293077946, 0.9432588815689087]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9489555954933167, 0.051044441759586334, 0.0, 0.0, 0.0, 0.0], [0.6821408867835999, 0.1395241767168045, 0.17833495140075684, 0.0, 0.0, 0.0], [0.20366324484348297, 0.05641487240791321, 0.06399301439523697, 0.6759288311004639, 0.0, 0.0], [0.3419547975063324, 0.06725440919399261, 0.07926183938980103, 0.1783619523048401, 0.3331669867038727, 0.0], [0.09464015811681747, 0.0074282134883105755, 0.006983973551541567, 0.0071843694895505905, 0.018724264577031136, 0.865039050579071]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.33834606409072876, 0.6616539359092712, 0.0, 0.0, 0.0, 0.0], [0.07855993509292603, 0.006165449041873217, 0.9152746200561523, 0.0, 0.0, 0.0], [0.01677597686648369, 0.0004037705948576331, 0.003340460592880845, 0.9794798493385315, 0.0, 0.0], [0.027600426226854324, 0.00044415233423933387, 0.0006541680195368826, 0.0002266185765620321, 0.971074640750885, 0.0], [0.010248198173940182, 3.701553578139283e-05, 0.00016064041119534522, 2.7341819077264518e-05, 1.0187304724240676e-05, 0.98951655626297]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.982503354549408, 0.017496665939688683, 0.0, 0.0, 0.0, 0.0], [0.8874197006225586, 0.05467939004302025, 0.05790085718035698, 0.0, 0.0, 0.0], [0.6849910616874695, 0.1228068619966507, 0.04972026124596596, 0.14248186349868774, 0.0, 0.0], [0.6015856862068176, 0.09881888329982758, 0.07070108503103256, 0.16652540862560272, 0.06236903741955757, 0.0], [0.3232504427433014, 0.12567411363124847, 0.04432179778814316, 0.07076980918645859, 0.06606649607419968, 0.36991727352142334]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9191647171974182, 0.0808352455496788, 0.0, 0.0, 0.0, 0.0], [0.45986413955688477, 0.39703112840652466, 0.14310479164123535, 0.0, 0.0, 0.0], [0.3003872334957123, 0.22181738913059235, 0.38161516189575195, 0.09618020057678223, 0.0, 0.0], [0.18963925540447235, 0.1376371532678604, 0.20173484086990356, 0.23632164299488068, 0.23466713726520538, 0.0], [0.15410441160202026, 0.09489496797323227, 0.11902562528848648, 0.10277965664863586, 0.4317220449447632, 0.09747327119112015]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.364999920129776, 0.6350001096725464, 0.0, 0.0, 0.0, 0.0], [0.24595215916633606, 0.5519201755523682, 0.20212766528129578, 0.0, 0.0, 0.0], [0.2721358835697174, 0.40738627314567566, 0.25186213850975037, 0.06861574947834015, 0.0, 0.0], [0.10242555290460587, 0.16683615744113922, 0.524804949760437, 0.05445462837815285, 0.15147870779037476, 0.0], [0.25029507279396057, 0.22198128700256348, 0.18899968266487122, 0.10677118599414825, 0.1303267478942871, 0.10162602365016937]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6990506649017334, 0.3009493350982666, 0.0, 0.0, 0.0, 0.0], [0.5107942819595337, 0.2948642075061798, 0.1943415403366089, 0.0, 0.0, 0.0], [0.4604707360267639, 0.2805190980434418, 0.19174803793430328, 0.0672621801495552, 0.0, 0.0], [0.37648412585258484, 0.21120662987232208, 0.20214538276195526, 0.10207021236419678, 0.10809355974197388, 0.0], [0.30138441920280457, 0.20456179976463318, 0.18250338733196259, 0.11019382625818253, 0.1629127413034439, 0.03844383731484413]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7131582498550415, 0.2868417799472809, 0.0, 0.0, 0.0, 0.0], [0.4058799147605896, 0.18063297867774963, 0.41348710656166077, 0.0, 0.0, 0.0], [0.265546053647995, 0.1698586493730545, 0.3358593285083771, 0.228736013174057, 0.0, 0.0], [0.31385406851768494, 0.1831669807434082, 0.14928358793258667, 0.05377671495079994, 0.29991865158081055, 0.0], [0.20466560125350952, 0.18731118738651276, 0.15959151089191437, 0.06381776183843613, 0.03642302006483078, 0.34819093346595764]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6586242914199829, 0.3413757383823395, 0.0, 0.0, 0.0, 0.0], [0.5917776226997375, 0.3160035014152527, 0.0922188088297844, 0.0, 0.0, 0.0], [0.5477152466773987, 0.23586955666542053, 0.061456020921468735, 0.1549593061208725, 0.0, 0.0], [0.4587061107158661, 0.22439992427825928, 0.07887422293424606, 0.0992034301161766, 0.13881628215312958, 0.0], [0.32743722200393677, 0.19600819051265717, 0.068057119846344, 0.0892510637640953, 0.11618079245090485, 0.20306548476219177]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9961552023887634, 0.0038448425475507975, 0.0, 0.0, 0.0, 0.0], [0.8594854474067688, 0.06906110048294067, 0.07145342975854874, 0.0, 0.0, 0.0], [0.3800053000450134, 0.04127567633986473, 0.5496612787246704, 0.029057776555418968, 0.0, 0.0], [0.21445226669311523, 0.05088742449879646, 0.4317440092563629, 0.25869303941726685, 0.044223275035619736, 0.0], [0.11175256222486496, 0.017593080177903175, 0.027507441118359566, 0.04086771607398987, 0.7754669785499573, 0.026812179014086723]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9285967946052551, 0.07140326499938965, 0.0, 0.0, 0.0, 0.0], [0.6077286005020142, 0.3121427297592163, 0.08012867718935013, 0.0, 0.0, 0.0], [0.4942909777164459, 0.28503698110580444, 0.11849315464496613, 0.10217894613742828, 0.0, 0.0], [0.4183879494667053, 0.23117904365062714, 0.0834062322974205, 0.11365949362516403, 0.1533672958612442, 0.0], [0.42215850949287415, 0.12917140126228333, 0.08740927278995514, 0.1016375944018364, 0.21230268478393555, 0.04732053726911545]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9786475896835327, 0.02135237120091915, 0.0, 0.0, 0.0, 0.0], [0.7749121785163879, 0.06510371714830399, 0.15998409688472748, 0.0, 0.0, 0.0], [0.6484923362731934, 0.07483134418725967, 0.14751605689525604, 0.12916021049022675, 0.0, 0.0], [0.5224639773368835, 0.06921815127134323, 0.13823404908180237, 0.1110658198595047, 0.15901805460453033, 0.0], [0.3964517116546631, 0.07325823605060577, 0.12938153743743896, 0.1064242571592331, 0.14864002168178558, 0.1458442211151123]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5525906085968018, 0.44740936160087585, 0.0, 0.0, 0.0, 0.0], [0.5585009455680847, 0.2176259458065033, 0.22387312352657318, 0.0, 0.0, 0.0], [0.5143128633499146, 0.15964674949645996, 0.15491968393325806, 0.1711207628250122, 0.0, 0.0], [0.5039961338043213, 0.11401888728141785, 0.11974027007818222, 0.12552587687969208, 0.13671889901161194, 0.0], [0.5061842799186707, 0.08567393571138382, 0.08903021365404129, 0.09759818762540817, 0.1027572825551033, 0.11875619739294052]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9242545366287231, 0.07574543356895447, 0.0, 0.0, 0.0, 0.0], [0.8257425427436829, 0.07932533323764801, 0.09493216127157211, 0.0, 0.0, 0.0], [0.7306380271911621, 0.0857183039188385, 0.08043931424617767, 0.10320431739091873, 0.0, 0.0], [0.6383238434791565, 0.07886394113302231, 0.07815027981996536, 0.08758097141981125, 0.1170809343457222, 0.0], [0.5552157163619995, 0.07409121096134186, 0.06834889203310013, 0.07778600603342056, 0.09999319165945053, 0.12456497550010681]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8578913807868958, 0.14210854470729828, 0.0, 0.0, 0.0, 0.0], [0.6423038244247437, 0.166290283203125, 0.19140593707561493, 0.0, 0.0, 0.0], [0.5530979633331299, 0.10609274357557297, 0.07821257412433624, 0.26259663701057434, 0.0, 0.0], [0.40121692419052124, 0.12223611027002335, 0.1934729963541031, 0.14164622128009796, 0.14142780005931854, 0.0], [0.40212565660476685, 0.18450751900672913, 0.07516805827617645, 0.05849048122763634, 0.1444634348154068, 0.13524490594863892]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9791558980941772, 0.020844051614403725, 0.0, 0.0, 0.0, 0.0], [0.8829841613769531, 0.06233249977231026, 0.05468335747718811, 0.0, 0.0, 0.0], [0.8105455040931702, 0.08617085963487625, 0.07321777194738388, 0.03006584383547306, 0.0, 0.0], [0.6819812059402466, 0.04990820586681366, 0.08296552300453186, 0.08369525521993637, 0.10144983977079391, 0.0], [0.4056689441204071, 0.07337666302919388, 0.08601408451795578, 0.061709366738796234, 0.13226434588432312, 0.2409665435552597]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9670190811157227, 0.03298088163137436, 0.0, 0.0, 0.0, 0.0], [0.8449064493179321, 0.0851450264453888, 0.06994850933551788, 0.0, 0.0, 0.0], [0.7123572826385498, 0.07896047830581665, 0.055410757660865784, 0.15327158570289612, 0.0, 0.0], [0.6402613520622253, 0.0739755630493164, 0.044393062591552734, 0.14322125911712646, 0.09814881533384323, 0.0], [0.5073903799057007, 0.07523059099912643, 0.07754647731781006, 0.11362491548061371, 0.13947951793670654, 0.08672808855772018]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8487569093704224, 0.1512431502342224, 0.0, 0.0, 0.0, 0.0], [0.8415648937225342, 0.12107233703136444, 0.03736274689435959, 0.0, 0.0, 0.0], [0.7505517601966858, 0.11348944902420044, 0.06179959326982498, 0.07415912300348282, 0.0, 0.0], [0.6614719033241272, 0.10242646187543869, 0.052934251725673676, 0.07529708743095398, 0.10787025839090347, 0.0], [0.6014202237129211, 0.11340376734733582, 0.05631929263472557, 0.07096721231937408, 0.10906282067298889, 0.04882663115859032]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9445484280586243, 0.05545158311724663, 0.0, 0.0, 0.0, 0.0], [0.8874568939208984, 0.05474215745925903, 0.0578010231256485, 0.0, 0.0, 0.0], [0.8281888961791992, 0.06895001977682114, 0.059034693986177444, 0.0438263975083828, 0.0, 0.0], [0.6429892778396606, 0.0674755647778511, 0.11629703640937805, 0.05417950078845024, 0.11905858665704727, 0.0], [0.7367823719978333, 0.056119054555892944, 0.06857288628816605, 0.034219540655612946, 0.0787537544965744, 0.02555238828063011]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0002913394710049033, 0.9997085928916931, 0.0, 0.0, 0.0, 0.0], [0.0007981209782883525, 0.5288336873054504, 0.4703682065010071, 0.0, 0.0, 0.0], [0.0007648481405340135, 0.34519824385643005, 0.3085267245769501, 0.34551018476486206, 0.0, 0.0], [0.0010283143492415547, 0.241359144449234, 0.23320138454437256, 0.2555713355541229, 0.2688397467136383, 0.0], [0.0009746829164214432, 0.17789699137210846, 0.16743157804012299, 0.1858760118484497, 0.18734444677829742, 0.28047630190849304]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.824492871761322, 0.17550717294216156, 0.0, 0.0, 0.0, 0.0], [0.12386877834796906, 0.044499922543764114, 0.8316312432289124, 0.0, 0.0, 0.0], [0.07924355566501617, 0.01296587660908699, 0.0015277155907824636, 0.9062628149986267, 0.0, 0.0], [0.08806384354829788, 0.0213409923017025, 0.0028886159416288137, 0.002845379989594221, 0.884861171245575, 0.0], [0.09983218461275101, 0.03363388776779175, 0.0054999832063913345, 0.002433052286505699, 0.0015082412865012884, 0.8570926189422607]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9646892547607422, 0.03531072288751602, 0.0, 0.0, 0.0, 0.0], [0.7529157400131226, 0.08733473718166351, 0.15974950790405273, 0.0, 0.0, 0.0], [0.4202282726764679, 0.09195102006196976, 0.23549850285053253, 0.25232216715812683, 0.0, 0.0], [0.30848920345306396, 0.05908140912652016, 0.38391315937042236, 0.15659146010875702, 0.09192468225955963, 0.0], [0.44790443778038025, 0.04329312965273857, 0.0796918049454689, 0.11081931740045547, 0.22124572098255157, 0.09704558551311493]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.991096019744873, 0.008904009126126766, 0.0, 0.0, 0.0, 0.0], [0.9697675704956055, 0.026084503158926964, 0.004147922620177269, 0.0, 0.0, 0.0], [0.9082901477813721, 0.033206019550561905, 0.00942116230726242, 0.049082688987255096, 0.0, 0.0], [0.8949133157730103, 0.05544555187225342, 0.005577624775469303, 0.03150692582130432, 0.012556522153317928, 0.0], [0.8497740030288696, 0.028890123590826988, 0.0036647915840148926, 0.03751987963914871, 0.038427725434303284, 0.04172350466251373]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9984525442123413, 0.0015474462416023016, 0.0, 0.0, 0.0, 0.0], [0.48947831988334656, 0.4812193810939789, 0.029302269220352173, 0.0, 0.0, 0.0], [0.11772153526544571, 0.13121186196804047, 0.6702314615249634, 0.08083520829677582, 0.0, 0.0], [0.13043689727783203, 0.04068669304251671, 0.2652038037776947, 0.4114362895488739, 0.15223638713359833, 0.0], [0.12661904096603394, 0.03275119513273239, 0.03567872568964958, 0.06039190664887428, 0.6021825075149536, 0.1423766165971756]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9805176854133606, 0.019482342526316643, 0.0, 0.0, 0.0, 0.0], [0.7948849201202393, 0.12061909586191177, 0.08449601382017136, 0.0, 0.0, 0.0], [0.5612356066703796, 0.15743127465248108, 0.20339730381965637, 0.0779358446598053, 0.0, 0.0], [0.42583736777305603, 0.10742014646530151, 0.15123659372329712, 0.08755031228065491, 0.22795552015304565, 0.0], [0.24752654135227203, 0.024188270792365074, 0.03039524517953396, 0.08586956560611725, 0.5714336633682251, 0.040586672723293304]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9887767434120178, 0.011223225854337215, 0.0, 0.0, 0.0, 0.0], [0.7572693228721619, 0.22317346930503845, 0.019557112827897072, 0.0, 0.0, 0.0], [0.5341880321502686, 0.22107566893100739, 0.1762184202671051, 0.06851787120103836, 0.0, 0.0], [0.17095312476158142, 0.0822940468788147, 0.576022207736969, 0.11097585409879684, 0.059754710644483566, 0.0], [0.2487109899520874, 0.08880793303251266, 0.08980197459459305, 0.09729334712028503, 0.4413093626499176, 0.03407646715641022]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8422133326530457, 0.15778663754463196, 0.0, 0.0, 0.0, 0.0], [0.468412846326828, 0.46105360984802246, 0.07053359597921371, 0.0, 0.0, 0.0], [0.2588140666484833, 0.4635888636112213, 0.18503506481647491, 0.09256205707788467, 0.0, 0.0], [0.18399578332901, 0.29154160618782043, 0.17031098902225494, 0.27173006534576416, 0.08242159336805344, 0.0], [0.1646990180015564, 0.2472696155309677, 0.08770562708377838, 0.22575001418590546, 0.1774536371231079, 0.09712201356887817]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9919946193695068, 0.008005390875041485, 0.0, 0.0, 0.0, 0.0], [0.9068724513053894, 0.044065121561288834, 0.04906242713332176, 0.0, 0.0, 0.0], [0.8582221865653992, 0.055348269641399384, 0.040419407188892365, 0.046010036021471024, 0.0, 0.0], [0.7855252623558044, 0.041242364794015884, 0.08369296044111252, 0.04887620359659195, 0.040663279592990875, 0.0], [0.7856317162513733, 0.05014643445611, 0.04751267284154892, 0.027365952730178833, 0.05614755302667618, 0.03319567069411278]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9041035175323486, 0.09589648246765137, 0.0, 0.0, 0.0, 0.0], [0.5862312912940979, 0.07199832051992416, 0.34177035093307495, 0.0, 0.0, 0.0], [0.3878960907459259, 0.04660807177424431, 0.20278996229171753, 0.36270591616630554, 0.0, 0.0], [0.2665242552757263, 0.024533024057745934, 0.12211935967206955, 0.20041218400001526, 0.386411190032959, 0.0], [0.23357485234737396, 0.02053728699684143, 0.09610321372747421, 0.13062246143817902, 0.22990450263023376, 0.289257675409317]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9639912247657776, 0.036008793860673904, 0.0, 0.0, 0.0, 0.0], [0.7075552344322205, 0.2542775869369507, 0.038167137652635574, 0.0, 0.0, 0.0], [0.2566526234149933, 0.20589298009872437, 0.01665665954351425, 0.5207977294921875, 0.0, 0.0], [0.1037939190864563, 0.04639088362455368, 0.008698614314198494, 0.7866851687431335, 0.05443140119314194, 0.0], [0.2214341163635254, 0.03379744663834572, 0.029023902490735054, 0.541292130947113, 0.15286092460155487, 0.021591555327177048]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9891703724861145, 0.010829661041498184, 0.0, 0.0, 0.0, 0.0], [0.7913155555725098, 0.12309625744819641, 0.08558809012174606, 0.0, 0.0, 0.0], [0.2954600155353546, 0.15808308124542236, 0.4217240810394287, 0.1247328370809555, 0.0, 0.0], [0.23440983891487122, 0.09886523336172104, 0.33160170912742615, 0.1971396654844284, 0.1379835456609726, 0.0], [0.19728390872478485, 0.05741839483380318, 0.06909029185771942, 0.16469819843769073, 0.2797277867794037, 0.23178131878376007]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9359127879142761, 0.0640871673822403, 0.0, 0.0, 0.0, 0.0], [0.7888627648353577, 0.08673475682735443, 0.12440246343612671, 0.0, 0.0, 0.0], [0.6535118818283081, 0.07573551684617996, 0.09732568264007568, 0.17342689633369446, 0.0, 0.0], [0.522276759147644, 0.058278825134038925, 0.09920477122068405, 0.17020836472511292, 0.15003129839897156, 0.0], [0.4108840823173523, 0.047306034713983536, 0.07265672832727432, 0.10560744255781174, 0.10550004243850708, 0.25804558396339417]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9683833122253418, 0.03161672502756119, 0.0, 0.0, 0.0, 0.0], [0.8965396881103516, 0.038870569318532944, 0.06458976864814758, 0.0, 0.0, 0.0], [0.8264952898025513, 0.03213464096188545, 0.05196719989180565, 0.0894029513001442, 0.0, 0.0], [0.7718173265457153, 0.030402837321162224, 0.045827414840459824, 0.07118473201990128, 0.08076759427785873, 0.0], [0.7292331457138062, 0.021699821576476097, 0.033074747771024704, 0.04720093309879303, 0.06474557518959045, 0.10404567420482635]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9979567527770996, 0.0020432830788195133, 0.0, 0.0, 0.0, 0.0], [0.955294132232666, 0.00802531372755766, 0.03668047487735748, 0.0, 0.0, 0.0], [0.9254710078239441, 0.002755576279014349, 0.0020629852078855038, 0.06971040368080139, 0.0, 0.0], [0.8660576939582825, 0.0038883681409060955, 0.0006785982404835522, 0.0006981453043408692, 0.1286771297454834, 0.0], [0.8455929160118103, 0.0037804055027663708, 0.000253423087997362, 6.0270751419011503e-05, 0.00011820747749879956, 0.15019479393959045]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9262455105781555, 0.07375453412532806, 0.0, 0.0, 0.0, 0.0], [0.7717157006263733, 0.16241952776908875, 0.06586471945047379, 0.0, 0.0, 0.0], [0.8167637586593628, 0.07807160913944244, 0.06324034929275513, 0.041924238204956055, 0.0, 0.0], [0.6867184638977051, 0.07755157351493835, 0.10056912153959274, 0.05955080687999725, 0.07561002671718597, 0.0], [0.6421161890029907, 0.11014898866415024, 0.07688194513320923, 0.054033469408750534, 0.10333634912967682, 0.013483096845448017]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9395954608917236, 0.060404520481824875, 0.0, 0.0, 0.0, 0.0], [0.23004619777202606, 0.6617380380630493, 0.1082158014178276, 0.0, 0.0, 0.0], [0.2670227289199829, 0.3607950508594513, 0.3249626159667969, 0.047219593077898026, 0.0, 0.0], [0.595201313495636, 0.12269274890422821, 0.06302059441804886, 0.08916817605495453, 0.12991715967655182, 0.0], [0.10284596681594849, 0.02938011661171913, 0.013739082030951977, 0.045860596001148224, 0.7698501348495483, 0.03832406550645828]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9040980935096741, 0.09590194374322891, 0.0, 0.0, 0.0, 0.0], [0.357237845659256, 0.6274612545967102, 0.015300876460969448, 0.0, 0.0, 0.0], [0.5917996764183044, 0.2764042019844055, 0.10476048290729523, 0.027035649865865707, 0.0, 0.0], [0.7254403829574585, 0.04983152449131012, 0.014982940629124641, 0.1778142899274826, 0.031930916011333466, 0.0], [0.7612743973731995, 0.06158972904086113, 0.005942251533269882, 0.01642685756087303, 0.1267806589603424, 0.0279861893504858]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9947587847709656, 0.005241230130195618, 0.0, 0.0, 0.0, 0.0], [0.9632415771484375, 0.017816413193941116, 0.018942030146718025, 0.0, 0.0, 0.0], [0.9671078324317932, 0.008509586565196514, 0.00856222677975893, 0.015820473432540894, 0.0, 0.0], [0.9340996146202087, 0.011952387169003487, 0.02018021047115326, 0.02675083465874195, 0.0070168930105865, 0.0], [0.9587237238883972, 0.004657115787267685, 0.003326789475977421, 0.006545313633978367, 0.010182461701333523, 0.016564540565013885]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9769991040229797, 0.023000910878181458, 0.0, 0.0, 0.0, 0.0], [0.7917609214782715, 0.1753319948911667, 0.032907065004110336, 0.0, 0.0, 0.0], [0.7949192523956299, 0.10531841963529587, 0.040218502283096313, 0.05954383686184883, 0.0, 0.0], [0.7097718715667725, 0.10552527755498886, 0.06597573310136795, 0.05765606462955475, 0.061070989817380905, 0.0], [0.7506601214408875, 0.026514461264014244, 0.021576043218374252, 0.034296683967113495, 0.08494450151920319, 0.08200812339782715]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.983751654624939, 0.016248304396867752, 0.0, 0.0, 0.0, 0.0], [0.5615494847297668, 0.08956841379404068, 0.3488820493221283, 0.0, 0.0, 0.0], [0.32929039001464844, 0.024114903062582016, 0.5428059697151184, 0.10378880053758621, 0.0, 0.0], [0.34330207109451294, 0.01308644749224186, 0.5121983289718628, 0.11146228760480881, 0.019950881600379944, 0.0], [0.4792812764644623, 0.01733359508216381, 0.1180536150932312, 0.06130281835794449, 0.20071913301944733, 0.12330964207649231]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9908847212791443, 0.009115329943597317, 0.0, 0.0, 0.0, 0.0], [0.5282707214355469, 0.3292262554168701, 0.1425030380487442, 0.0, 0.0, 0.0], [0.48788541555404663, 0.23368670046329498, 0.17578084766864777, 0.10264702141284943, 0.0, 0.0], [0.31444698572158813, 0.18065163493156433, 0.168714240193367, 0.09506598114967346, 0.24112118780612946, 0.0], [0.5168765187263489, 0.035897161811590195, 0.026188155636191368, 0.04039734974503517, 0.18791745603084564, 0.1927233189344406]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8750308156013489, 0.12496919929981232, 0.0, 0.0, 0.0, 0.0], [0.4550614655017853, 0.4900427758693695, 0.05489582195878029, 0.0, 0.0, 0.0], [0.2933720052242279, 0.5449907183647156, 0.09444297850131989, 0.06719419360160828, 0.0, 0.0], [0.489708811044693, 0.2720997631549835, 0.06861965358257294, 0.14694802463054657, 0.022623788565397263, 0.0], [0.4729066491127014, 0.08103099465370178, 0.016052134335041046, 0.30672287940979004, 0.10120721161365509, 0.022080255672335625]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9630220532417297, 0.03697792813181877, 0.0, 0.0, 0.0, 0.0], [0.7557195425033569, 0.16436372697353363, 0.07991670072078705, 0.0, 0.0, 0.0], [0.6947705745697021, 0.08409853279590607, 0.0638260766863823, 0.15730486810207367, 0.0, 0.0], [0.5821147561073303, 0.03297805413603783, 0.07936596870422363, 0.19441406428813934, 0.11112712323665619, 0.0], [0.5974540710449219, 0.04261096194386482, 0.06919723749160767, 0.14563441276550293, 0.12481734901666641, 0.020285936072468758]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9957822561264038, 0.004217816516757011, 0.0, 0.0, 0.0, 0.0], [0.9312832951545715, 0.010560247115790844, 0.05815650522708893, 0.0, 0.0, 0.0], [0.8435326814651489, 0.015695005655288696, 0.045751139521598816, 0.09502115100622177, 0.0, 0.0], [0.772409975528717, 0.011981245130300522, 0.03504609689116478, 0.03876771405339241, 0.14179500937461853, 0.0], [0.7642908692359924, 0.009868789464235306, 0.00812275055795908, 0.013314393348991871, 0.04824395477771759, 0.15615922212600708]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9701177477836609, 0.02988232672214508, 0.0, 0.0, 0.0, 0.0], [0.6564007997512817, 0.22506150603294373, 0.11853761970996857, 0.0, 0.0, 0.0], [0.6958062648773193, 0.14701850712299347, 0.07145983725786209, 0.08571550250053406, 0.0, 0.0], [0.6353274583816528, 0.1346064656972885, 0.030994214117527008, 0.056916315108537674, 0.1421555131673813, 0.0], [0.6779401898384094, 0.053654152899980545, 0.01800631172955036, 0.06284520775079727, 0.1103820651769638, 0.07717210054397583]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9822334051132202, 0.017766647040843964, 0.0, 0.0, 0.0, 0.0], [0.9037663340568542, 0.06541544198989868, 0.03081829659640789, 0.0, 0.0, 0.0], [0.8119193911552429, 0.03679030388593674, 0.060560714453458786, 0.09072960168123245, 0.0, 0.0], [0.40546438097953796, 0.10383912175893784, 0.10211236774921417, 0.35434210300445557, 0.03424208238720894, 0.0], [0.22824221849441528, 0.017278727144002914, 0.05055465176701546, 0.6015752553939819, 0.09411764144897461, 0.008231506682932377]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9873148202896118, 0.012685136869549751, 0.0, 0.0, 0.0, 0.0], [0.35445743799209595, 0.5317603349685669, 0.11378221958875656, 0.0, 0.0, 0.0], [0.07823363691568375, 0.7221359014511108, 0.10936623811721802, 0.090264230966568, 0.0, 0.0], [0.21967869997024536, 0.4048435091972351, 0.12358088046312332, 0.20018866658210754, 0.051708199083805084, 0.0], [0.36089760065078735, 0.10459021478891373, 0.06983799487352371, 0.2976483404636383, 0.13869903981685638, 0.02832675166428089]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9732162356376648, 0.0267837755382061, 0.0, 0.0, 0.0, 0.0], [0.9167553782463074, 0.061452705413103104, 0.02179192565381527, 0.0, 0.0, 0.0], [0.8543081283569336, 0.08049600571393967, 0.030334919691085815, 0.03486092761158943, 0.0, 0.0], [0.8919214606285095, 0.04280779883265495, 0.022045055404305458, 0.023470671847462654, 0.01975487545132637, 0.0], [0.8116763234138489, 0.03413533419370651, 0.03567665070295334, 0.04748587682843208, 0.0253971628844738, 0.04562860727310181]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9502761960029602, 0.04972382262349129, 0.0, 0.0, 0.0, 0.0], [0.7637454271316528, 0.2007361352443695, 0.03551840782165527, 0.0, 0.0, 0.0], [0.6279097199440002, 0.03768139332532883, 0.1994536966085434, 0.13495522737503052, 0.0, 0.0], [0.6397060751914978, 0.027007432654500008, 0.09082036465406418, 0.20653828978538513, 0.03592785820364952, 0.0], [0.4559425115585327, 0.021641194820404053, 0.12939567863941193, 0.21800927817821503, 0.10379841923713684, 0.07121295481920242]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9498406648635864, 0.050159383565187454, 0.0, 0.0, 0.0, 0.0], [0.8688724637031555, 0.0872218981385231, 0.043905653059482574, 0.0, 0.0, 0.0], [0.6937950253486633, 0.06359200924634933, 0.091790571808815, 0.15082231163978577, 0.0, 0.0], [0.7266597151756287, 0.04389883577823639, 0.04683985933661461, 0.09851823002099991, 0.08408336341381073, 0.0], [0.7848998308181763, 0.037147827446460724, 0.012907838448882103, 0.01053939200937748, 0.12079165875911713, 0.03371351957321167]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9891054034233093, 0.01089458167552948, 0.0, 0.0, 0.0, 0.0], [0.8929519653320312, 0.08700055629014969, 0.02004752680659294, 0.0, 0.0, 0.0], [0.7891124486923218, 0.09797251224517822, 0.08633202314376831, 0.026582980528473854, 0.0, 0.0], [0.8850635886192322, 0.03645012155175209, 0.05395457148551941, 0.01237727515399456, 0.012154522351920605, 0.0], [0.6861329674720764, 0.05720378831028938, 0.011636304669082165, 0.021660611033439636, 0.1748800277709961, 0.048486363142728806]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9396191835403442, 0.06038080155849457, 0.0, 0.0, 0.0, 0.0], [0.7851794958114624, 0.19751444458961487, 0.017306052148342133, 0.0, 0.0, 0.0], [0.7660509943962097, 0.15444670617580414, 0.03188290074467659, 0.04761936888098717, 0.0, 0.0], [0.703522801399231, 0.05171430483460426, 0.07760990411043167, 0.1533905267715454, 0.013762423768639565, 0.0], [0.7121888399124146, 0.04994234815239906, 0.03772548958659172, 0.08649132400751114, 0.06541401147842407, 0.04823806509375572]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.974072277545929, 0.025927715003490448, 0.0, 0.0, 0.0, 0.0], [0.792539656162262, 0.01171559002250433, 0.19574476778507233, 0.0, 0.0, 0.0], [0.5106770992279053, 0.007296787109225988, 0.039619915187358856, 0.4424062669277191, 0.0, 0.0], [0.5862472057342529, 0.012099712155759335, 0.024585209786891937, 0.06737840175628662, 0.30968940258026123, 0.0], [0.30196306109428406, 0.007724012713879347, 0.011518122628331184, 0.046947259455919266, 0.22146707773208618, 0.41038045287132263]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9744554162025452, 0.02554464340209961, 0.0, 0.0, 0.0, 0.0], [0.9769195318222046, 0.015048524364829063, 0.008031901903450489, 0.0, 0.0, 0.0], [0.9060619473457336, 0.025875424966216087, 0.025954782962799072, 0.04210779070854187, 0.0, 0.0], [0.9400081038475037, 0.00555665697902441, 0.005828304681926966, 0.031757812947034836, 0.016849134117364883, 0.0], [0.9105738401412964, 0.0019752182997763157, 0.008646721951663494, 0.013360846787691116, 0.03543964773416519, 0.030003678053617477]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9791666865348816, 0.020833350718021393, 0.0, 0.0, 0.0, 0.0], [0.8444858193397522, 0.13507869839668274, 0.020435383543372154, 0.0, 0.0, 0.0], [0.7903086543083191, 0.14559169113636017, 0.037529975175857544, 0.026569725945591927, 0.0, 0.0], [0.7298924326896667, 0.056496407836675644, 0.032735615968704224, 0.10400459170341492, 0.07687094807624817, 0.0], [0.5684185028076172, 0.04388832300901413, 0.026293467730283737, 0.0811714455485344, 0.24314835667610168, 0.037079911679029465]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9499868154525757, 0.05001320689916611, 0.0, 0.0, 0.0, 0.0], [0.9336170554161072, 0.05848868936300278, 0.007894262671470642, 0.0, 0.0, 0.0], [0.7897834181785583, 0.11071821302175522, 0.05360178276896477, 0.04589657858014107, 0.0, 0.0], [0.885930061340332, 0.05752986669540405, 0.01374326553195715, 0.0033877466339617968, 0.03940902277827263, 0.0], [0.9337607622146606, 0.02647063508629799, 0.004523396957665682, 0.0061904797330498695, 0.014132906682789326, 0.014921708963811398]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 1.8521224554035598e-09, 0.0, 0.0, 0.0, 0.0], [6.6758907451003324e-06, 0.9999804496765137, 1.2841281204600818e-05, 0.0, 0.0, 0.0], [2.2194194926328237e-08, 2.6684581211355862e-09, 0.9999971389770508, 2.8136880700913025e-06, 0.0, 0.0], [1.0145409987671883e-06, 4.464065739284706e-08, 0.00035356366424821317, 0.9993677735328674, 0.0002776293840724975, 0.0], [9.436550429953172e-10, 1.382057315812979e-11, 5.017835036369434e-10, 2.965183876213473e-09, 0.9999971389770508, 2.8644042231462663e-06]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9948632121086121, 0.005136783700436354, 0.0, 0.0, 0.0, 0.0], [0.9274215698242188, 0.01832387037575245, 0.05425456911325455, 0.0, 0.0, 0.0], [0.9678993225097656, 0.004143435508012772, 0.004314453341066837, 0.023642776533961296, 0.0, 0.0], [0.8999068737030029, 0.001467161695472896, 0.00029133574571460485, 0.002585014794021845, 0.09574954956769943, 0.0], [0.9386115670204163, 0.00022248300956562161, 0.0006146665546111763, 0.0015495637198910117, 0.030689461156725883, 0.028312424197793007]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9999959468841553, 4.042720775032649e-06, 0.0, 0.0, 0.0, 0.0], [0.9982761144638062, 3.2613831990602193e-06, 0.001720669330097735, 0.0, 0.0, 0.0], [0.9998809099197388, 5.328835683826583e-08, 6.376215537784446e-07, 0.00011847059795400128, 0.0, 0.0], [0.9996154308319092, 3.473169556400535e-07, 3.8920820344401363e-08, 4.468433303372876e-07, 0.00038369710091501474, 0.0], [0.9994840621948242, 1.655020476221125e-08, 2.8715557931491276e-08, 1.0638284493325045e-06, 0.0002126671897713095, 0.00030212008277885616]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9514135718345642, 0.048586405813694, 0.0, 0.0, 0.0, 0.0], [0.5749948024749756, 0.39028096199035645, 0.03472418338060379, 0.0, 0.0, 0.0], [0.7442318201065063, 0.1752411425113678, 0.0756477490067482, 0.004879283253103495, 0.0, 0.0], [0.5232070684432983, 0.09429339319467545, 0.1138191670179367, 0.19979268312454224, 0.06888769567012787, 0.0], [0.47472575306892395, 0.05636607110500336, 0.04530389606952667, 0.06967321783304214, 0.3098014295101166, 0.0441296212375164]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8734648823738098, 0.12653514742851257, 0.0, 0.0, 0.0, 0.0], [0.6097912788391113, 0.3541727066040039, 0.036036062985658646, 0.0, 0.0, 0.0], [0.45984190702438354, 0.38697871565818787, 0.0996011346578598, 0.05357823893427849, 0.0, 0.0], [0.572220504283905, 0.23636263608932495, 0.08344558626413345, 0.06921917200088501, 0.03875211998820305, 0.0], [0.5143564343452454, 0.16723087430000305, 0.09019406139850616, 0.0765448659658432, 0.10578085482120514, 0.04589281603693962]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.981228768825531, 0.018771231174468994, 0.0, 0.0, 0.0, 0.0], [0.6142941117286682, 0.3503977954387665, 0.0353081189095974, 0.0, 0.0, 0.0], [0.5770686268806458, 0.32858458161354065, 0.05508256331086159, 0.03926428034901619, 0.0, 0.0], [0.17188192903995514, 0.011042501777410507, 0.054578714072704315, 0.7326585650444031, 0.029838265851140022, 0.0], [0.3783015012741089, 0.017070062458515167, 0.021754134446382523, 0.4409688115119934, 0.06093813106417656, 0.08096737414598465]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9923112392425537, 0.007688735146075487, 0.0, 0.0, 0.0, 0.0], [0.9498787522315979, 0.016709784045815468, 0.03341152146458626, 0.0, 0.0, 0.0], [0.9961295127868652, 0.0008787295082584023, 0.0006868162308819592, 0.0023048371076583862, 0.0, 0.0], [0.9935757517814636, 0.0032634998206049204, 0.0009993825806304812, 0.00027932299417443573, 0.0018820574041455984, 0.0], [0.9907532930374146, 0.00021344318520277739, 0.0004595233185682446, 0.0007905619568191469, 0.004424723796546459, 0.003358350833877921]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9647740125656128, 0.03522596135735512, 0.0, 0.0, 0.0, 0.0], [0.8194130063056946, 0.1365436613559723, 0.04404333233833313, 0.0, 0.0, 0.0], [0.7584245800971985, 0.006878929678350687, 0.20653395354747772, 0.028162529692053795, 0.0, 0.0], [0.5298128128051758, 0.002678812015801668, 0.07857988774776459, 0.3598373234272003, 0.02909109927713871, 0.0], [0.7544413208961487, 0.00036782227107323706, 0.0019713479559868574, 0.00324004958383739, 0.1942344754934311, 0.04574500769376755]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9749131202697754, 0.02508680149912834, 0.0, 0.0, 0.0, 0.0], [0.9306471943855286, 0.05705660209059715, 0.012296222150325775, 0.0, 0.0, 0.0], [0.9305251836776733, 0.052770983427762985, 0.01111945416778326, 0.005584415514022112, 0.0, 0.0], [0.8863320350646973, 0.01292418036609888, 0.017724711447954178, 0.06150198355317116, 0.021517015993595123, 0.0], [0.791684627532959, 0.015036096796393394, 0.0317479707300663, 0.03392200171947479, 0.03707978501915932, 0.09052948653697968]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9608501195907593, 0.039149850606918335, 0.0, 0.0, 0.0, 0.0], [0.9121272563934326, 0.02257651649415493, 0.06529619544744492, 0.0, 0.0, 0.0], [0.9364108443260193, 0.015584447421133518, 0.024544963613152504, 0.02345985174179077, 0.0, 0.0], [0.9454620480537415, 0.006762288510799408, 0.022026237100362778, 0.009137796238064766, 0.016611700877547264, 0.0], [0.8346164226531982, 0.001881699077785015, 0.00560904573649168, 0.01887359470129013, 0.12449200451374054, 0.014527074061334133]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9964227080345154, 0.0035772807896137238, 0.0, 0.0, 0.0, 0.0], [0.9713928699493408, 0.024453025311231613, 0.004154058638960123, 0.0, 0.0, 0.0], [0.9735792279243469, 0.019003381952643394, 0.003664410673081875, 0.0037529165856540203, 0.0, 0.0], [0.9586312174797058, 0.007116180844604969, 0.009218388237059116, 0.022725583985447884, 0.0023084774147719145, 0.0], [0.973607063293457, 0.008490582928061485, 0.0032512471079826355, 0.003606445388868451, 0.004877461586147547, 0.006167212035506964]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.97598797082901, 0.024011990055441856, 0.0, 0.0, 0.0, 0.0], [0.9460638165473938, 0.04211375489830971, 0.011822436936199665, 0.0, 0.0, 0.0], [0.8446813225746155, 0.04293116182088852, 0.05218198522925377, 0.06020559370517731, 0.0, 0.0], [0.9378372430801392, 0.03354858607053757, 0.008826455101370811, 0.0028792242519557476, 0.016908427700400352, 0.0], [0.8124931454658508, 0.02696753479540348, 0.05999218672513962, 0.03445731848478317, 0.011011860333383083, 0.05507794767618179]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9001203775405884, 0.09987961500883102, 0.0, 0.0, 0.0, 0.0], [0.627193033695221, 0.07988718152046204, 0.29291975498199463, 0.0, 0.0, 0.0], [0.7624077796936035, 0.02734432928264141, 0.038679543882608414, 0.17156831920146942, 0.0, 0.0], [0.7995968461036682, 0.014336260966956615, 0.01437566988170147, 0.025438452139496803, 0.14625284075737, 0.0], [0.7851970791816711, 0.04204057529568672, 0.025253651663661003, 0.02908395044505596, 0.029306314885616302, 0.08911846578121185]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9954467415809631, 0.0045532057993113995, 0.0, 0.0, 0.0, 0.0], [0.9356001615524292, 0.04476744681596756, 0.019632352516055107, 0.0, 0.0, 0.0], [0.5605552792549133, 0.09861977398395538, 0.29983264207839966, 0.040992289781570435, 0.0, 0.0], [0.5893709659576416, 0.11000988632440567, 0.08033622056245804, 0.16754034161567688, 0.05274256691336632, 0.0], [0.22305884957313538, 0.05680817365646362, 0.05467984080314636, 0.24733951687812805, 0.3111244738101959, 0.1069890558719635]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9301451444625854, 0.06985488533973694, 0.0, 0.0, 0.0, 0.0], [0.8936478495597839, 0.08535721153020859, 0.020994966849684715, 0.0, 0.0, 0.0], [0.8404538035392761, 0.10619214922189713, 0.02363673783838749, 0.029717326164245605, 0.0, 0.0], [0.8927386403083801, 0.024784674867987633, 0.008319000713527203, 0.05165454372763634, 0.022503145039081573, 0.0], [0.8646610975265503, 0.009503193199634552, 0.0024329854641109705, 0.04796753078699112, 0.04273205250501633, 0.03270319849252701]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9859625697135925, 0.014037408865988255, 0.0, 0.0, 0.0, 0.0], [0.9702037572860718, 0.0168070700019598, 0.012989125214517117, 0.0, 0.0, 0.0], [0.9524770379066467, 0.016064459457993507, 0.013456220738589764, 0.018002323806285858, 0.0, 0.0], [0.9332928657531738, 0.01897200010716915, 0.02014683373272419, 0.017023753374814987, 0.010564540512859821, 0.0], [0.9113592505455017, 0.012528638355433941, 0.02209620550274849, 0.01751861348748207, 0.018517911434173584, 0.01797938533127308]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9681769013404846, 0.03182310611009598, 0.0, 0.0, 0.0, 0.0], [0.9096417427062988, 0.07916690409183502, 0.011191264726221561, 0.0, 0.0, 0.0], [0.8379932045936584, 0.13078266382217407, 0.012140989303588867, 0.019083037972450256, 0.0, 0.0], [0.9116525053977966, 0.05451957508921623, 0.009499342180788517, 0.00746585289016366, 0.01686275750398636, 0.0], [0.8510289192199707, 0.07338211685419083, 0.008022507652640343, 0.009083161130547523, 0.04261006414890289, 0.015873271971940994]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9799023866653442, 0.020097682252526283, 0.0, 0.0, 0.0, 0.0], [0.9558742642402649, 0.029063312336802483, 0.015062497928738594, 0.0, 0.0, 0.0], [0.7943133115768433, 0.06074100360274315, 0.06907659024000168, 0.07586916536092758, 0.0, 0.0], [0.5494324564933777, 0.03154711425304413, 0.05482015758752823, 0.05788077041506767, 0.3063195049762726, 0.0], [0.6453980803489685, 0.010770943015813828, 0.017528092488646507, 0.02157985046505928, 0.24958276748657227, 0.05514020845293999]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9506809115409851, 0.0493190623819828, 0.0, 0.0, 0.0, 0.0], [0.8553215265274048, 0.09256264567375183, 0.05211575701832771, 0.0, 0.0, 0.0], [0.850852370262146, 0.04734604433178902, 0.044177331030368805, 0.057624250650405884, 0.0, 0.0], [0.7697131633758545, 0.02788589708507061, 0.031017286702990532, 0.06842502951622009, 0.1029587835073471, 0.0], [0.7931903004646301, 0.04052198305726051, 0.029242033138871193, 0.04478124529123306, 0.04894689470529556, 0.04331749677658081]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9770310521125793, 0.02296893112361431, 0.0, 0.0, 0.0, 0.0], [0.9429817199707031, 0.017321482300758362, 0.03969680890440941, 0.0, 0.0, 0.0], [0.9144344925880432, 0.008583576418459415, 0.013035810552537441, 0.06394599378108978, 0.0, 0.0], [0.9222429990768433, 0.0036440351977944374, 0.003740275977179408, 0.010410364717245102, 0.05996239185333252, 0.0], [0.9198879599571228, 0.0030822583939880133, 0.0034827394410967827, 0.004206796642392874, 0.02125428058207035, 0.048085976392030716]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.977458119392395, 0.022541873157024384, 0.0, 0.0, 0.0, 0.0], [0.8929325342178345, 0.07475466281175613, 0.032312843948602676, 0.0, 0.0, 0.0], [0.8423511385917664, 0.05980278551578522, 0.03740081936120987, 0.06044524535536766, 0.0, 0.0], [0.7674624919891357, 0.03536349534988403, 0.042155250906944275, 0.06658654659986496, 0.08843226730823517, 0.0], [0.6182611584663391, 0.01611059531569481, 0.020167622715234756, 0.03868892416357994, 0.23147016763687134, 0.07530155777931213]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9634856581687927, 0.036514393985271454, 0.0, 0.0, 0.0, 0.0], [0.4363938570022583, 0.522637128829956, 0.04096902906894684, 0.0, 0.0, 0.0], [0.3608614206314087, 0.35129693150520325, 0.2655103802680969, 0.022331148386001587, 0.0, 0.0], [0.3942921757698059, 0.021704670041799545, 0.07794328778982162, 0.37168896198272705, 0.1343708038330078, 0.0], [0.6310713887214661, 0.01698400266468525, 0.025942081585526466, 0.08615949749946594, 0.2183200567960739, 0.021522950381040573]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9988250136375427, 0.0011750265257433057, 0.0, 0.0, 0.0, 0.0], [0.9944871068000793, 0.0004826401418540627, 0.0050302306190133095, 0.0, 0.0, 0.0], [0.9981209635734558, 2.705173392314464e-05, 0.0001130745149566792, 0.0017389442073181272, 0.0, 0.0], [0.9982239603996277, 6.83655816828832e-05, 0.00010199935059063137, 6.028370262356475e-05, 0.0015453165397047997, 0.0], [0.9982888102531433, 1.055222810464329e-06, 3.2781026675365865e-05, 0.00013038977340329438, 0.0006605894886888564, 0.0008863684488460422]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9936710596084595, 0.006328921765089035, 0.0, 0.0, 0.0, 0.0], [0.9727688431739807, 0.0018561368342489004, 0.025375060737133026, 0.0, 0.0, 0.0], [0.9724299907684326, 0.0019586149137467146, 0.011192461475729942, 0.014418890699744225, 0.0, 0.0], [0.9782041311264038, 0.0009589138207957149, 0.0018706483533605933, 0.006326568778604269, 0.012639678083360195, 0.0], [0.9592596888542175, 0.0024555064737796783, 0.00161241355817765, 0.005019655916839838, 0.006687097251415253, 0.024965662509202957]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9629000425338745, 0.03709998354315758, 0.0, 0.0, 0.0, 0.0], [0.36801934242248535, 0.6152258515357971, 0.016754813492298126, 0.0, 0.0, 0.0], [0.3173511326313019, 0.6140013337135315, 0.05375149846076965, 0.014896026812493801, 0.0, 0.0], [0.48987284302711487, 0.21071474254131317, 0.04693019017577171, 0.20700432360172272, 0.04547784850001335, 0.0], [0.48774227499961853, 0.1769528090953827, 0.06915216147899628, 0.09849268198013306, 0.12091436982154846, 0.046745721250772476]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9794419407844543, 0.020558049902319908, 0.0, 0.0, 0.0, 0.0], [0.6677903532981873, 0.31032365560531616, 0.021886007860302925, 0.0, 0.0, 0.0], [0.7118757367134094, 0.11108540743589401, 0.14187385141849518, 0.03516504913568497, 0.0, 0.0], [0.4501457214355469, 0.04036055505275726, 0.040458209812641144, 0.388570100069046, 0.08046531677246094, 0.0], [0.49346262216567993, 0.013696977868676186, 0.008126799948513508, 0.13074499368667603, 0.3086138069629669, 0.04535480588674545]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9846054315567017, 0.015394587069749832, 0.0, 0.0, 0.0, 0.0], [0.9806739091873169, 0.007713791914284229, 0.011612347327172756, 0.0, 0.0, 0.0], [0.932663083076477, 0.01957838423550129, 0.02410353161394596, 0.023654978722333908, 0.0, 0.0], [0.9422016739845276, 0.0009538981830701232, 0.0010898025939241052, 0.00319337984547019, 0.05256118252873421, 0.0], [0.9352930784225464, 0.0010279357666149735, 0.004444425459951162, 0.001637140172533691, 0.010590963996946812, 0.04700646549463272]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9985783100128174, 0.0014216724084690213, 0.0, 0.0, 0.0, 0.0], [0.9893348813056946, 0.0011178902350366116, 0.00954714696854353, 0.0, 0.0, 0.0], [0.9979978203773499, 7.997050124686211e-05, 0.00013218850654084235, 0.0017900333041325212, 0.0, 0.0], [0.9986976385116577, 4.1044117097044364e-05, 3.8683547245454974e-06, 2.3676282580709085e-05, 0.0012337174266576767, 0.0], [0.9971563816070557, 1.852225250331685e-05, 1.8826559653462027e-06, 2.7900125132873654e-05, 0.0006533482228405774, 0.0021419788245111704]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9768233299255371, 0.023176640272140503, 0.0, 0.0, 0.0, 0.0], [0.9194678068161011, 0.05088186264038086, 0.029650341719388962, 0.0, 0.0, 0.0], [0.8474554419517517, 0.06100169196724892, 0.04372376948595047, 0.04781914874911308, 0.0, 0.0], [0.8011623620986938, 0.041866958141326904, 0.04375807195901871, 0.041894737631082535, 0.07131782174110413, 0.0], [0.8031871914863586, 0.02450493723154068, 0.017323585227131844, 0.04744395986199379, 0.06109930947422981, 0.046441152691841125]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9829428195953369, 0.01705716922879219, 0.0, 0.0, 0.0, 0.0], [0.8863736987113953, 0.09492647647857666, 0.018699750304222107, 0.0, 0.0, 0.0], [0.9231085777282715, 0.03696346655488014, 0.032198335975408554, 0.007729663979262114, 0.0, 0.0], [0.9068527221679688, 0.016046639531850815, 0.014310522936284542, 0.04543786868453026, 0.017352323979139328, 0.0], [0.6555973887443542, 0.05091019719839096, 0.028384855017066002, 0.1256549060344696, 0.10546853393316269, 0.03398407623171806]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9502318501472473, 0.049768079072237015, 0.0, 0.0, 0.0, 0.0], [0.8829865455627441, 0.1000962108373642, 0.01691717840731144, 0.0, 0.0, 0.0], [0.8057457804679871, 0.14463546872138977, 0.03018922731280327, 0.019429458305239677, 0.0, 0.0], [0.8706230521202087, 0.032440632581710815, 0.026951627805829048, 0.04410304129123688, 0.025881657376885414, 0.0], [0.688364565372467, 0.009681451134383678, 0.016449343413114548, 0.0987110361456871, 0.08971209079027176, 0.09708156436681747]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9792683124542236, 0.02073168195784092, 0.0, 0.0, 0.0, 0.0], [0.9523284435272217, 0.025933818891644478, 0.021737735718488693, 0.0, 0.0, 0.0], [0.9144353270530701, 0.017671240493655205, 0.022358495742082596, 0.04553484544157982, 0.0, 0.0], [0.9448292851448059, 0.006467597559094429, 0.006386063527315855, 0.03263096138834953, 0.00968620739877224, 0.0], [0.9347906112670898, 0.007862505502998829, 0.007788175716996193, 0.021432818844914436, 0.008491144515573978, 0.01963483914732933]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.983370304107666, 0.016629677265882492, 0.0, 0.0, 0.0, 0.0], [0.963111400604248, 0.009229931980371475, 0.027658598497509956, 0.0, 0.0, 0.0], [0.9706628322601318, 0.0041494048200547695, 0.0068131014704704285, 0.018374638631939888, 0.0, 0.0], [0.987951934337616, 0.002165885642170906, 0.00034901127219200134, 0.001583816367201507, 0.00794942770153284, 0.0], [0.9457950592041016, 0.014583553187549114, 0.0003652951563708484, 0.0009569536778144538, 0.013621564954519272, 0.02467755414545536]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9878059029579163, 0.01219407469034195, 0.0, 0.0, 0.0, 0.0], [0.87103670835495, 0.09448163211345673, 0.03448161482810974, 0.0, 0.0, 0.0], [0.6309783458709717, 0.11090382188558578, 0.1923021823167801, 0.06581564992666245, 0.0, 0.0], [0.5360490083694458, 0.04618944972753525, 0.13605308532714844, 0.26455509662628174, 0.017153292894363403, 0.0], [0.8287520408630371, 0.023732755333185196, 0.02008037269115448, 0.07245264202356339, 0.030431220307946205, 0.024550989270210266]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8995685577392578, 0.10043150931596756, 0.0, 0.0, 0.0, 0.0], [0.270343542098999, 0.6504329442977905, 0.07922357320785522, 0.0, 0.0, 0.0], [0.20541730523109436, 0.5892508625984192, 0.18085837364196777, 0.024473490193486214, 0.0, 0.0], [0.5573861002922058, 0.1774134784936905, 0.08806808292865753, 0.09881848096847534, 0.07831384986639023, 0.0], [0.5922912359237671, 0.08700639009475708, 0.05643285810947418, 0.05685883015394211, 0.12181518226861954, 0.08559554070234299]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9316380620002747, 0.06836195290088654, 0.0, 0.0, 0.0, 0.0], [0.9572945833206177, 0.026243582367897034, 0.0164618119597435, 0.0, 0.0, 0.0], [0.9880544543266296, 0.00427332753315568, 0.002954584313556552, 0.004717645235359669, 0.0, 0.0], [0.99403977394104, 0.0009413420339114964, 0.0004739820142276585, 0.00011646930943243206, 0.004428447224199772, 0.0], [0.9806035161018372, 2.5468933017691597e-05, 0.00016239412070717663, 0.0001476418401580304, 0.0013442443450912833, 0.017716845497488976]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.993178129196167, 0.006821857299655676, 0.0, 0.0, 0.0, 0.0], [0.9756524562835693, 0.01318411435931921, 0.011163423769176006, 0.0, 0.0, 0.0], [0.9418966770172119, 0.004721744451671839, 0.0023818055633455515, 0.050999753177165985, 0.0, 0.0], [0.9905040860176086, 0.0022848136723041534, 6.198462506290525e-05, 0.0005984465242363513, 0.006550676189363003, 0.0], [0.9697660207748413, 0.0008878845837898552, 0.00023466735729016364, 0.0017040816601365805, 0.004128355998545885, 0.02327893301844597]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9716231822967529, 0.02837684564292431, 0.0, 0.0, 0.0, 0.0], [0.9223619699478149, 0.028907248750329018, 0.048730745911598206, 0.0, 0.0, 0.0], [0.8426317572593689, 0.023872116580605507, 0.04748132824897766, 0.08601479232311249, 0.0, 0.0], [0.8521121740341187, 0.020744236186146736, 0.04494619369506836, 0.05765002593398094, 0.02454746514558792, 0.0], [0.8800725936889648, 0.022448532283306122, 0.018235722556710243, 0.01925482600927353, 0.015854258090257645, 0.044134121388196945]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9412723779678345, 0.058727629482746124, 0.0, 0.0, 0.0, 0.0], [0.916313886642456, 0.05759201943874359, 0.02609400637447834, 0.0, 0.0, 0.0], [0.8392423391342163, 0.057690516114234924, 0.01382902916520834, 0.08923812955617905, 0.0, 0.0], [0.8987162113189697, 0.0134778693318367, 0.0003456450067460537, 0.003298751311376691, 0.08416149020195007, 0.0], [0.8701692223548889, 0.002700856188312173, 0.00143499206751585, 0.0056661744602024555, 0.08874300867319107, 0.031285665929317474]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9656725525856018, 0.03432750701904297, 0.0, 0.0, 0.0, 0.0], [0.9178615808486938, 0.062257930636405945, 0.019880469888448715, 0.0, 0.0, 0.0], [0.823314905166626, 0.06282395124435425, 0.03670429438352585, 0.07715693861246109, 0.0, 0.0], [0.8501748442649841, 0.03816927224397659, 0.03196492791175842, 0.0516013503074646, 0.02808968350291252, 0.0], [0.6572404503822327, 0.05877397954463959, 0.04336007311940193, 0.09013211727142334, 0.08146599680185318, 0.06902744621038437]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9162061810493469, 0.0837937667965889, 0.0, 0.0, 0.0, 0.0], [0.9451773762702942, 0.04099284112453461, 0.013829832896590233, 0.0, 0.0, 0.0], [0.8928355574607849, 0.05368670076131821, 0.017596954479813576, 0.03588071092963219, 0.0, 0.0], [0.8337052464485168, 0.04799601063132286, 0.033513229340314865, 0.04680858924984932, 0.03797686845064163, 0.0], [0.8167192339897156, 0.06337132304906845, 0.013286277651786804, 0.020469767972826958, 0.025292355567216873, 0.06086111441254616]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9525133371353149, 0.04748663306236267, 0.0, 0.0, 0.0, 0.0], [0.3019869327545166, 0.6520938873291016, 0.04591925069689751, 0.0, 0.0, 0.0], [0.285582959651947, 0.556952178478241, 0.1444743126630783, 0.012990524061024189, 0.0, 0.0], [0.843804121017456, 0.032251205295324326, 0.03954290598630905, 0.06848159432411194, 0.015920041128993034, 0.0], [0.6664940714836121, 0.06095913052558899, 0.04064354673027992, 0.06804485619068146, 0.09186329692602158, 0.07199501991271973]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9682655334472656, 0.031734466552734375, 0.0, 0.0, 0.0, 0.0], [0.738521933555603, 0.22856839001178741, 0.032909639179706573, 0.0, 0.0, 0.0], [0.5946676135063171, 0.2303314357995987, 0.14867636561393738, 0.02632458508014679, 0.0, 0.0], [0.6339254975318909, 0.05813034623861313, 0.09654320776462555, 0.14291946589946747, 0.06848153471946716, 0.0], [0.40375572443008423, 0.08945391327142715, 0.07635112851858139, 0.25587135553359985, 0.1433039754629135, 0.03126389905810356]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9869793653488159, 0.013020593672990799, 0.0, 0.0, 0.0, 0.0], [0.8631385564804077, 0.1105666309595108, 0.02629482001066208, 0.0, 0.0, 0.0], [0.9488080143928528, 0.028614996001124382, 0.006535546388477087, 0.016041526570916176, 0.0, 0.0], [0.9672170877456665, 0.006604980677366257, 0.00045171406236477196, 0.004844417329877615, 0.020881708711385727, 0.0], [0.9354621171951294, 0.02047806605696678, 0.0011700231116265059, 0.007056943140923977, 0.0163181871175766, 0.019514625892043114]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9846673011779785, 0.015332723967730999, 0.0, 0.0, 0.0, 0.0], [0.9052747488021851, 0.08373606950044632, 0.010989243164658546, 0.0, 0.0, 0.0], [0.8145939111709595, 0.04283742979168892, 0.10568301379680634, 0.03688570484519005, 0.0, 0.0], [0.23519809544086456, 0.012018457986414433, 0.05280117318034172, 0.6516180038452148, 0.04836418479681015, 0.0], [0.31818512082099915, 0.018632443621754646, 0.03948190063238144, 0.3755541741847992, 0.20787373185157776, 0.04027257487177849]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9811733365058899, 0.018826685845851898, 0.0, 0.0, 0.0, 0.0], [0.8618939518928528, 0.06479164958000183, 0.07331438362598419, 0.0, 0.0, 0.0], [0.7664540410041809, 0.07330425828695297, 0.10353513062000275, 0.056706514209508896, 0.0, 0.0], [0.8128499984741211, 0.03215480223298073, 0.059005625545978546, 0.05416511744260788, 0.04182446748018265, 0.0], [0.8687856197357178, 0.026987861841917038, 0.02047000452876091, 0.01629738137125969, 0.03218390792608261, 0.03527523949742317]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9264583587646484, 0.07354167848825455, 0.0, 0.0, 0.0, 0.0], [0.8403540849685669, 0.06373751163482666, 0.09590838104486465, 0.0, 0.0, 0.0], [0.7330995798110962, 0.06451118737459183, 0.10380073636770248, 0.09858842939138412, 0.0, 0.0], [0.9143612384796143, 0.008257776498794556, 0.007320381235331297, 0.017966248095035553, 0.05209439620375633, 0.0], [0.8971915245056152, 0.008555498905479908, 0.007019453682005405, 0.014860544353723526, 0.03399762138724327, 0.03837529569864273]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9180347919464111, 0.08196526020765305, 0.0, 0.0, 0.0, 0.0], [0.8328666687011719, 0.1219901517033577, 0.04514322429895401, 0.0, 0.0, 0.0], [0.7994157075881958, 0.0874413549900055, 0.03605784848332405, 0.07708510011434555, 0.0, 0.0], [0.880984902381897, 0.020749641582369804, 0.020554615184664726, 0.017120830714702606, 0.06058995798230171, 0.0], [0.745303213596344, 0.044334057718515396, 0.022549288347363472, 0.0331527441740036, 0.03357058763504028, 0.12109009176492691]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9867060780525208, 0.013293893076479435, 0.0, 0.0, 0.0, 0.0], [0.982177734375, 0.012414131313562393, 0.005408108700066805, 0.0, 0.0, 0.0], [0.9630486369132996, 0.015290752984583378, 0.010345698334276676, 0.0113149369135499, 0.0, 0.0], [0.9213568568229675, 0.014132463373243809, 0.017639216035604477, 0.016567690297961235, 0.030303770676255226, 0.0], [0.9373326301574707, 0.009064299054443836, 0.007548365276306868, 0.006576443091034889, 0.011827622540295124, 0.027650514617562294]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9951004385948181, 0.00489962799474597, 0.0, 0.0, 0.0, 0.0], [0.9476007223129272, 0.041407931596040726, 0.010991275310516357, 0.0, 0.0, 0.0], [0.9142175316810608, 0.023523783311247826, 0.039145033806562424, 0.023113621398806572, 0.0, 0.0], [0.9534738659858704, 0.008932933211326599, 0.015272765420377254, 0.007908251136541367, 0.014412266202270985, 0.0], [0.9427101016044617, 0.00823307130485773, 0.004650997929275036, 0.004178107250481844, 0.005463531706482172, 0.03476419299840927]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9543376564979553, 0.045662373304367065, 0.0, 0.0, 0.0, 0.0], [0.9696040749549866, 0.01954760029911995, 0.01084828469902277, 0.0, 0.0, 0.0], [0.9710449576377869, 0.012425386346876621, 0.008068876340985298, 0.008460716344416142, 0.0, 0.0], [0.9726192951202393, 0.002697656163945794, 0.00044831327977590263, 0.0013814778067171574, 0.022853154689073563, 0.0], [0.9675466418266296, 0.009613442234694958, 0.003203035332262516, 0.00424883933737874, 0.007442260626703501, 0.00794589426368475]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9887008666992188, 0.011299116536974907, 0.0, 0.0, 0.0, 0.0], [0.9382632374763489, 0.04204244911670685, 0.019694412127137184, 0.0, 0.0, 0.0], [0.8351995944976807, 0.03487853705883026, 0.05134471505880356, 0.07857715338468552, 0.0, 0.0], [0.9042676687240601, 0.010541575029492378, 0.016426723450422287, 0.025921987369656563, 0.04284200444817543, 0.0], [0.8913140892982483, 0.00891267228871584, 0.005010711494833231, 0.008175632916390896, 0.013514749705791473, 0.07307209819555283]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8693912029266357, 0.13060881197452545, 0.0, 0.0, 0.0, 0.0], [0.3507988452911377, 0.606351912021637, 0.04284917935729027, 0.0, 0.0, 0.0], [0.35475659370422363, 0.3502019941806793, 0.24722407758235931, 0.04781729355454445, 0.0, 0.0], [0.35370609164237976, 0.03527737781405449, 0.09567111730575562, 0.449796199798584, 0.06554921716451645, 0.0], [0.4132595360279083, 0.09055527299642563, 0.05286579951643944, 0.174679696559906, 0.173848956823349, 0.09479076415300369]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9629756212234497, 0.037024300545454025, 0.0, 0.0, 0.0, 0.0], [0.9756426811218262, 0.01965854875743389, 0.004698706325143576, 0.0, 0.0, 0.0], [0.9775736927986145, 0.013286248780786991, 0.0025590297300368547, 0.006581062916666269, 0.0, 0.0], [0.9870142936706543, 0.007388236932456493, 0.0009579154429957271, 0.0018318220973014832, 0.0028077505994588137, 0.0], [0.9409245848655701, 0.016633737832307816, 0.0022979143541306257, 0.0058906711637973785, 0.0055129327811300755, 0.02874022163450718]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.962827205657959, 0.037172831594944, 0.0, 0.0, 0.0, 0.0], [0.9582237601280212, 0.024641817435622215, 0.017134377732872963, 0.0, 0.0, 0.0], [0.9351300001144409, 0.015331573784351349, 0.014810982160270214, 0.034727465361356735, 0.0, 0.0], [0.9225171208381653, 0.010528750717639923, 0.011010154150426388, 0.01944003626704216, 0.036503832787275314, 0.0], [0.8420165777206421, 0.04357199743390083, 0.007488282397389412, 0.01496153138577938, 0.02385285682976246, 0.06810864061117172]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9926387071609497, 0.00736132962629199, 0.0, 0.0, 0.0, 0.0], [0.9957393407821655, 0.0033469819463789463, 0.000913690309971571, 0.0, 0.0, 0.0], [0.9869900345802307, 0.001974786864593625, 0.001524551771581173, 0.009510699659585953, 0.0, 0.0], [0.9933527708053589, 0.001020324882119894, 0.00034337223041802645, 0.0010291127255186439, 0.004254369530826807, 0.0], [0.9749016761779785, 0.00043480272870510817, 0.0004306558985263109, 0.0012364407302811742, 0.0015347707085311413, 0.021461669355630875]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9897475242614746, 0.010252462700009346, 0.0, 0.0, 0.0, 0.0], [0.9790639281272888, 0.01650906540453434, 0.0044270907528698444, 0.0, 0.0, 0.0], [0.9521436095237732, 0.029432358220219612, 0.008943161927163601, 0.009480923414230347, 0.0, 0.0], [0.939594030380249, 0.021510960534214973, 0.010278552770614624, 0.004555229097604752, 0.024061163887381554, 0.0], [0.9205074906349182, 0.016153652220964432, 0.010818594135344028, 0.01664440892636776, 0.014566398225724697, 0.021309375762939453]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9898501634597778, 0.010149780660867691, 0.0, 0.0, 0.0, 0.0], [0.9820910096168518, 0.006907520350068808, 0.011001535691320896, 0.0, 0.0, 0.0], [0.9684997200965881, 0.008987602777779102, 0.015342563390731812, 0.007170087192207575, 0.0, 0.0], [0.9274120330810547, 0.009485266171395779, 0.022066107019782066, 0.03222890570759773, 0.008807653561234474, 0.0], [0.900665819644928, 0.021623756736516953, 0.013808279298245907, 0.009843860752880573, 0.008521373383700848, 0.04553695768117905]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9954444169998169, 0.004555588588118553, 0.0, 0.0, 0.0, 0.0], [0.995254397392273, 0.002460238989442587, 0.002285485854372382, 0.0, 0.0, 0.0], [0.9862446188926697, 0.0015168144600465894, 0.004072288051247597, 0.008166354149580002, 0.0, 0.0], [0.9889963865280151, 0.001226040069013834, 0.0007996349013410509, 0.0006774227367714047, 0.008300574496388435, 0.0], [0.9865202903747559, 0.00039427157025784254, 0.0009571771952323616, 0.0004954367759637535, 0.0009604979422874749, 0.010672281496226788]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9821295142173767, 0.017870500683784485, 0.0, 0.0, 0.0, 0.0], [0.7489436268806458, 0.22002726793289185, 0.031029189005494118, 0.0, 0.0, 0.0], [0.28547799587249756, 0.21125678718090057, 0.47871601581573486, 0.024549242109060287, 0.0, 0.0], [0.8056644201278687, 0.026974644511938095, 0.04302806034684181, 0.06993705034255981, 0.05439583212137222, 0.0], [0.3307209014892578, 0.022326624020934105, 0.016627125442028046, 0.08019453287124634, 0.41574832797050476, 0.13438253104686737]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9697746634483337, 0.030225319787859917, 0.0, 0.0, 0.0, 0.0], [0.9800565838813782, 0.015018894337117672, 0.004924521781504154, 0.0, 0.0, 0.0], [0.9237861037254333, 0.052764780819416046, 0.00630240747705102, 0.017146753147244453, 0.0, 0.0], [0.9451844096183777, 0.03618047758936882, 0.001989208161830902, 0.003958724904805422, 0.012687299400568008, 0.0], [0.9633325934410095, 0.018662991002202034, 0.0030418417882174253, 0.007070912979543209, 0.0050094155594706535, 0.002882065251469612]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9873244762420654, 0.012675459496676922, 0.0, 0.0, 0.0, 0.0], [0.9904569983482361, 0.0055419523268938065, 0.004001122899353504, 0.0, 0.0, 0.0], [0.9814971685409546, 0.004653455223888159, 0.003725277027115226, 0.010124054737389088, 0.0, 0.0], [0.9744365811347961, 0.004632251337170601, 0.002379992976784706, 0.006518087349832058, 0.012033028528094292, 0.0], [0.9624497294425964, 0.0033743639942258596, 0.0013198587112128735, 0.0017275003483518958, 0.002944675739854574, 0.028183799237012863]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9807674288749695, 0.01923258602619171, 0.0, 0.0, 0.0, 0.0], [0.9664245843887329, 0.015413926914334297, 0.018161438405513763, 0.0, 0.0, 0.0], [0.9632682204246521, 0.004538117907941341, 0.002925391308963299, 0.029268190264701843, 0.0, 0.0], [0.9562349319458008, 0.0012223608791828156, 0.0005304080550558865, 0.00867149606347084, 0.03334089741110802, 0.0], [0.9657101035118103, 0.0009808284230530262, 0.0016686266753822565, 0.002634831238538027, 0.005866361316293478, 0.023139292374253273]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9639716148376465, 0.036028459668159485, 0.0, 0.0, 0.0, 0.0], [0.9562800526618958, 0.03373315557837486, 0.009986846707761288, 0.0, 0.0, 0.0], [0.8539998531341553, 0.08073022216558456, 0.03334445133805275, 0.031925540417432785, 0.0, 0.0], [0.9547491073608398, 0.009605025872588158, 0.004146162886172533, 0.0020133228972554207, 0.029486361891031265, 0.0], [0.9331137537956238, 0.028699662536382675, 0.005477475933730602, 0.006368075497448444, 0.012613046914339066, 0.013728085905313492]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9392993450164795, 0.06070063263177872, 0.0, 0.0, 0.0, 0.0], [0.9298391342163086, 0.061895377933979034, 0.008265496231615543, 0.0, 0.0, 0.0], [0.8471823334693909, 0.09035038203001022, 0.01763608679175377, 0.044831156730651855, 0.0, 0.0], [0.8857703804969788, 0.03918175399303436, 0.007867704145610332, 0.02276589721441269, 0.04441439360380173, 0.0], [0.8563280701637268, 0.10088995099067688, 0.006531452294439077, 0.008485927246510983, 0.007368441205471754, 0.020396249368786812]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8353264331817627, 0.1646735519170761, 0.0, 0.0, 0.0, 0.0], [0.6160858869552612, 0.3137648403644562, 0.07014927268028259, 0.0, 0.0, 0.0], [0.34316325187683105, 0.2758493721485138, 0.1196604073047638, 0.26132699847221375, 0.0, 0.0], [0.5908172130584717, 0.050290752202272415, 0.041665926575660706, 0.2199493646621704, 0.0972767099738121, 0.0], [0.8481413125991821, 0.06318090111017227, 0.014733693562448025, 0.055267371237277985, 0.00901501253247261, 0.009661628864705563]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9627319574356079, 0.03726799786090851, 0.0, 0.0, 0.0, 0.0], [0.7757522463798523, 0.1799626499414444, 0.044285036623477936, 0.0, 0.0, 0.0], [0.6317060589790344, 0.24380716681480408, 0.10925652086734772, 0.015230235643684864, 0.0, 0.0], [0.9539909958839417, 0.018182311207056046, 0.011601822450757027, 0.012299076654016972, 0.003925766795873642, 0.0], [0.40356943011283875, 0.14237558841705322, 0.05661217123270035, 0.1975736767053604, 0.0929921343922615, 0.10687707364559174]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9802619218826294, 0.019738124683499336, 0.0, 0.0, 0.0, 0.0], [0.9873908162117004, 0.007800452411174774, 0.004808681085705757, 0.0, 0.0, 0.0], [0.9283918738365173, 0.008301235735416412, 0.01330565195530653, 0.05000120773911476, 0.0, 0.0], [0.8981055021286011, 0.015591299161314964, 0.010177576914429665, 0.039987027645111084, 0.0361386202275753, 0.0], [0.9753499031066895, 0.00035433052107691765, 0.0005866039427928627, 0.0011877501383423805, 0.0010750899091362953, 0.021446440368890762]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9295330047607422, 0.07046692818403244, 0.0, 0.0, 0.0, 0.0], [0.9361506104469299, 0.04116682708263397, 0.022682538256049156, 0.0, 0.0, 0.0], [0.8486821055412292, 0.05802798643708229, 0.024856165051460266, 0.0684337466955185, 0.0, 0.0], [0.8661180734634399, 0.02232467755675316, 0.010369130410254002, 0.02600197121500969, 0.07518619298934937, 0.0], [0.8074421882629395, 0.044382549822330475, 0.01849711686372757, 0.03357789292931557, 0.018561245873570442, 0.07753907144069672]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9680535197257996, 0.03194643557071686, 0.0, 0.0, 0.0, 0.0], [0.9693689942359924, 0.02568492479622364, 0.004946070723235607, 0.0, 0.0, 0.0], [0.9620568156242371, 0.022552406415343285, 0.005471326876431704, 0.009919456206262112, 0.0, 0.0], [0.9727528095245361, 0.010137127712368965, 0.000757327419705689, 0.0028828983195126057, 0.013469807803630829, 0.0], [0.9624635577201843, 0.0031109037809073925, 0.0010007602395489812, 0.0019475930603221059, 0.008266227319836617, 0.02321087196469307]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8542501330375671, 0.14574992656707764, 0.0, 0.0, 0.0, 0.0], [0.9725967645645142, 0.014116315171122551, 0.01328685600310564, 0.0, 0.0, 0.0], [0.9257621765136719, 0.03257262706756592, 0.01461210660636425, 0.027053095400333405, 0.0, 0.0], [0.7923423051834106, 0.027305101975798607, 0.01880674995481968, 0.13854165375232697, 0.023004096001386642, 0.0], [0.6152060627937317, 0.02665526419878006, 0.029352931305766106, 0.05590886250138283, 0.11611279845237732, 0.15676409006118774]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9804654121398926, 0.019534552469849586, 0.0, 0.0, 0.0, 0.0], [0.9882452487945557, 0.007509466726332903, 0.004245325922966003, 0.0, 0.0, 0.0], [0.9584206938743591, 0.0109635591506958, 0.010456060990691185, 0.020159708335995674, 0.0, 0.0], [0.9604811668395996, 0.007182627450674772, 0.003072339342907071, 0.006898913532495499, 0.02236509881913662, 0.0], [0.966888964176178, 0.0032812939025461674, 0.00550054432824254, 0.004234083462506533, 0.005038043484091759, 0.015057181939482689]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9498194456100464, 0.05018055811524391, 0.0, 0.0, 0.0, 0.0], [0.9781363606452942, 0.016430046409368515, 0.0054335566237568855, 0.0, 0.0, 0.0], [0.8618696331977844, 0.036093585193157196, 0.07555554062128067, 0.026481209322810173, 0.0, 0.0], [0.5449837446212769, 0.015411133877933025, 0.023516526445746422, 0.25743600726127625, 0.15865260362625122, 0.0], [0.9571874737739563, 0.0030803855042904615, 0.0014446862041950226, 0.006861559115350246, 0.014818714000284672, 0.01660723052918911]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6156560778617859, 0.3843439519405365, 0.0, 0.0, 0.0, 0.0], [0.36760634183883667, 0.42816370725631714, 0.20423001050949097, 0.0, 0.0, 0.0], [0.16471554338932037, 0.4136792719364166, 0.2509237229824066, 0.17068152129650116, 0.0, 0.0], [0.4184456169605255, 0.1524762362241745, 0.10305401682853699, 0.11071498692035675, 0.21530911326408386, 0.0], [0.19686934351921082, 0.2014620453119278, 0.12827259302139282, 0.09203246980905533, 0.09167550504207611, 0.2896881103515625]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9027364253997803, 0.09726352989673615, 0.0, 0.0, 0.0, 0.0], [0.9736634492874146, 0.014004302211105824, 0.01233230996876955, 0.0, 0.0, 0.0], [0.8504456281661987, 0.05690572410821915, 0.032060906291007996, 0.06058764085173607, 0.0, 0.0], [0.7661210298538208, 0.03530392050743103, 0.03433045372366905, 0.09675204753875732, 0.06749245524406433, 0.0], [0.8650374412536621, 0.020085260272026062, 0.01149806659668684, 0.01855834573507309, 0.018430285155773163, 0.06639053672552109]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9653082489967346, 0.03469168767333031, 0.0, 0.0, 0.0, 0.0], [0.9816323518753052, 0.014176066033542156, 0.004191514104604721, 0.0, 0.0, 0.0], [0.9275256395339966, 0.04737218841910362, 0.01152826938778162, 0.013573966920375824, 0.0, 0.0], [0.9293117523193359, 0.025833239778876305, 0.007227106485515833, 0.014300585724413395, 0.02332727052271366, 0.0], [0.8895062804222107, 0.04689619690179825, 0.0047171092592179775, 0.006286581978201866, 0.00609014043584466, 0.04650374501943588]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8938026428222656, 0.10619727522134781, 0.0, 0.0, 0.0, 0.0], [0.8221707940101624, 0.06304481625556946, 0.11478441953659058, 0.0, 0.0, 0.0], [0.5047380924224854, 0.15375731885433197, 0.2277037501335144, 0.11380083113908768, 0.0, 0.0], [0.4082071781158447, 0.09066355973482132, 0.11696872115135193, 0.24553199112415314, 0.13862857222557068, 0.0], [0.7291035652160645, 0.06638889014720917, 0.023112818598747253, 0.031103096902370453, 0.057143256068229675, 0.09314827620983124]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9247531890869141, 0.07524678111076355, 0.0, 0.0, 0.0, 0.0], [0.8957376480102539, 0.06989553570747375, 0.03436679765582085, 0.0, 0.0, 0.0], [0.7924937605857849, 0.0960114598274231, 0.05509118735790253, 0.056403566151857376, 0.0, 0.0], [0.7891505360603333, 0.07880303263664246, 0.03840155899524689, 0.05396979674696922, 0.03967496380209923, 0.0], [0.7807856798171997, 0.0799354612827301, 0.042531758546829224, 0.03234211727976799, 0.0178169384598732, 0.046588052064180374]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9480886459350586, 0.05191127583384514, 0.0, 0.0, 0.0, 0.0], [0.863694965839386, 0.04756204038858414, 0.08874296396970749, 0.0, 0.0, 0.0], [0.9341371059417725, 0.022224076092243195, 0.022624483332037926, 0.021014342084527016, 0.0, 0.0], [0.9588143229484558, 0.008020909503102303, 0.004490078426897526, 0.005862293299287558, 0.022812429815530777, 0.0], [0.9385918378829956, 0.021227721124887466, 0.0048724692314863205, 0.010940189473330975, 0.009524582885205746, 0.014843451790511608]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9763734340667725, 0.023626558482646942, 0.0, 0.0, 0.0, 0.0], [0.9884802103042603, 0.005189393647015095, 0.0063303736969828606, 0.0, 0.0, 0.0], [0.9477092027664185, 0.0179851483553648, 0.010156610049307346, 0.024149026721715927, 0.0, 0.0], [0.967192530632019, 0.006552813574671745, 0.0033227826934307814, 0.00556332478299737, 0.017368387430906296, 0.0], [0.9584562182426453, 0.007502961438149214, 0.0051363310776650906, 0.008071648888289928, 0.005997124593704939, 0.014835843816399574]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.884070873260498, 0.11592914164066315, 0.0, 0.0, 0.0, 0.0], [0.9931254386901855, 0.005070806015282869, 0.0018038019770756364, 0.0, 0.0, 0.0], [0.9534159302711487, 0.02382904477417469, 0.007748977281153202, 0.015006075613200665, 0.0, 0.0], [0.9151289463043213, 0.010873105376958847, 0.013190957717597485, 0.011050421744585037, 0.04975655674934387, 0.0], [0.8769673109054565, 0.03385210782289505, 0.00848648976534605, 0.009969149716198444, 0.03468578681349754, 0.036039214581251144]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0003709519514814019, 0.999629020690918, 0.0, 0.0, 0.0, 0.0], [6.525027856696397e-05, 0.3737829029560089, 0.6261518597602844, 0.0, 0.0, 0.0], [4.606018774211407e-05, 0.210508793592453, 0.4115968942642212, 0.3778482675552368, 0.0, 0.0], [4.753069515572861e-05, 0.11616954207420349, 0.23264272511005402, 0.3985331058502197, 0.2526070475578308, 0.0], [1.247641534973809e-06, 0.14819711446762085, 0.15813173353672028, 0.30074331164360046, 0.11939018964767456, 0.27353641390800476]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.971555769443512, 0.028444187715649605, 0.0, 0.0, 0.0, 0.0], [0.9529065489768982, 0.03233075141906738, 0.014762768521904945, 0.0, 0.0, 0.0], [0.9343128204345703, 0.02351292595267296, 0.02049802988767624, 0.021676240488886833, 0.0, 0.0], [0.9529678225517273, 0.00855141133069992, 0.004359325394034386, 0.008064556866884232, 0.026056913658976555, 0.0], [0.9653593897819519, 0.008487647399306297, 0.003499280195683241, 0.002721576252952218, 0.0032828773837536573, 0.016649367287755013]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8630780577659607, 0.13692188262939453, 0.0, 0.0, 0.0, 0.0], [0.7696157097816467, 0.0851333811879158, 0.14525099098682404, 0.0, 0.0, 0.0], [0.7133337259292603, 0.10170899331569672, 0.11931268870830536, 0.06564456224441528, 0.0, 0.0], [0.7186222076416016, 0.05444284901022911, 0.01386815495789051, 0.07808027416467667, 0.13498654961585999, 0.0], [0.7990148663520813, 0.05805593729019165, 0.009447019547224045, 0.017770467326045036, 0.02113853208720684, 0.09457314014434814]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9518988728523254, 0.048101115971803665, 0.0, 0.0, 0.0, 0.0], [0.8580653071403503, 0.02944577857851982, 0.11248888075351715, 0.0, 0.0, 0.0], [0.6577738523483276, 0.08513449877500534, 0.1261308640241623, 0.1309608370065689, 0.0, 0.0], [0.8087368607521057, 0.0323016420006752, 0.01841817982494831, 0.06856140494346619, 0.07198194414377213, 0.0], [0.6683295965194702, 0.13281384110450745, 0.021880635991692543, 0.02787741646170616, 0.04923408478498459, 0.0998644009232521]]]], \"left_text\": [\"No\", \",\", \" I\", \" am\", \" your\", \" father\"], \"right_text\": [\"No\", \",\", \" I\", \" am\", \" your\", \" father\"]}], \"default_filter\": \"0\", \"display_mode\": \"dark\", \"root_div_id\": \"bertviz-300f38de2d1b4e66a8cc391d887f8db3\", \"include_layers\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], \"include_heads\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], \"total_heads\": 12}; // HACK: {\"attention\": [{\"name\": null, \"attn\": [[[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.961219847202301, 0.038780149072408676, 0.0, 0.0, 0.0, 0.0], [0.7466979026794434, 0.11987314373254776, 0.1334289014339447, 0.0, 0.0, 0.0], [0.5885030031204224, 0.13792067766189575, 0.212137371301651, 0.06143897399306297, 0.0, 0.0], [0.6570857763290405, 0.08996301889419556, 0.12751281261444092, 0.08361563086509705, 0.041822850704193115, 0.0], [0.2728874385356903, 0.11203353852033615, 0.1663985401391983, 0.08467111736536026, 0.16952736675739288, 0.19448210299015045]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.010616563260555267, 0.9893833994865417, 0.0, 0.0, 0.0, 0.0], [0.0024677535984665155, 0.008448007516562939, 0.9890841841697693, 0.0, 0.0, 0.0], [0.0001232847134815529, 0.0018733182223513722, 0.013126976788043976, 0.9848763942718506, 0.0, 0.0], [0.0010669564362615347, 0.001136627048254013, 0.003034998197108507, 0.0015735096530988812, 0.9931879043579102, 0.0], [0.00019791982776951045, 0.0010528112761676311, 0.0015437351539731026, 0.0009642760851420462, 3.4924432839034125e-05, 0.9962062835693359]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.47578439116477966, 0.524215579032898, 0.0, 0.0, 0.0, 0.0], [0.5906045436859131, 0.2486611008644104, 0.16073434054851532, 0.0, 0.0, 0.0], [0.5529289841651917, 0.18856702744960785, 0.14457571506500244, 0.11392831057310104, 0.0, 0.0], [0.45094072818756104, 0.16486799716949463, 0.17318038642406464, 0.11748014390468597, 0.09353074431419373, 0.0], [0.4257245659828186, 0.1732865273952484, 0.15651953220367432, 0.07022649794816971, 0.0808701142668724, 0.09337282180786133]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6133623123168945, 0.38663768768310547, 0.0, 0.0, 0.0, 0.0], [0.06098509579896927, 0.03253461793065071, 0.9064802527427673, 0.0, 0.0, 0.0], [0.006717085838317871, 0.0004012881254311651, 0.7572958469390869, 0.23558568954467773, 0.0, 0.0], [0.03722766041755676, 0.002948855282738805, 0.10081092268228531, 0.04142269119620323, 0.8175898790359497, 0.0], [0.04989781975746155, 0.00030758307548239827, 0.0024198265746235847, 0.0034334994852542877, 0.0006823898293077946, 0.9432588815689087]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9489555954933167, 0.051044441759586334, 0.0, 0.0, 0.0, 0.0], [0.6821408867835999, 0.1395241767168045, 0.17833495140075684, 0.0, 0.0, 0.0], [0.20366324484348297, 0.05641487240791321, 0.06399301439523697, 0.6759288311004639, 0.0, 0.0], [0.3419547975063324, 0.06725440919399261, 0.07926183938980103, 0.1783619523048401, 0.3331669867038727, 0.0], [0.09464015811681747, 0.0074282134883105755, 0.006983973551541567, 0.0071843694895505905, 0.018724264577031136, 0.865039050579071]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.33834606409072876, 0.6616539359092712, 0.0, 0.0, 0.0, 0.0], [0.07855993509292603, 0.006165449041873217, 0.9152746200561523, 0.0, 0.0, 0.0], [0.01677597686648369, 0.0004037705948576331, 0.003340460592880845, 0.9794798493385315, 0.0, 0.0], [0.027600426226854324, 0.00044415233423933387, 0.0006541680195368826, 0.0002266185765620321, 0.971074640750885, 0.0], [0.010248198173940182, 3.701553578139283e-05, 0.00016064041119534522, 2.7341819077264518e-05, 1.0187304724240676e-05, 0.98951655626297]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.982503354549408, 0.017496665939688683, 0.0, 0.0, 0.0, 0.0], [0.8874197006225586, 0.05467939004302025, 0.05790085718035698, 0.0, 0.0, 0.0], [0.6849910616874695, 0.1228068619966507, 0.04972026124596596, 0.14248186349868774, 0.0, 0.0], [0.6015856862068176, 0.09881888329982758, 0.07070108503103256, 0.16652540862560272, 0.06236903741955757, 0.0], [0.3232504427433014, 0.12567411363124847, 0.04432179778814316, 0.07076980918645859, 0.06606649607419968, 0.36991727352142334]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9191647171974182, 0.0808352455496788, 0.0, 0.0, 0.0, 0.0], [0.45986413955688477, 0.39703112840652466, 0.14310479164123535, 0.0, 0.0, 0.0], [0.3003872334957123, 0.22181738913059235, 0.38161516189575195, 0.09618020057678223, 0.0, 0.0], [0.18963925540447235, 0.1376371532678604, 0.20173484086990356, 0.23632164299488068, 0.23466713726520538, 0.0], [0.15410441160202026, 0.09489496797323227, 0.11902562528848648, 0.10277965664863586, 0.4317220449447632, 0.09747327119112015]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.364999920129776, 0.6350001096725464, 0.0, 0.0, 0.0, 0.0], [0.24595215916633606, 0.5519201755523682, 0.20212766528129578, 0.0, 0.0, 0.0], [0.2721358835697174, 0.40738627314567566, 0.25186213850975037, 0.06861574947834015, 0.0, 0.0], [0.10242555290460587, 0.16683615744113922, 0.524804949760437, 0.05445462837815285, 0.15147870779037476, 0.0], [0.25029507279396057, 0.22198128700256348, 0.18899968266487122, 0.10677118599414825, 0.1303267478942871, 0.10162602365016937]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6990506649017334, 0.3009493350982666, 0.0, 0.0, 0.0, 0.0], [0.5107942819595337, 0.2948642075061798, 0.1943415403366089, 0.0, 0.0, 0.0], [0.4604707360267639, 0.2805190980434418, 0.19174803793430328, 0.0672621801495552, 0.0, 0.0], [0.37648412585258484, 0.21120662987232208, 0.20214538276195526, 0.10207021236419678, 0.10809355974197388, 0.0], [0.30138441920280457, 0.20456179976463318, 0.18250338733196259, 0.11019382625818253, 0.1629127413034439, 0.03844383731484413]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7131582498550415, 0.2868417799472809, 0.0, 0.0, 0.0, 0.0], [0.4058799147605896, 0.18063297867774963, 0.41348710656166077, 0.0, 0.0, 0.0], [0.265546053647995, 0.1698586493730545, 0.3358593285083771, 0.228736013174057, 0.0, 0.0], [0.31385406851768494, 0.1831669807434082, 0.14928358793258667, 0.05377671495079994, 0.29991865158081055, 0.0], [0.20466560125350952, 0.18731118738651276, 0.15959151089191437, 0.06381776183843613, 0.03642302006483078, 0.34819093346595764]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6586242914199829, 0.3413757383823395, 0.0, 0.0, 0.0, 0.0], [0.5917776226997375, 0.3160035014152527, 0.0922188088297844, 0.0, 0.0, 0.0], [0.5477152466773987, 0.23586955666542053, 0.061456020921468735, 0.1549593061208725, 0.0, 0.0], [0.4587061107158661, 0.22439992427825928, 0.07887422293424606, 0.0992034301161766, 0.13881628215312958, 0.0], [0.32743722200393677, 0.19600819051265717, 0.068057119846344, 0.0892510637640953, 0.11618079245090485, 0.20306548476219177]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9961552023887634, 0.0038448425475507975, 0.0, 0.0, 0.0, 0.0], [0.8594854474067688, 0.06906110048294067, 0.07145342975854874, 0.0, 0.0, 0.0], [0.3800053000450134, 0.04127567633986473, 0.5496612787246704, 0.029057776555418968, 0.0, 0.0], [0.21445226669311523, 0.05088742449879646, 0.4317440092563629, 0.25869303941726685, 0.044223275035619736, 0.0], [0.11175256222486496, 0.017593080177903175, 0.027507441118359566, 0.04086771607398987, 0.7754669785499573, 0.026812179014086723]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9285967946052551, 0.07140326499938965, 0.0, 0.0, 0.0, 0.0], [0.6077286005020142, 0.3121427297592163, 0.08012867718935013, 0.0, 0.0, 0.0], [0.4942909777164459, 0.28503698110580444, 0.11849315464496613, 0.10217894613742828, 0.0, 0.0], [0.4183879494667053, 0.23117904365062714, 0.0834062322974205, 0.11365949362516403, 0.1533672958612442, 0.0], [0.42215850949287415, 0.12917140126228333, 0.08740927278995514, 0.1016375944018364, 0.21230268478393555, 0.04732053726911545]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9786475896835327, 0.02135237120091915, 0.0, 0.0, 0.0, 0.0], [0.7749121785163879, 0.06510371714830399, 0.15998409688472748, 0.0, 0.0, 0.0], [0.6484923362731934, 0.07483134418725967, 0.14751605689525604, 0.12916021049022675, 0.0, 0.0], [0.5224639773368835, 0.06921815127134323, 0.13823404908180237, 0.1110658198595047, 0.15901805460453033, 0.0], [0.3964517116546631, 0.07325823605060577, 0.12938153743743896, 0.1064242571592331, 0.14864002168178558, 0.1458442211151123]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5525906085968018, 0.44740936160087585, 0.0, 0.0, 0.0, 0.0], [0.5585009455680847, 0.2176259458065033, 0.22387312352657318, 0.0, 0.0, 0.0], [0.5143128633499146, 0.15964674949645996, 0.15491968393325806, 0.1711207628250122, 0.0, 0.0], [0.5039961338043213, 0.11401888728141785, 0.11974027007818222, 0.12552587687969208, 0.13671889901161194, 0.0], [0.5061842799186707, 0.08567393571138382, 0.08903021365404129, 0.09759818762540817, 0.1027572825551033, 0.11875619739294052]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9242545366287231, 0.07574543356895447, 0.0, 0.0, 0.0, 0.0], [0.8257425427436829, 0.07932533323764801, 0.09493216127157211, 0.0, 0.0, 0.0], [0.7306380271911621, 0.0857183039188385, 0.08043931424617767, 0.10320431739091873, 0.0, 0.0], [0.6383238434791565, 0.07886394113302231, 0.07815027981996536, 0.08758097141981125, 0.1170809343457222, 0.0], [0.5552157163619995, 0.07409121096134186, 0.06834889203310013, 0.07778600603342056, 0.09999319165945053, 0.12456497550010681]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8578913807868958, 0.14210854470729828, 0.0, 0.0, 0.0, 0.0], [0.6423038244247437, 0.166290283203125, 0.19140593707561493, 0.0, 0.0, 0.0], [0.5530979633331299, 0.10609274357557297, 0.07821257412433624, 0.26259663701057434, 0.0, 0.0], [0.40121692419052124, 0.12223611027002335, 0.1934729963541031, 0.14164622128009796, 0.14142780005931854, 0.0], [0.40212565660476685, 0.18450751900672913, 0.07516805827617645, 0.05849048122763634, 0.1444634348154068, 0.13524490594863892]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9791558980941772, 0.020844051614403725, 0.0, 0.0, 0.0, 0.0], [0.8829841613769531, 0.06233249977231026, 0.05468335747718811, 0.0, 0.0, 0.0], [0.8105455040931702, 0.08617085963487625, 0.07321777194738388, 0.03006584383547306, 0.0, 0.0], [0.6819812059402466, 0.04990820586681366, 0.08296552300453186, 0.08369525521993637, 0.10144983977079391, 0.0], [0.4056689441204071, 0.07337666302919388, 0.08601408451795578, 0.061709366738796234, 0.13226434588432312, 0.2409665435552597]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9670190811157227, 0.03298088163137436, 0.0, 0.0, 0.0, 0.0], [0.8449064493179321, 0.0851450264453888, 0.06994850933551788, 0.0, 0.0, 0.0], [0.7123572826385498, 0.07896047830581665, 0.055410757660865784, 0.15327158570289612, 0.0, 0.0], [0.6402613520622253, 0.0739755630493164, 0.044393062591552734, 0.14322125911712646, 0.09814881533384323, 0.0], [0.5073903799057007, 0.07523059099912643, 0.07754647731781006, 0.11362491548061371, 0.13947951793670654, 0.08672808855772018]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8487569093704224, 0.1512431502342224, 0.0, 0.0, 0.0, 0.0], [0.8415648937225342, 0.12107233703136444, 0.03736274689435959, 0.0, 0.0, 0.0], [0.7505517601966858, 0.11348944902420044, 0.06179959326982498, 0.07415912300348282, 0.0, 0.0], [0.6614719033241272, 0.10242646187543869, 0.052934251725673676, 0.07529708743095398, 0.10787025839090347, 0.0], [0.6014202237129211, 0.11340376734733582, 0.05631929263472557, 0.07096721231937408, 0.10906282067298889, 0.04882663115859032]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9445484280586243, 0.05545158311724663, 0.0, 0.0, 0.0, 0.0], [0.8874568939208984, 0.05474215745925903, 0.0578010231256485, 0.0, 0.0, 0.0], [0.8281888961791992, 0.06895001977682114, 0.059034693986177444, 0.0438263975083828, 0.0, 0.0], [0.6429892778396606, 0.0674755647778511, 0.11629703640937805, 0.05417950078845024, 0.11905858665704727, 0.0], [0.7367823719978333, 0.056119054555892944, 0.06857288628816605, 0.034219540655612946, 0.0787537544965744, 0.02555238828063011]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0002913394710049033, 0.9997085928916931, 0.0, 0.0, 0.0, 0.0], [0.0007981209782883525, 0.5288336873054504, 0.4703682065010071, 0.0, 0.0, 0.0], [0.0007648481405340135, 0.34519824385643005, 0.3085267245769501, 0.34551018476486206, 0.0, 0.0], [0.0010283143492415547, 0.241359144449234, 0.23320138454437256, 0.2555713355541229, 0.2688397467136383, 0.0], [0.0009746829164214432, 0.17789699137210846, 0.16743157804012299, 0.1858760118484497, 0.18734444677829742, 0.28047630190849304]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.824492871761322, 0.17550717294216156, 0.0, 0.0, 0.0, 0.0], [0.12386877834796906, 0.044499922543764114, 0.8316312432289124, 0.0, 0.0, 0.0], [0.07924355566501617, 0.01296587660908699, 0.0015277155907824636, 0.9062628149986267, 0.0, 0.0], [0.08806384354829788, 0.0213409923017025, 0.0028886159416288137, 0.002845379989594221, 0.884861171245575, 0.0], [0.09983218461275101, 0.03363388776779175, 0.0054999832063913345, 0.002433052286505699, 0.0015082412865012884, 0.8570926189422607]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9646892547607422, 0.03531072288751602, 0.0, 0.0, 0.0, 0.0], [0.7529157400131226, 0.08733473718166351, 0.15974950790405273, 0.0, 0.0, 0.0], [0.4202282726764679, 0.09195102006196976, 0.23549850285053253, 0.25232216715812683, 0.0, 0.0], [0.30848920345306396, 0.05908140912652016, 0.38391315937042236, 0.15659146010875702, 0.09192468225955963, 0.0], [0.44790443778038025, 0.04329312965273857, 0.0796918049454689, 0.11081931740045547, 0.22124572098255157, 0.09704558551311493]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.991096019744873, 0.008904009126126766, 0.0, 0.0, 0.0, 0.0], [0.9697675704956055, 0.026084503158926964, 0.004147922620177269, 0.0, 0.0, 0.0], [0.9082901477813721, 0.033206019550561905, 0.00942116230726242, 0.049082688987255096, 0.0, 0.0], [0.8949133157730103, 0.05544555187225342, 0.005577624775469303, 0.03150692582130432, 0.012556522153317928, 0.0], [0.8497740030288696, 0.028890123590826988, 0.0036647915840148926, 0.03751987963914871, 0.038427725434303284, 0.04172350466251373]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9984525442123413, 0.0015474462416023016, 0.0, 0.0, 0.0, 0.0], [0.48947831988334656, 0.4812193810939789, 0.029302269220352173, 0.0, 0.0, 0.0], [0.11772153526544571, 0.13121186196804047, 0.6702314615249634, 0.08083520829677582, 0.0, 0.0], [0.13043689727783203, 0.04068669304251671, 0.2652038037776947, 0.4114362895488739, 0.15223638713359833, 0.0], [0.12661904096603394, 0.03275119513273239, 0.03567872568964958, 0.06039190664887428, 0.6021825075149536, 0.1423766165971756]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9805176854133606, 0.019482342526316643, 0.0, 0.0, 0.0, 0.0], [0.7948849201202393, 0.12061909586191177, 0.08449601382017136, 0.0, 0.0, 0.0], [0.5612356066703796, 0.15743127465248108, 0.20339730381965637, 0.0779358446598053, 0.0, 0.0], [0.42583736777305603, 0.10742014646530151, 0.15123659372329712, 0.08755031228065491, 0.22795552015304565, 0.0], [0.24752654135227203, 0.024188270792365074, 0.03039524517953396, 0.08586956560611725, 0.5714336633682251, 0.040586672723293304]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9887767434120178, 0.011223225854337215, 0.0, 0.0, 0.0, 0.0], [0.7572693228721619, 0.22317346930503845, 0.019557112827897072, 0.0, 0.0, 0.0], [0.5341880321502686, 0.22107566893100739, 0.1762184202671051, 0.06851787120103836, 0.0, 0.0], [0.17095312476158142, 0.0822940468788147, 0.576022207736969, 0.11097585409879684, 0.059754710644483566, 0.0], [0.2487109899520874, 0.08880793303251266, 0.08980197459459305, 0.09729334712028503, 0.4413093626499176, 0.03407646715641022]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8422133326530457, 0.15778663754463196, 0.0, 0.0, 0.0, 0.0], [0.468412846326828, 0.46105360984802246, 0.07053359597921371, 0.0, 0.0, 0.0], [0.2588140666484833, 0.4635888636112213, 0.18503506481647491, 0.09256205707788467, 0.0, 0.0], [0.18399578332901, 0.29154160618782043, 0.17031098902225494, 0.27173006534576416, 0.08242159336805344, 0.0], [0.1646990180015564, 0.2472696155309677, 0.08770562708377838, 0.22575001418590546, 0.1774536371231079, 0.09712201356887817]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9919946193695068, 0.008005390875041485, 0.0, 0.0, 0.0, 0.0], [0.9068724513053894, 0.044065121561288834, 0.04906242713332176, 0.0, 0.0, 0.0], [0.8582221865653992, 0.055348269641399384, 0.040419407188892365, 0.046010036021471024, 0.0, 0.0], [0.7855252623558044, 0.041242364794015884, 0.08369296044111252, 0.04887620359659195, 0.040663279592990875, 0.0], [0.7856317162513733, 0.05014643445611, 0.04751267284154892, 0.027365952730178833, 0.05614755302667618, 0.03319567069411278]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9041035175323486, 0.09589648246765137, 0.0, 0.0, 0.0, 0.0], [0.5862312912940979, 0.07199832051992416, 0.34177035093307495, 0.0, 0.0, 0.0], [0.3878960907459259, 0.04660807177424431, 0.20278996229171753, 0.36270591616630554, 0.0, 0.0], [0.2665242552757263, 0.024533024057745934, 0.12211935967206955, 0.20041218400001526, 0.386411190032959, 0.0], [0.23357485234737396, 0.02053728699684143, 0.09610321372747421, 0.13062246143817902, 0.22990450263023376, 0.289257675409317]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9639912247657776, 0.036008793860673904, 0.0, 0.0, 0.0, 0.0], [0.7075552344322205, 0.2542775869369507, 0.038167137652635574, 0.0, 0.0, 0.0], [0.2566526234149933, 0.20589298009872437, 0.01665665954351425, 0.5207977294921875, 0.0, 0.0], [0.1037939190864563, 0.04639088362455368, 0.008698614314198494, 0.7866851687431335, 0.05443140119314194, 0.0], [0.2214341163635254, 0.03379744663834572, 0.029023902490735054, 0.541292130947113, 0.15286092460155487, 0.021591555327177048]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9891703724861145, 0.010829661041498184, 0.0, 0.0, 0.0, 0.0], [0.7913155555725098, 0.12309625744819641, 0.08558809012174606, 0.0, 0.0, 0.0], [0.2954600155353546, 0.15808308124542236, 0.4217240810394287, 0.1247328370809555, 0.0, 0.0], [0.23440983891487122, 0.09886523336172104, 0.33160170912742615, 0.1971396654844284, 0.1379835456609726, 0.0], [0.19728390872478485, 0.05741839483380318, 0.06909029185771942, 0.16469819843769073, 0.2797277867794037, 0.23178131878376007]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9359127879142761, 0.0640871673822403, 0.0, 0.0, 0.0, 0.0], [0.7888627648353577, 0.08673475682735443, 0.12440246343612671, 0.0, 0.0, 0.0], [0.6535118818283081, 0.07573551684617996, 0.09732568264007568, 0.17342689633369446, 0.0, 0.0], [0.522276759147644, 0.058278825134038925, 0.09920477122068405, 0.17020836472511292, 0.15003129839897156, 0.0], [0.4108840823173523, 0.047306034713983536, 0.07265672832727432, 0.10560744255781174, 0.10550004243850708, 0.25804558396339417]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9683833122253418, 0.03161672502756119, 0.0, 0.0, 0.0, 0.0], [0.8965396881103516, 0.038870569318532944, 0.06458976864814758, 0.0, 0.0, 0.0], [0.8264952898025513, 0.03213464096188545, 0.05196719989180565, 0.0894029513001442, 0.0, 0.0], [0.7718173265457153, 0.030402837321162224, 0.045827414840459824, 0.07118473201990128, 0.08076759427785873, 0.0], [0.7292331457138062, 0.021699821576476097, 0.033074747771024704, 0.04720093309879303, 0.06474557518959045, 0.10404567420482635]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9979567527770996, 0.0020432830788195133, 0.0, 0.0, 0.0, 0.0], [0.955294132232666, 0.00802531372755766, 0.03668047487735748, 0.0, 0.0, 0.0], [0.9254710078239441, 0.002755576279014349, 0.0020629852078855038, 0.06971040368080139, 0.0, 0.0], [0.8660576939582825, 0.0038883681409060955, 0.0006785982404835522, 0.0006981453043408692, 0.1286771297454834, 0.0], [0.8455929160118103, 0.0037804055027663708, 0.000253423087997362, 6.0270751419011503e-05, 0.00011820747749879956, 0.15019479393959045]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9262455105781555, 0.07375453412532806, 0.0, 0.0, 0.0, 0.0], [0.7717157006263733, 0.16241952776908875, 0.06586471945047379, 0.0, 0.0, 0.0], [0.8167637586593628, 0.07807160913944244, 0.06324034929275513, 0.041924238204956055, 0.0, 0.0], [0.6867184638977051, 0.07755157351493835, 0.10056912153959274, 0.05955080687999725, 0.07561002671718597, 0.0], [0.6421161890029907, 0.11014898866415024, 0.07688194513320923, 0.054033469408750534, 0.10333634912967682, 0.013483096845448017]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9395954608917236, 0.060404520481824875, 0.0, 0.0, 0.0, 0.0], [0.23004619777202606, 0.6617380380630493, 0.1082158014178276, 0.0, 0.0, 0.0], [0.2670227289199829, 0.3607950508594513, 0.3249626159667969, 0.047219593077898026, 0.0, 0.0], [0.595201313495636, 0.12269274890422821, 0.06302059441804886, 0.08916817605495453, 0.12991715967655182, 0.0], [0.10284596681594849, 0.02938011661171913, 0.013739082030951977, 0.045860596001148224, 0.7698501348495483, 0.03832406550645828]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9040980935096741, 0.09590194374322891, 0.0, 0.0, 0.0, 0.0], [0.357237845659256, 0.6274612545967102, 0.015300876460969448, 0.0, 0.0, 0.0], [0.5917996764183044, 0.2764042019844055, 0.10476048290729523, 0.027035649865865707, 0.0, 0.0], [0.7254403829574585, 0.04983152449131012, 0.014982940629124641, 0.1778142899274826, 0.031930916011333466, 0.0], [0.7612743973731995, 0.06158972904086113, 0.005942251533269882, 0.01642685756087303, 0.1267806589603424, 0.0279861893504858]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9947587847709656, 0.005241230130195618, 0.0, 0.0, 0.0, 0.0], [0.9632415771484375, 0.017816413193941116, 0.018942030146718025, 0.0, 0.0, 0.0], [0.9671078324317932, 0.008509586565196514, 0.00856222677975893, 0.015820473432540894, 0.0, 0.0], [0.9340996146202087, 0.011952387169003487, 0.02018021047115326, 0.02675083465874195, 0.0070168930105865, 0.0], [0.9587237238883972, 0.004657115787267685, 0.003326789475977421, 0.006545313633978367, 0.010182461701333523, 0.016564540565013885]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9769991040229797, 0.023000910878181458, 0.0, 0.0, 0.0, 0.0], [0.7917609214782715, 0.1753319948911667, 0.032907065004110336, 0.0, 0.0, 0.0], [0.7949192523956299, 0.10531841963529587, 0.040218502283096313, 0.05954383686184883, 0.0, 0.0], [0.7097718715667725, 0.10552527755498886, 0.06597573310136795, 0.05765606462955475, 0.061070989817380905, 0.0], [0.7506601214408875, 0.026514461264014244, 0.021576043218374252, 0.034296683967113495, 0.08494450151920319, 0.08200812339782715]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.983751654624939, 0.016248304396867752, 0.0, 0.0, 0.0, 0.0], [0.5615494847297668, 0.08956841379404068, 0.3488820493221283, 0.0, 0.0, 0.0], [0.32929039001464844, 0.024114903062582016, 0.5428059697151184, 0.10378880053758621, 0.0, 0.0], [0.34330207109451294, 0.01308644749224186, 0.5121983289718628, 0.11146228760480881, 0.019950881600379944, 0.0], [0.4792812764644623, 0.01733359508216381, 0.1180536150932312, 0.06130281835794449, 0.20071913301944733, 0.12330964207649231]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9908847212791443, 0.009115329943597317, 0.0, 0.0, 0.0, 0.0], [0.5282707214355469, 0.3292262554168701, 0.1425030380487442, 0.0, 0.0, 0.0], [0.48788541555404663, 0.23368670046329498, 0.17578084766864777, 0.10264702141284943, 0.0, 0.0], [0.31444698572158813, 0.18065163493156433, 0.168714240193367, 0.09506598114967346, 0.24112118780612946, 0.0], [0.5168765187263489, 0.035897161811590195, 0.026188155636191368, 0.04039734974503517, 0.18791745603084564, 0.1927233189344406]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8750308156013489, 0.12496919929981232, 0.0, 0.0, 0.0, 0.0], [0.4550614655017853, 0.4900427758693695, 0.05489582195878029, 0.0, 0.0, 0.0], [0.2933720052242279, 0.5449907183647156, 0.09444297850131989, 0.06719419360160828, 0.0, 0.0], [0.489708811044693, 0.2720997631549835, 0.06861965358257294, 0.14694802463054657, 0.022623788565397263, 0.0], [0.4729066491127014, 0.08103099465370178, 0.016052134335041046, 0.30672287940979004, 0.10120721161365509, 0.022080255672335625]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9630220532417297, 0.03697792813181877, 0.0, 0.0, 0.0, 0.0], [0.7557195425033569, 0.16436372697353363, 0.07991670072078705, 0.0, 0.0, 0.0], [0.6947705745697021, 0.08409853279590607, 0.0638260766863823, 0.15730486810207367, 0.0, 0.0], [0.5821147561073303, 0.03297805413603783, 0.07936596870422363, 0.19441406428813934, 0.11112712323665619, 0.0], [0.5974540710449219, 0.04261096194386482, 0.06919723749160767, 0.14563441276550293, 0.12481734901666641, 0.020285936072468758]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9957822561264038, 0.004217816516757011, 0.0, 0.0, 0.0, 0.0], [0.9312832951545715, 0.010560247115790844, 0.05815650522708893, 0.0, 0.0, 0.0], [0.8435326814651489, 0.015695005655288696, 0.045751139521598816, 0.09502115100622177, 0.0, 0.0], [0.772409975528717, 0.011981245130300522, 0.03504609689116478, 0.03876771405339241, 0.14179500937461853, 0.0], [0.7642908692359924, 0.009868789464235306, 0.00812275055795908, 0.013314393348991871, 0.04824395477771759, 0.15615922212600708]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9701177477836609, 0.02988232672214508, 0.0, 0.0, 0.0, 0.0], [0.6564007997512817, 0.22506150603294373, 0.11853761970996857, 0.0, 0.0, 0.0], [0.6958062648773193, 0.14701850712299347, 0.07145983725786209, 0.08571550250053406, 0.0, 0.0], [0.6353274583816528, 0.1346064656972885, 0.030994214117527008, 0.056916315108537674, 0.1421555131673813, 0.0], [0.6779401898384094, 0.053654152899980545, 0.01800631172955036, 0.06284520775079727, 0.1103820651769638, 0.07717210054397583]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9822334051132202, 0.017766647040843964, 0.0, 0.0, 0.0, 0.0], [0.9037663340568542, 0.06541544198989868, 0.03081829659640789, 0.0, 0.0, 0.0], [0.8119193911552429, 0.03679030388593674, 0.060560714453458786, 0.09072960168123245, 0.0, 0.0], [0.40546438097953796, 0.10383912175893784, 0.10211236774921417, 0.35434210300445557, 0.03424208238720894, 0.0], [0.22824221849441528, 0.017278727144002914, 0.05055465176701546, 0.6015752553939819, 0.09411764144897461, 0.008231506682932377]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9873148202896118, 0.012685136869549751, 0.0, 0.0, 0.0, 0.0], [0.35445743799209595, 0.5317603349685669, 0.11378221958875656, 0.0, 0.0, 0.0], [0.07823363691568375, 0.7221359014511108, 0.10936623811721802, 0.090264230966568, 0.0, 0.0], [0.21967869997024536, 0.4048435091972351, 0.12358088046312332, 0.20018866658210754, 0.051708199083805084, 0.0], [0.36089760065078735, 0.10459021478891373, 0.06983799487352371, 0.2976483404636383, 0.13869903981685638, 0.02832675166428089]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9732162356376648, 0.0267837755382061, 0.0, 0.0, 0.0, 0.0], [0.9167553782463074, 0.061452705413103104, 0.02179192565381527, 0.0, 0.0, 0.0], [0.8543081283569336, 0.08049600571393967, 0.030334919691085815, 0.03486092761158943, 0.0, 0.0], [0.8919214606285095, 0.04280779883265495, 0.022045055404305458, 0.023470671847462654, 0.01975487545132637, 0.0], [0.8116763234138489, 0.03413533419370651, 0.03567665070295334, 0.04748587682843208, 0.0253971628844738, 0.04562860727310181]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9502761960029602, 0.04972382262349129, 0.0, 0.0, 0.0, 0.0], [0.7637454271316528, 0.2007361352443695, 0.03551840782165527, 0.0, 0.0, 0.0], [0.6279097199440002, 0.03768139332532883, 0.1994536966085434, 0.13495522737503052, 0.0, 0.0], [0.6397060751914978, 0.027007432654500008, 0.09082036465406418, 0.20653828978538513, 0.03592785820364952, 0.0], [0.4559425115585327, 0.021641194820404053, 0.12939567863941193, 0.21800927817821503, 0.10379841923713684, 0.07121295481920242]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9498406648635864, 0.050159383565187454, 0.0, 0.0, 0.0, 0.0], [0.8688724637031555, 0.0872218981385231, 0.043905653059482574, 0.0, 0.0, 0.0], [0.6937950253486633, 0.06359200924634933, 0.091790571808815, 0.15082231163978577, 0.0, 0.0], [0.7266597151756287, 0.04389883577823639, 0.04683985933661461, 0.09851823002099991, 0.08408336341381073, 0.0], [0.7848998308181763, 0.037147827446460724, 0.012907838448882103, 0.01053939200937748, 0.12079165875911713, 0.03371351957321167]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9891054034233093, 0.01089458167552948, 0.0, 0.0, 0.0, 0.0], [0.8929519653320312, 0.08700055629014969, 0.02004752680659294, 0.0, 0.0, 0.0], [0.7891124486923218, 0.09797251224517822, 0.08633202314376831, 0.026582980528473854, 0.0, 0.0], [0.8850635886192322, 0.03645012155175209, 0.05395457148551941, 0.01237727515399456, 0.012154522351920605, 0.0], [0.6861329674720764, 0.05720378831028938, 0.011636304669082165, 0.021660611033439636, 0.1748800277709961, 0.048486363142728806]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9396191835403442, 0.06038080155849457, 0.0, 0.0, 0.0, 0.0], [0.7851794958114624, 0.19751444458961487, 0.017306052148342133, 0.0, 0.0, 0.0], [0.7660509943962097, 0.15444670617580414, 0.03188290074467659, 0.04761936888098717, 0.0, 0.0], [0.703522801399231, 0.05171430483460426, 0.07760990411043167, 0.1533905267715454, 0.013762423768639565, 0.0], [0.7121888399124146, 0.04994234815239906, 0.03772548958659172, 0.08649132400751114, 0.06541401147842407, 0.04823806509375572]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.974072277545929, 0.025927715003490448, 0.0, 0.0, 0.0, 0.0], [0.792539656162262, 0.01171559002250433, 0.19574476778507233, 0.0, 0.0, 0.0], [0.5106770992279053, 0.007296787109225988, 0.039619915187358856, 0.4424062669277191, 0.0, 0.0], [0.5862472057342529, 0.012099712155759335, 0.024585209786891937, 0.06737840175628662, 0.30968940258026123, 0.0], [0.30196306109428406, 0.007724012713879347, 0.011518122628331184, 0.046947259455919266, 0.22146707773208618, 0.41038045287132263]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9744554162025452, 0.02554464340209961, 0.0, 0.0, 0.0, 0.0], [0.9769195318222046, 0.015048524364829063, 0.008031901903450489, 0.0, 0.0, 0.0], [0.9060619473457336, 0.025875424966216087, 0.025954782962799072, 0.04210779070854187, 0.0, 0.0], [0.9400081038475037, 0.00555665697902441, 0.005828304681926966, 0.031757812947034836, 0.016849134117364883, 0.0], [0.9105738401412964, 0.0019752182997763157, 0.008646721951663494, 0.013360846787691116, 0.03543964773416519, 0.030003678053617477]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9791666865348816, 0.020833350718021393, 0.0, 0.0, 0.0, 0.0], [0.8444858193397522, 0.13507869839668274, 0.020435383543372154, 0.0, 0.0, 0.0], [0.7903086543083191, 0.14559169113636017, 0.037529975175857544, 0.026569725945591927, 0.0, 0.0], [0.7298924326896667, 0.056496407836675644, 0.032735615968704224, 0.10400459170341492, 0.07687094807624817, 0.0], [0.5684185028076172, 0.04388832300901413, 0.026293467730283737, 0.0811714455485344, 0.24314835667610168, 0.037079911679029465]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9499868154525757, 0.05001320689916611, 0.0, 0.0, 0.0, 0.0], [0.9336170554161072, 0.05848868936300278, 0.007894262671470642, 0.0, 0.0, 0.0], [0.7897834181785583, 0.11071821302175522, 0.05360178276896477, 0.04589657858014107, 0.0, 0.0], [0.885930061340332, 0.05752986669540405, 0.01374326553195715, 0.0033877466339617968, 0.03940902277827263, 0.0], [0.9337607622146606, 0.02647063508629799, 0.004523396957665682, 0.0061904797330498695, 0.014132906682789326, 0.014921708963811398]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 1.8521224554035598e-09, 0.0, 0.0, 0.0, 0.0], [6.6758907451003324e-06, 0.9999804496765137, 1.2841281204600818e-05, 0.0, 0.0, 0.0], [2.2194194926328237e-08, 2.6684581211355862e-09, 0.9999971389770508, 2.8136880700913025e-06, 0.0, 0.0], [1.0145409987671883e-06, 4.464065739284706e-08, 0.00035356366424821317, 0.9993677735328674, 0.0002776293840724975, 0.0], [9.436550429953172e-10, 1.382057315812979e-11, 5.017835036369434e-10, 2.965183876213473e-09, 0.9999971389770508, 2.8644042231462663e-06]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9948632121086121, 0.005136783700436354, 0.0, 0.0, 0.0, 0.0], [0.9274215698242188, 0.01832387037575245, 0.05425456911325455, 0.0, 0.0, 0.0], [0.9678993225097656, 0.004143435508012772, 0.004314453341066837, 0.023642776533961296, 0.0, 0.0], [0.8999068737030029, 0.001467161695472896, 0.00029133574571460485, 0.002585014794021845, 0.09574954956769943, 0.0], [0.9386115670204163, 0.00022248300956562161, 0.0006146665546111763, 0.0015495637198910117, 0.030689461156725883, 0.028312424197793007]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9999959468841553, 4.042720775032649e-06, 0.0, 0.0, 0.0, 0.0], [0.9982761144638062, 3.2613831990602193e-06, 0.001720669330097735, 0.0, 0.0, 0.0], [0.9998809099197388, 5.328835683826583e-08, 6.376215537784446e-07, 0.00011847059795400128, 0.0, 0.0], [0.9996154308319092, 3.473169556400535e-07, 3.8920820344401363e-08, 4.468433303372876e-07, 0.00038369710091501474, 0.0], [0.9994840621948242, 1.655020476221125e-08, 2.8715557931491276e-08, 1.0638284493325045e-06, 0.0002126671897713095, 0.00030212008277885616]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9514135718345642, 0.048586405813694, 0.0, 0.0, 0.0, 0.0], [0.5749948024749756, 0.39028096199035645, 0.03472418338060379, 0.0, 0.0, 0.0], [0.7442318201065063, 0.1752411425113678, 0.0756477490067482, 0.004879283253103495, 0.0, 0.0], [0.5232070684432983, 0.09429339319467545, 0.1138191670179367, 0.19979268312454224, 0.06888769567012787, 0.0], [0.47472575306892395, 0.05636607110500336, 0.04530389606952667, 0.06967321783304214, 0.3098014295101166, 0.0441296212375164]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8734648823738098, 0.12653514742851257, 0.0, 0.0, 0.0, 0.0], [0.6097912788391113, 0.3541727066040039, 0.036036062985658646, 0.0, 0.0, 0.0], [0.45984190702438354, 0.38697871565818787, 0.0996011346578598, 0.05357823893427849, 0.0, 0.0], [0.572220504283905, 0.23636263608932495, 0.08344558626413345, 0.06921917200088501, 0.03875211998820305, 0.0], [0.5143564343452454, 0.16723087430000305, 0.09019406139850616, 0.0765448659658432, 0.10578085482120514, 0.04589281603693962]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.981228768825531, 0.018771231174468994, 0.0, 0.0, 0.0, 0.0], [0.6142941117286682, 0.3503977954387665, 0.0353081189095974, 0.0, 0.0, 0.0], [0.5770686268806458, 0.32858458161354065, 0.05508256331086159, 0.03926428034901619, 0.0, 0.0], [0.17188192903995514, 0.011042501777410507, 0.054578714072704315, 0.7326585650444031, 0.029838265851140022, 0.0], [0.3783015012741089, 0.017070062458515167, 0.021754134446382523, 0.4409688115119934, 0.06093813106417656, 0.08096737414598465]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9923112392425537, 0.007688735146075487, 0.0, 0.0, 0.0, 0.0], [0.9498787522315979, 0.016709784045815468, 0.03341152146458626, 0.0, 0.0, 0.0], [0.9961295127868652, 0.0008787295082584023, 0.0006868162308819592, 0.0023048371076583862, 0.0, 0.0], [0.9935757517814636, 0.0032634998206049204, 0.0009993825806304812, 0.00027932299417443573, 0.0018820574041455984, 0.0], [0.9907532930374146, 0.00021344318520277739, 0.0004595233185682446, 0.0007905619568191469, 0.004424723796546459, 0.003358350833877921]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9647740125656128, 0.03522596135735512, 0.0, 0.0, 0.0, 0.0], [0.8194130063056946, 0.1365436613559723, 0.04404333233833313, 0.0, 0.0, 0.0], [0.7584245800971985, 0.006878929678350687, 0.20653395354747772, 0.028162529692053795, 0.0, 0.0], [0.5298128128051758, 0.002678812015801668, 0.07857988774776459, 0.3598373234272003, 0.02909109927713871, 0.0], [0.7544413208961487, 0.00036782227107323706, 0.0019713479559868574, 0.00324004958383739, 0.1942344754934311, 0.04574500769376755]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9749131202697754, 0.02508680149912834, 0.0, 0.0, 0.0, 0.0], [0.9306471943855286, 0.05705660209059715, 0.012296222150325775, 0.0, 0.0, 0.0], [0.9305251836776733, 0.052770983427762985, 0.01111945416778326, 0.005584415514022112, 0.0, 0.0], [0.8863320350646973, 0.01292418036609888, 0.017724711447954178, 0.06150198355317116, 0.021517015993595123, 0.0], [0.791684627532959, 0.015036096796393394, 0.0317479707300663, 0.03392200171947479, 0.03707978501915932, 0.09052948653697968]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9608501195907593, 0.039149850606918335, 0.0, 0.0, 0.0, 0.0], [0.9121272563934326, 0.02257651649415493, 0.06529619544744492, 0.0, 0.0, 0.0], [0.9364108443260193, 0.015584447421133518, 0.024544963613152504, 0.02345985174179077, 0.0, 0.0], [0.9454620480537415, 0.006762288510799408, 0.022026237100362778, 0.009137796238064766, 0.016611700877547264, 0.0], [0.8346164226531982, 0.001881699077785015, 0.00560904573649168, 0.01887359470129013, 0.12449200451374054, 0.014527074061334133]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9964227080345154, 0.0035772807896137238, 0.0, 0.0, 0.0, 0.0], [0.9713928699493408, 0.024453025311231613, 0.004154058638960123, 0.0, 0.0, 0.0], [0.9735792279243469, 0.019003381952643394, 0.003664410673081875, 0.0037529165856540203, 0.0, 0.0], [0.9586312174797058, 0.007116180844604969, 0.009218388237059116, 0.022725583985447884, 0.0023084774147719145, 0.0], [0.973607063293457, 0.008490582928061485, 0.0032512471079826355, 0.003606445388868451, 0.004877461586147547, 0.006167212035506964]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.97598797082901, 0.024011990055441856, 0.0, 0.0, 0.0, 0.0], [0.9460638165473938, 0.04211375489830971, 0.011822436936199665, 0.0, 0.0, 0.0], [0.8446813225746155, 0.04293116182088852, 0.05218198522925377, 0.06020559370517731, 0.0, 0.0], [0.9378372430801392, 0.03354858607053757, 0.008826455101370811, 0.0028792242519557476, 0.016908427700400352, 0.0], [0.8124931454658508, 0.02696753479540348, 0.05999218672513962, 0.03445731848478317, 0.011011860333383083, 0.05507794767618179]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9001203775405884, 0.09987961500883102, 0.0, 0.0, 0.0, 0.0], [0.627193033695221, 0.07988718152046204, 0.29291975498199463, 0.0, 0.0, 0.0], [0.7624077796936035, 0.02734432928264141, 0.038679543882608414, 0.17156831920146942, 0.0, 0.0], [0.7995968461036682, 0.014336260966956615, 0.01437566988170147, 0.025438452139496803, 0.14625284075737, 0.0], [0.7851970791816711, 0.04204057529568672, 0.025253651663661003, 0.02908395044505596, 0.029306314885616302, 0.08911846578121185]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9954467415809631, 0.0045532057993113995, 0.0, 0.0, 0.0, 0.0], [0.9356001615524292, 0.04476744681596756, 0.019632352516055107, 0.0, 0.0, 0.0], [0.5605552792549133, 0.09861977398395538, 0.29983264207839966, 0.040992289781570435, 0.0, 0.0], [0.5893709659576416, 0.11000988632440567, 0.08033622056245804, 0.16754034161567688, 0.05274256691336632, 0.0], [0.22305884957313538, 0.05680817365646362, 0.05467984080314636, 0.24733951687812805, 0.3111244738101959, 0.1069890558719635]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9301451444625854, 0.06985488533973694, 0.0, 0.0, 0.0, 0.0], [0.8936478495597839, 0.08535721153020859, 0.020994966849684715, 0.0, 0.0, 0.0], [0.8404538035392761, 0.10619214922189713, 0.02363673783838749, 0.029717326164245605, 0.0, 0.0], [0.8927386403083801, 0.024784674867987633, 0.008319000713527203, 0.05165454372763634, 0.022503145039081573, 0.0], [0.8646610975265503, 0.009503193199634552, 0.0024329854641109705, 0.04796753078699112, 0.04273205250501633, 0.03270319849252701]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9859625697135925, 0.014037408865988255, 0.0, 0.0, 0.0, 0.0], [0.9702037572860718, 0.0168070700019598, 0.012989125214517117, 0.0, 0.0, 0.0], [0.9524770379066467, 0.016064459457993507, 0.013456220738589764, 0.018002323806285858, 0.0, 0.0], [0.9332928657531738, 0.01897200010716915, 0.02014683373272419, 0.017023753374814987, 0.010564540512859821, 0.0], [0.9113592505455017, 0.012528638355433941, 0.02209620550274849, 0.01751861348748207, 0.018517911434173584, 0.01797938533127308]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9681769013404846, 0.03182310611009598, 0.0, 0.0, 0.0, 0.0], [0.9096417427062988, 0.07916690409183502, 0.011191264726221561, 0.0, 0.0, 0.0], [0.8379932045936584, 0.13078266382217407, 0.012140989303588867, 0.019083037972450256, 0.0, 0.0], [0.9116525053977966, 0.05451957508921623, 0.009499342180788517, 0.00746585289016366, 0.01686275750398636, 0.0], [0.8510289192199707, 0.07338211685419083, 0.008022507652640343, 0.009083161130547523, 0.04261006414890289, 0.015873271971940994]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9799023866653442, 0.020097682252526283, 0.0, 0.0, 0.0, 0.0], [0.9558742642402649, 0.029063312336802483, 0.015062497928738594, 0.0, 0.0, 0.0], [0.7943133115768433, 0.06074100360274315, 0.06907659024000168, 0.07586916536092758, 0.0, 0.0], [0.5494324564933777, 0.03154711425304413, 0.05482015758752823, 0.05788077041506767, 0.3063195049762726, 0.0], [0.6453980803489685, 0.010770943015813828, 0.017528092488646507, 0.02157985046505928, 0.24958276748657227, 0.05514020845293999]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9506809115409851, 0.0493190623819828, 0.0, 0.0, 0.0, 0.0], [0.8553215265274048, 0.09256264567375183, 0.05211575701832771, 0.0, 0.0, 0.0], [0.850852370262146, 0.04734604433178902, 0.044177331030368805, 0.057624250650405884, 0.0, 0.0], [0.7697131633758545, 0.02788589708507061, 0.031017286702990532, 0.06842502951622009, 0.1029587835073471, 0.0], [0.7931903004646301, 0.04052198305726051, 0.029242033138871193, 0.04478124529123306, 0.04894689470529556, 0.04331749677658081]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9770310521125793, 0.02296893112361431, 0.0, 0.0, 0.0, 0.0], [0.9429817199707031, 0.017321482300758362, 0.03969680890440941, 0.0, 0.0, 0.0], [0.9144344925880432, 0.008583576418459415, 0.013035810552537441, 0.06394599378108978, 0.0, 0.0], [0.9222429990768433, 0.0036440351977944374, 0.003740275977179408, 0.010410364717245102, 0.05996239185333252, 0.0], [0.9198879599571228, 0.0030822583939880133, 0.0034827394410967827, 0.004206796642392874, 0.02125428058207035, 0.048085976392030716]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.977458119392395, 0.022541873157024384, 0.0, 0.0, 0.0, 0.0], [0.8929325342178345, 0.07475466281175613, 0.032312843948602676, 0.0, 0.0, 0.0], [0.8423511385917664, 0.05980278551578522, 0.03740081936120987, 0.06044524535536766, 0.0, 0.0], [0.7674624919891357, 0.03536349534988403, 0.042155250906944275, 0.06658654659986496, 0.08843226730823517, 0.0], [0.6182611584663391, 0.01611059531569481, 0.020167622715234756, 0.03868892416357994, 0.23147016763687134, 0.07530155777931213]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9634856581687927, 0.036514393985271454, 0.0, 0.0, 0.0, 0.0], [0.4363938570022583, 0.522637128829956, 0.04096902906894684, 0.0, 0.0, 0.0], [0.3608614206314087, 0.35129693150520325, 0.2655103802680969, 0.022331148386001587, 0.0, 0.0], [0.3942921757698059, 0.021704670041799545, 0.07794328778982162, 0.37168896198272705, 0.1343708038330078, 0.0], [0.6310713887214661, 0.01698400266468525, 0.025942081585526466, 0.08615949749946594, 0.2183200567960739, 0.021522950381040573]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9988250136375427, 0.0011750265257433057, 0.0, 0.0, 0.0, 0.0], [0.9944871068000793, 0.0004826401418540627, 0.0050302306190133095, 0.0, 0.0, 0.0], [0.9981209635734558, 2.705173392314464e-05, 0.0001130745149566792, 0.0017389442073181272, 0.0, 0.0], [0.9982239603996277, 6.83655816828832e-05, 0.00010199935059063137, 6.028370262356475e-05, 0.0015453165397047997, 0.0], [0.9982888102531433, 1.055222810464329e-06, 3.2781026675365865e-05, 0.00013038977340329438, 0.0006605894886888564, 0.0008863684488460422]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9936710596084595, 0.006328921765089035, 0.0, 0.0, 0.0, 0.0], [0.9727688431739807, 0.0018561368342489004, 0.025375060737133026, 0.0, 0.0, 0.0], [0.9724299907684326, 0.0019586149137467146, 0.011192461475729942, 0.014418890699744225, 0.0, 0.0], [0.9782041311264038, 0.0009589138207957149, 0.0018706483533605933, 0.006326568778604269, 0.012639678083360195, 0.0], [0.9592596888542175, 0.0024555064737796783, 0.00161241355817765, 0.005019655916839838, 0.006687097251415253, 0.024965662509202957]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9629000425338745, 0.03709998354315758, 0.0, 0.0, 0.0, 0.0], [0.36801934242248535, 0.6152258515357971, 0.016754813492298126, 0.0, 0.0, 0.0], [0.3173511326313019, 0.6140013337135315, 0.05375149846076965, 0.014896026812493801, 0.0, 0.0], [0.48987284302711487, 0.21071474254131317, 0.04693019017577171, 0.20700432360172272, 0.04547784850001335, 0.0], [0.48774227499961853, 0.1769528090953827, 0.06915216147899628, 0.09849268198013306, 0.12091436982154846, 0.046745721250772476]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9794419407844543, 0.020558049902319908, 0.0, 0.0, 0.0, 0.0], [0.6677903532981873, 0.31032365560531616, 0.021886007860302925, 0.0, 0.0, 0.0], [0.7118757367134094, 0.11108540743589401, 0.14187385141849518, 0.03516504913568497, 0.0, 0.0], [0.4501457214355469, 0.04036055505275726, 0.040458209812641144, 0.388570100069046, 0.08046531677246094, 0.0], [0.49346262216567993, 0.013696977868676186, 0.008126799948513508, 0.13074499368667603, 0.3086138069629669, 0.04535480588674545]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9846054315567017, 0.015394587069749832, 0.0, 0.0, 0.0, 0.0], [0.9806739091873169, 0.007713791914284229, 0.011612347327172756, 0.0, 0.0, 0.0], [0.932663083076477, 0.01957838423550129, 0.02410353161394596, 0.023654978722333908, 0.0, 0.0], [0.9422016739845276, 0.0009538981830701232, 0.0010898025939241052, 0.00319337984547019, 0.05256118252873421, 0.0], [0.9352930784225464, 0.0010279357666149735, 0.004444425459951162, 0.001637140172533691, 0.010590963996946812, 0.04700646549463272]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9985783100128174, 0.0014216724084690213, 0.0, 0.0, 0.0, 0.0], [0.9893348813056946, 0.0011178902350366116, 0.00954714696854353, 0.0, 0.0, 0.0], [0.9979978203773499, 7.997050124686211e-05, 0.00013218850654084235, 0.0017900333041325212, 0.0, 0.0], [0.9986976385116577, 4.1044117097044364e-05, 3.8683547245454974e-06, 2.3676282580709085e-05, 0.0012337174266576767, 0.0], [0.9971563816070557, 1.852225250331685e-05, 1.8826559653462027e-06, 2.7900125132873654e-05, 0.0006533482228405774, 0.0021419788245111704]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9768233299255371, 0.023176640272140503, 0.0, 0.0, 0.0, 0.0], [0.9194678068161011, 0.05088186264038086, 0.029650341719388962, 0.0, 0.0, 0.0], [0.8474554419517517, 0.06100169196724892, 0.04372376948595047, 0.04781914874911308, 0.0, 0.0], [0.8011623620986938, 0.041866958141326904, 0.04375807195901871, 0.041894737631082535, 0.07131782174110413, 0.0], [0.8031871914863586, 0.02450493723154068, 0.017323585227131844, 0.04744395986199379, 0.06109930947422981, 0.046441152691841125]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9829428195953369, 0.01705716922879219, 0.0, 0.0, 0.0, 0.0], [0.8863736987113953, 0.09492647647857666, 0.018699750304222107, 0.0, 0.0, 0.0], [0.9231085777282715, 0.03696346655488014, 0.032198335975408554, 0.007729663979262114, 0.0, 0.0], [0.9068527221679688, 0.016046639531850815, 0.014310522936284542, 0.04543786868453026, 0.017352323979139328, 0.0], [0.6555973887443542, 0.05091019719839096, 0.028384855017066002, 0.1256549060344696, 0.10546853393316269, 0.03398407623171806]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9502318501472473, 0.049768079072237015, 0.0, 0.0, 0.0, 0.0], [0.8829865455627441, 0.1000962108373642, 0.01691717840731144, 0.0, 0.0, 0.0], [0.8057457804679871, 0.14463546872138977, 0.03018922731280327, 0.019429458305239677, 0.0, 0.0], [0.8706230521202087, 0.032440632581710815, 0.026951627805829048, 0.04410304129123688, 0.025881657376885414, 0.0], [0.688364565372467, 0.009681451134383678, 0.016449343413114548, 0.0987110361456871, 0.08971209079027176, 0.09708156436681747]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9792683124542236, 0.02073168195784092, 0.0, 0.0, 0.0, 0.0], [0.9523284435272217, 0.025933818891644478, 0.021737735718488693, 0.0, 0.0, 0.0], [0.9144353270530701, 0.017671240493655205, 0.022358495742082596, 0.04553484544157982, 0.0, 0.0], [0.9448292851448059, 0.006467597559094429, 0.006386063527315855, 0.03263096138834953, 0.00968620739877224, 0.0], [0.9347906112670898, 0.007862505502998829, 0.007788175716996193, 0.021432818844914436, 0.008491144515573978, 0.01963483914732933]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.983370304107666, 0.016629677265882492, 0.0, 0.0, 0.0, 0.0], [0.963111400604248, 0.009229931980371475, 0.027658598497509956, 0.0, 0.0, 0.0], [0.9706628322601318, 0.0041494048200547695, 0.0068131014704704285, 0.018374638631939888, 0.0, 0.0], [0.987951934337616, 0.002165885642170906, 0.00034901127219200134, 0.001583816367201507, 0.00794942770153284, 0.0], [0.9457950592041016, 0.014583553187549114, 0.0003652951563708484, 0.0009569536778144538, 0.013621564954519272, 0.02467755414545536]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9878059029579163, 0.01219407469034195, 0.0, 0.0, 0.0, 0.0], [0.87103670835495, 0.09448163211345673, 0.03448161482810974, 0.0, 0.0, 0.0], [0.6309783458709717, 0.11090382188558578, 0.1923021823167801, 0.06581564992666245, 0.0, 0.0], [0.5360490083694458, 0.04618944972753525, 0.13605308532714844, 0.26455509662628174, 0.017153292894363403, 0.0], [0.8287520408630371, 0.023732755333185196, 0.02008037269115448, 0.07245264202356339, 0.030431220307946205, 0.024550989270210266]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8995685577392578, 0.10043150931596756, 0.0, 0.0, 0.0, 0.0], [0.270343542098999, 0.6504329442977905, 0.07922357320785522, 0.0, 0.0, 0.0], [0.20541730523109436, 0.5892508625984192, 0.18085837364196777, 0.024473490193486214, 0.0, 0.0], [0.5573861002922058, 0.1774134784936905, 0.08806808292865753, 0.09881848096847534, 0.07831384986639023, 0.0], [0.5922912359237671, 0.08700639009475708, 0.05643285810947418, 0.05685883015394211, 0.12181518226861954, 0.08559554070234299]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9316380620002747, 0.06836195290088654, 0.0, 0.0, 0.0, 0.0], [0.9572945833206177, 0.026243582367897034, 0.0164618119597435, 0.0, 0.0, 0.0], [0.9880544543266296, 0.00427332753315568, 0.002954584313556552, 0.004717645235359669, 0.0, 0.0], [0.99403977394104, 0.0009413420339114964, 0.0004739820142276585, 0.00011646930943243206, 0.004428447224199772, 0.0], [0.9806035161018372, 2.5468933017691597e-05, 0.00016239412070717663, 0.0001476418401580304, 0.0013442443450912833, 0.017716845497488976]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.993178129196167, 0.006821857299655676, 0.0, 0.0, 0.0, 0.0], [0.9756524562835693, 0.01318411435931921, 0.011163423769176006, 0.0, 0.0, 0.0], [0.9418966770172119, 0.004721744451671839, 0.0023818055633455515, 0.050999753177165985, 0.0, 0.0], [0.9905040860176086, 0.0022848136723041534, 6.198462506290525e-05, 0.0005984465242363513, 0.006550676189363003, 0.0], [0.9697660207748413, 0.0008878845837898552, 0.00023466735729016364, 0.0017040816601365805, 0.004128355998545885, 0.02327893301844597]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9716231822967529, 0.02837684564292431, 0.0, 0.0, 0.0, 0.0], [0.9223619699478149, 0.028907248750329018, 0.048730745911598206, 0.0, 0.0, 0.0], [0.8426317572593689, 0.023872116580605507, 0.04748132824897766, 0.08601479232311249, 0.0, 0.0], [0.8521121740341187, 0.020744236186146736, 0.04494619369506836, 0.05765002593398094, 0.02454746514558792, 0.0], [0.8800725936889648, 0.022448532283306122, 0.018235722556710243, 0.01925482600927353, 0.015854258090257645, 0.044134121388196945]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9412723779678345, 0.058727629482746124, 0.0, 0.0, 0.0, 0.0], [0.916313886642456, 0.05759201943874359, 0.02609400637447834, 0.0, 0.0, 0.0], [0.8392423391342163, 0.057690516114234924, 0.01382902916520834, 0.08923812955617905, 0.0, 0.0], [0.8987162113189697, 0.0134778693318367, 0.0003456450067460537, 0.003298751311376691, 0.08416149020195007, 0.0], [0.8701692223548889, 0.002700856188312173, 0.00143499206751585, 0.0056661744602024555, 0.08874300867319107, 0.031285665929317474]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9656725525856018, 0.03432750701904297, 0.0, 0.0, 0.0, 0.0], [0.9178615808486938, 0.062257930636405945, 0.019880469888448715, 0.0, 0.0, 0.0], [0.823314905166626, 0.06282395124435425, 0.03670429438352585, 0.07715693861246109, 0.0, 0.0], [0.8501748442649841, 0.03816927224397659, 0.03196492791175842, 0.0516013503074646, 0.02808968350291252, 0.0], [0.6572404503822327, 0.05877397954463959, 0.04336007311940193, 0.09013211727142334, 0.08146599680185318, 0.06902744621038437]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9162061810493469, 0.0837937667965889, 0.0, 0.0, 0.0, 0.0], [0.9451773762702942, 0.04099284112453461, 0.013829832896590233, 0.0, 0.0, 0.0], [0.8928355574607849, 0.05368670076131821, 0.017596954479813576, 0.03588071092963219, 0.0, 0.0], [0.8337052464485168, 0.04799601063132286, 0.033513229340314865, 0.04680858924984932, 0.03797686845064163, 0.0], [0.8167192339897156, 0.06337132304906845, 0.013286277651786804, 0.020469767972826958, 0.025292355567216873, 0.06086111441254616]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9525133371353149, 0.04748663306236267, 0.0, 0.0, 0.0, 0.0], [0.3019869327545166, 0.6520938873291016, 0.04591925069689751, 0.0, 0.0, 0.0], [0.285582959651947, 0.556952178478241, 0.1444743126630783, 0.012990524061024189, 0.0, 0.0], [0.843804121017456, 0.032251205295324326, 0.03954290598630905, 0.06848159432411194, 0.015920041128993034, 0.0], [0.6664940714836121, 0.06095913052558899, 0.04064354673027992, 0.06804485619068146, 0.09186329692602158, 0.07199501991271973]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9682655334472656, 0.031734466552734375, 0.0, 0.0, 0.0, 0.0], [0.738521933555603, 0.22856839001178741, 0.032909639179706573, 0.0, 0.0, 0.0], [0.5946676135063171, 0.2303314357995987, 0.14867636561393738, 0.02632458508014679, 0.0, 0.0], [0.6339254975318909, 0.05813034623861313, 0.09654320776462555, 0.14291946589946747, 0.06848153471946716, 0.0], [0.40375572443008423, 0.08945391327142715, 0.07635112851858139, 0.25587135553359985, 0.1433039754629135, 0.03126389905810356]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9869793653488159, 0.013020593672990799, 0.0, 0.0, 0.0, 0.0], [0.8631385564804077, 0.1105666309595108, 0.02629482001066208, 0.0, 0.0, 0.0], [0.9488080143928528, 0.028614996001124382, 0.006535546388477087, 0.016041526570916176, 0.0, 0.0], [0.9672170877456665, 0.006604980677366257, 0.00045171406236477196, 0.004844417329877615, 0.020881708711385727, 0.0], [0.9354621171951294, 0.02047806605696678, 0.0011700231116265059, 0.007056943140923977, 0.0163181871175766, 0.019514625892043114]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9846673011779785, 0.015332723967730999, 0.0, 0.0, 0.0, 0.0], [0.9052747488021851, 0.08373606950044632, 0.010989243164658546, 0.0, 0.0, 0.0], [0.8145939111709595, 0.04283742979168892, 0.10568301379680634, 0.03688570484519005, 0.0, 0.0], [0.23519809544086456, 0.012018457986414433, 0.05280117318034172, 0.6516180038452148, 0.04836418479681015, 0.0], [0.31818512082099915, 0.018632443621754646, 0.03948190063238144, 0.3755541741847992, 0.20787373185157776, 0.04027257487177849]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9811733365058899, 0.018826685845851898, 0.0, 0.0, 0.0, 0.0], [0.8618939518928528, 0.06479164958000183, 0.07331438362598419, 0.0, 0.0, 0.0], [0.7664540410041809, 0.07330425828695297, 0.10353513062000275, 0.056706514209508896, 0.0, 0.0], [0.8128499984741211, 0.03215480223298073, 0.059005625545978546, 0.05416511744260788, 0.04182446748018265, 0.0], [0.8687856197357178, 0.026987861841917038, 0.02047000452876091, 0.01629738137125969, 0.03218390792608261, 0.03527523949742317]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9264583587646484, 0.07354167848825455, 0.0, 0.0, 0.0, 0.0], [0.8403540849685669, 0.06373751163482666, 0.09590838104486465, 0.0, 0.0, 0.0], [0.7330995798110962, 0.06451118737459183, 0.10380073636770248, 0.09858842939138412, 0.0, 0.0], [0.9143612384796143, 0.008257776498794556, 0.007320381235331297, 0.017966248095035553, 0.05209439620375633, 0.0], [0.8971915245056152, 0.008555498905479908, 0.007019453682005405, 0.014860544353723526, 0.03399762138724327, 0.03837529569864273]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9180347919464111, 0.08196526020765305, 0.0, 0.0, 0.0, 0.0], [0.8328666687011719, 0.1219901517033577, 0.04514322429895401, 0.0, 0.0, 0.0], [0.7994157075881958, 0.0874413549900055, 0.03605784848332405, 0.07708510011434555, 0.0, 0.0], [0.880984902381897, 0.020749641582369804, 0.020554615184664726, 0.017120830714702606, 0.06058995798230171, 0.0], [0.745303213596344, 0.044334057718515396, 0.022549288347363472, 0.0331527441740036, 0.03357058763504028, 0.12109009176492691]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9867060780525208, 0.013293893076479435, 0.0, 0.0, 0.0, 0.0], [0.982177734375, 0.012414131313562393, 0.005408108700066805, 0.0, 0.0, 0.0], [0.9630486369132996, 0.015290752984583378, 0.010345698334276676, 0.0113149369135499, 0.0, 0.0], [0.9213568568229675, 0.014132463373243809, 0.017639216035604477, 0.016567690297961235, 0.030303770676255226, 0.0], [0.9373326301574707, 0.009064299054443836, 0.007548365276306868, 0.006576443091034889, 0.011827622540295124, 0.027650514617562294]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9951004385948181, 0.00489962799474597, 0.0, 0.0, 0.0, 0.0], [0.9476007223129272, 0.041407931596040726, 0.010991275310516357, 0.0, 0.0, 0.0], [0.9142175316810608, 0.023523783311247826, 0.039145033806562424, 0.023113621398806572, 0.0, 0.0], [0.9534738659858704, 0.008932933211326599, 0.015272765420377254, 0.007908251136541367, 0.014412266202270985, 0.0], [0.9427101016044617, 0.00823307130485773, 0.004650997929275036, 0.004178107250481844, 0.005463531706482172, 0.03476419299840927]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9543376564979553, 0.045662373304367065, 0.0, 0.0, 0.0, 0.0], [0.9696040749549866, 0.01954760029911995, 0.01084828469902277, 0.0, 0.0, 0.0], [0.9710449576377869, 0.012425386346876621, 0.008068876340985298, 0.008460716344416142, 0.0, 0.0], [0.9726192951202393, 0.002697656163945794, 0.00044831327977590263, 0.0013814778067171574, 0.022853154689073563, 0.0], [0.9675466418266296, 0.009613442234694958, 0.003203035332262516, 0.00424883933737874, 0.007442260626703501, 0.00794589426368475]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9887008666992188, 0.011299116536974907, 0.0, 0.0, 0.0, 0.0], [0.9382632374763489, 0.04204244911670685, 0.019694412127137184, 0.0, 0.0, 0.0], [0.8351995944976807, 0.03487853705883026, 0.05134471505880356, 0.07857715338468552, 0.0, 0.0], [0.9042676687240601, 0.010541575029492378, 0.016426723450422287, 0.025921987369656563, 0.04284200444817543, 0.0], [0.8913140892982483, 0.00891267228871584, 0.005010711494833231, 0.008175632916390896, 0.013514749705791473, 0.07307209819555283]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8693912029266357, 0.13060881197452545, 0.0, 0.0, 0.0, 0.0], [0.3507988452911377, 0.606351912021637, 0.04284917935729027, 0.0, 0.0, 0.0], [0.35475659370422363, 0.3502019941806793, 0.24722407758235931, 0.04781729355454445, 0.0, 0.0], [0.35370609164237976, 0.03527737781405449, 0.09567111730575562, 0.449796199798584, 0.06554921716451645, 0.0], [0.4132595360279083, 0.09055527299642563, 0.05286579951643944, 0.174679696559906, 0.173848956823349, 0.09479076415300369]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9629756212234497, 0.037024300545454025, 0.0, 0.0, 0.0, 0.0], [0.9756426811218262, 0.01965854875743389, 0.004698706325143576, 0.0, 0.0, 0.0], [0.9775736927986145, 0.013286248780786991, 0.0025590297300368547, 0.006581062916666269, 0.0, 0.0], [0.9870142936706543, 0.007388236932456493, 0.0009579154429957271, 0.0018318220973014832, 0.0028077505994588137, 0.0], [0.9409245848655701, 0.016633737832307816, 0.0022979143541306257, 0.0058906711637973785, 0.0055129327811300755, 0.02874022163450718]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.962827205657959, 0.037172831594944, 0.0, 0.0, 0.0, 0.0], [0.9582237601280212, 0.024641817435622215, 0.017134377732872963, 0.0, 0.0, 0.0], [0.9351300001144409, 0.015331573784351349, 0.014810982160270214, 0.034727465361356735, 0.0, 0.0], [0.9225171208381653, 0.010528750717639923, 0.011010154150426388, 0.01944003626704216, 0.036503832787275314, 0.0], [0.8420165777206421, 0.04357199743390083, 0.007488282397389412, 0.01496153138577938, 0.02385285682976246, 0.06810864061117172]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9926387071609497, 0.00736132962629199, 0.0, 0.0, 0.0, 0.0], [0.9957393407821655, 0.0033469819463789463, 0.000913690309971571, 0.0, 0.0, 0.0], [0.9869900345802307, 0.001974786864593625, 0.001524551771581173, 0.009510699659585953, 0.0, 0.0], [0.9933527708053589, 0.001020324882119894, 0.00034337223041802645, 0.0010291127255186439, 0.004254369530826807, 0.0], [0.9749016761779785, 0.00043480272870510817, 0.0004306558985263109, 0.0012364407302811742, 0.0015347707085311413, 0.021461669355630875]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9897475242614746, 0.010252462700009346, 0.0, 0.0, 0.0, 0.0], [0.9790639281272888, 0.01650906540453434, 0.0044270907528698444, 0.0, 0.0, 0.0], [0.9521436095237732, 0.029432358220219612, 0.008943161927163601, 0.009480923414230347, 0.0, 0.0], [0.939594030380249, 0.021510960534214973, 0.010278552770614624, 0.004555229097604752, 0.024061163887381554, 0.0], [0.9205074906349182, 0.016153652220964432, 0.010818594135344028, 0.01664440892636776, 0.014566398225724697, 0.021309375762939453]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9898501634597778, 0.010149780660867691, 0.0, 0.0, 0.0, 0.0], [0.9820910096168518, 0.006907520350068808, 0.011001535691320896, 0.0, 0.0, 0.0], [0.9684997200965881, 0.008987602777779102, 0.015342563390731812, 0.007170087192207575, 0.0, 0.0], [0.9274120330810547, 0.009485266171395779, 0.022066107019782066, 0.03222890570759773, 0.008807653561234474, 0.0], [0.900665819644928, 0.021623756736516953, 0.013808279298245907, 0.009843860752880573, 0.008521373383700848, 0.04553695768117905]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9954444169998169, 0.004555588588118553, 0.0, 0.0, 0.0, 0.0], [0.995254397392273, 0.002460238989442587, 0.002285485854372382, 0.0, 0.0, 0.0], [0.9862446188926697, 0.0015168144600465894, 0.004072288051247597, 0.008166354149580002, 0.0, 0.0], [0.9889963865280151, 0.001226040069013834, 0.0007996349013410509, 0.0006774227367714047, 0.008300574496388435, 0.0], [0.9865202903747559, 0.00039427157025784254, 0.0009571771952323616, 0.0004954367759637535, 0.0009604979422874749, 0.010672281496226788]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9821295142173767, 0.017870500683784485, 0.0, 0.0, 0.0, 0.0], [0.7489436268806458, 0.22002726793289185, 0.031029189005494118, 0.0, 0.0, 0.0], [0.28547799587249756, 0.21125678718090057, 0.47871601581573486, 0.024549242109060287, 0.0, 0.0], [0.8056644201278687, 0.026974644511938095, 0.04302806034684181, 0.06993705034255981, 0.05439583212137222, 0.0], [0.3307209014892578, 0.022326624020934105, 0.016627125442028046, 0.08019453287124634, 0.41574832797050476, 0.13438253104686737]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9697746634483337, 0.030225319787859917, 0.0, 0.0, 0.0, 0.0], [0.9800565838813782, 0.015018894337117672, 0.004924521781504154, 0.0, 0.0, 0.0], [0.9237861037254333, 0.052764780819416046, 0.00630240747705102, 0.017146753147244453, 0.0, 0.0], [0.9451844096183777, 0.03618047758936882, 0.001989208161830902, 0.003958724904805422, 0.012687299400568008, 0.0], [0.9633325934410095, 0.018662991002202034, 0.0030418417882174253, 0.007070912979543209, 0.0050094155594706535, 0.002882065251469612]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9873244762420654, 0.012675459496676922, 0.0, 0.0, 0.0, 0.0], [0.9904569983482361, 0.0055419523268938065, 0.004001122899353504, 0.0, 0.0, 0.0], [0.9814971685409546, 0.004653455223888159, 0.003725277027115226, 0.010124054737389088, 0.0, 0.0], [0.9744365811347961, 0.004632251337170601, 0.002379992976784706, 0.006518087349832058, 0.012033028528094292, 0.0], [0.9624497294425964, 0.0033743639942258596, 0.0013198587112128735, 0.0017275003483518958, 0.002944675739854574, 0.028183799237012863]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9807674288749695, 0.01923258602619171, 0.0, 0.0, 0.0, 0.0], [0.9664245843887329, 0.015413926914334297, 0.018161438405513763, 0.0, 0.0, 0.0], [0.9632682204246521, 0.004538117907941341, 0.002925391308963299, 0.029268190264701843, 0.0, 0.0], [0.9562349319458008, 0.0012223608791828156, 0.0005304080550558865, 0.00867149606347084, 0.03334089741110802, 0.0], [0.9657101035118103, 0.0009808284230530262, 0.0016686266753822565, 0.002634831238538027, 0.005866361316293478, 0.023139292374253273]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9639716148376465, 0.036028459668159485, 0.0, 0.0, 0.0, 0.0], [0.9562800526618958, 0.03373315557837486, 0.009986846707761288, 0.0, 0.0, 0.0], [0.8539998531341553, 0.08073022216558456, 0.03334445133805275, 0.031925540417432785, 0.0, 0.0], [0.9547491073608398, 0.009605025872588158, 0.004146162886172533, 0.0020133228972554207, 0.029486361891031265, 0.0], [0.9331137537956238, 0.028699662536382675, 0.005477475933730602, 0.006368075497448444, 0.012613046914339066, 0.013728085905313492]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9392993450164795, 0.06070063263177872, 0.0, 0.0, 0.0, 0.0], [0.9298391342163086, 0.061895377933979034, 0.008265496231615543, 0.0, 0.0, 0.0], [0.8471823334693909, 0.09035038203001022, 0.01763608679175377, 0.044831156730651855, 0.0, 0.0], [0.8857703804969788, 0.03918175399303436, 0.007867704145610332, 0.02276589721441269, 0.04441439360380173, 0.0], [0.8563280701637268, 0.10088995099067688, 0.006531452294439077, 0.008485927246510983, 0.007368441205471754, 0.020396249368786812]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8353264331817627, 0.1646735519170761, 0.0, 0.0, 0.0, 0.0], [0.6160858869552612, 0.3137648403644562, 0.07014927268028259, 0.0, 0.0, 0.0], [0.34316325187683105, 0.2758493721485138, 0.1196604073047638, 0.26132699847221375, 0.0, 0.0], [0.5908172130584717, 0.050290752202272415, 0.041665926575660706, 0.2199493646621704, 0.0972767099738121, 0.0], [0.8481413125991821, 0.06318090111017227, 0.014733693562448025, 0.055267371237277985, 0.00901501253247261, 0.009661628864705563]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9627319574356079, 0.03726799786090851, 0.0, 0.0, 0.0, 0.0], [0.7757522463798523, 0.1799626499414444, 0.044285036623477936, 0.0, 0.0, 0.0], [0.6317060589790344, 0.24380716681480408, 0.10925652086734772, 0.015230235643684864, 0.0, 0.0], [0.9539909958839417, 0.018182311207056046, 0.011601822450757027, 0.012299076654016972, 0.003925766795873642, 0.0], [0.40356943011283875, 0.14237558841705322, 0.05661217123270035, 0.1975736767053604, 0.0929921343922615, 0.10687707364559174]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9802619218826294, 0.019738124683499336, 0.0, 0.0, 0.0, 0.0], [0.9873908162117004, 0.007800452411174774, 0.004808681085705757, 0.0, 0.0, 0.0], [0.9283918738365173, 0.008301235735416412, 0.01330565195530653, 0.05000120773911476, 0.0, 0.0], [0.8981055021286011, 0.015591299161314964, 0.010177576914429665, 0.039987027645111084, 0.0361386202275753, 0.0], [0.9753499031066895, 0.00035433052107691765, 0.0005866039427928627, 0.0011877501383423805, 0.0010750899091362953, 0.021446440368890762]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9295330047607422, 0.07046692818403244, 0.0, 0.0, 0.0, 0.0], [0.9361506104469299, 0.04116682708263397, 0.022682538256049156, 0.0, 0.0, 0.0], [0.8486821055412292, 0.05802798643708229, 0.024856165051460266, 0.0684337466955185, 0.0, 0.0], [0.8661180734634399, 0.02232467755675316, 0.010369130410254002, 0.02600197121500969, 0.07518619298934937, 0.0], [0.8074421882629395, 0.044382549822330475, 0.01849711686372757, 0.03357789292931557, 0.018561245873570442, 0.07753907144069672]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9680535197257996, 0.03194643557071686, 0.0, 0.0, 0.0, 0.0], [0.9693689942359924, 0.02568492479622364, 0.004946070723235607, 0.0, 0.0, 0.0], [0.9620568156242371, 0.022552406415343285, 0.005471326876431704, 0.009919456206262112, 0.0, 0.0], [0.9727528095245361, 0.010137127712368965, 0.000757327419705689, 0.0028828983195126057, 0.013469807803630829, 0.0], [0.9624635577201843, 0.0031109037809073925, 0.0010007602395489812, 0.0019475930603221059, 0.008266227319836617, 0.02321087196469307]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8542501330375671, 0.14574992656707764, 0.0, 0.0, 0.0, 0.0], [0.9725967645645142, 0.014116315171122551, 0.01328685600310564, 0.0, 0.0, 0.0], [0.9257621765136719, 0.03257262706756592, 0.01461210660636425, 0.027053095400333405, 0.0, 0.0], [0.7923423051834106, 0.027305101975798607, 0.01880674995481968, 0.13854165375232697, 0.023004096001386642, 0.0], [0.6152060627937317, 0.02665526419878006, 0.029352931305766106, 0.05590886250138283, 0.11611279845237732, 0.15676409006118774]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9804654121398926, 0.019534552469849586, 0.0, 0.0, 0.0, 0.0], [0.9882452487945557, 0.007509466726332903, 0.004245325922966003, 0.0, 0.0, 0.0], [0.9584206938743591, 0.0109635591506958, 0.010456060990691185, 0.020159708335995674, 0.0, 0.0], [0.9604811668395996, 0.007182627450674772, 0.003072339342907071, 0.006898913532495499, 0.02236509881913662, 0.0], [0.966888964176178, 0.0032812939025461674, 0.00550054432824254, 0.004234083462506533, 0.005038043484091759, 0.015057181939482689]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9498194456100464, 0.05018055811524391, 0.0, 0.0, 0.0, 0.0], [0.9781363606452942, 0.016430046409368515, 0.0054335566237568855, 0.0, 0.0, 0.0], [0.8618696331977844, 0.036093585193157196, 0.07555554062128067, 0.026481209322810173, 0.0, 0.0], [0.5449837446212769, 0.015411133877933025, 0.023516526445746422, 0.25743600726127625, 0.15865260362625122, 0.0], [0.9571874737739563, 0.0030803855042904615, 0.0014446862041950226, 0.006861559115350246, 0.014818714000284672, 0.01660723052918911]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6156560778617859, 0.3843439519405365, 0.0, 0.0, 0.0, 0.0], [0.36760634183883667, 0.42816370725631714, 0.20423001050949097, 0.0, 0.0, 0.0], [0.16471554338932037, 0.4136792719364166, 0.2509237229824066, 0.17068152129650116, 0.0, 0.0], [0.4184456169605255, 0.1524762362241745, 0.10305401682853699, 0.11071498692035675, 0.21530911326408386, 0.0], [0.19686934351921082, 0.2014620453119278, 0.12827259302139282, 0.09203246980905533, 0.09167550504207611, 0.2896881103515625]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9027364253997803, 0.09726352989673615, 0.0, 0.0, 0.0, 0.0], [0.9736634492874146, 0.014004302211105824, 0.01233230996876955, 0.0, 0.0, 0.0], [0.8504456281661987, 0.05690572410821915, 0.032060906291007996, 0.06058764085173607, 0.0, 0.0], [0.7661210298538208, 0.03530392050743103, 0.03433045372366905, 0.09675204753875732, 0.06749245524406433, 0.0], [0.8650374412536621, 0.020085260272026062, 0.01149806659668684, 0.01855834573507309, 0.018430285155773163, 0.06639053672552109]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9653082489967346, 0.03469168767333031, 0.0, 0.0, 0.0, 0.0], [0.9816323518753052, 0.014176066033542156, 0.004191514104604721, 0.0, 0.0, 0.0], [0.9275256395339966, 0.04737218841910362, 0.01152826938778162, 0.013573966920375824, 0.0, 0.0], [0.9293117523193359, 0.025833239778876305, 0.007227106485515833, 0.014300585724413395, 0.02332727052271366, 0.0], [0.8895062804222107, 0.04689619690179825, 0.0047171092592179775, 0.006286581978201866, 0.00609014043584466, 0.04650374501943588]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8938026428222656, 0.10619727522134781, 0.0, 0.0, 0.0, 0.0], [0.8221707940101624, 0.06304481625556946, 0.11478441953659058, 0.0, 0.0, 0.0], [0.5047380924224854, 0.15375731885433197, 0.2277037501335144, 0.11380083113908768, 0.0, 0.0], [0.4082071781158447, 0.09066355973482132, 0.11696872115135193, 0.24553199112415314, 0.13862857222557068, 0.0], [0.7291035652160645, 0.06638889014720917, 0.023112818598747253, 0.031103096902370453, 0.057143256068229675, 0.09314827620983124]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9247531890869141, 0.07524678111076355, 0.0, 0.0, 0.0, 0.0], [0.8957376480102539, 0.06989553570747375, 0.03436679765582085, 0.0, 0.0, 0.0], [0.7924937605857849, 0.0960114598274231, 0.05509118735790253, 0.056403566151857376, 0.0, 0.0], [0.7891505360603333, 0.07880303263664246, 0.03840155899524689, 0.05396979674696922, 0.03967496380209923, 0.0], [0.7807856798171997, 0.0799354612827301, 0.042531758546829224, 0.03234211727976799, 0.0178169384598732, 0.046588052064180374]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9480886459350586, 0.05191127583384514, 0.0, 0.0, 0.0, 0.0], [0.863694965839386, 0.04756204038858414, 0.08874296396970749, 0.0, 0.0, 0.0], [0.9341371059417725, 0.022224076092243195, 0.022624483332037926, 0.021014342084527016, 0.0, 0.0], [0.9588143229484558, 0.008020909503102303, 0.004490078426897526, 0.005862293299287558, 0.022812429815530777, 0.0], [0.9385918378829956, 0.021227721124887466, 0.0048724692314863205, 0.010940189473330975, 0.009524582885205746, 0.014843451790511608]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9763734340667725, 0.023626558482646942, 0.0, 0.0, 0.0, 0.0], [0.9884802103042603, 0.005189393647015095, 0.0063303736969828606, 0.0, 0.0, 0.0], [0.9477092027664185, 0.0179851483553648, 0.010156610049307346, 0.024149026721715927, 0.0, 0.0], [0.967192530632019, 0.006552813574671745, 0.0033227826934307814, 0.00556332478299737, 0.017368387430906296, 0.0], [0.9584562182426453, 0.007502961438149214, 0.0051363310776650906, 0.008071648888289928, 0.005997124593704939, 0.014835843816399574]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.884070873260498, 0.11592914164066315, 0.0, 0.0, 0.0, 0.0], [0.9931254386901855, 0.005070806015282869, 0.0018038019770756364, 0.0, 0.0, 0.0], [0.9534159302711487, 0.02382904477417469, 0.007748977281153202, 0.015006075613200665, 0.0, 0.0], [0.9151289463043213, 0.010873105376958847, 0.013190957717597485, 0.011050421744585037, 0.04975655674934387, 0.0], [0.8769673109054565, 0.03385210782289505, 0.00848648976534605, 0.009969149716198444, 0.03468578681349754, 0.036039214581251144]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0003709519514814019, 0.999629020690918, 0.0, 0.0, 0.0, 0.0], [6.525027856696397e-05, 0.3737829029560089, 0.6261518597602844, 0.0, 0.0, 0.0], [4.606018774211407e-05, 0.210508793592453, 0.4115968942642212, 0.3778482675552368, 0.0, 0.0], [4.753069515572861e-05, 0.11616954207420349, 0.23264272511005402, 0.3985331058502197, 0.2526070475578308, 0.0], [1.247641534973809e-06, 0.14819711446762085, 0.15813173353672028, 0.30074331164360046, 0.11939018964767456, 0.27353641390800476]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.971555769443512, 0.028444187715649605, 0.0, 0.0, 0.0, 0.0], [0.9529065489768982, 0.03233075141906738, 0.014762768521904945, 0.0, 0.0, 0.0], [0.9343128204345703, 0.02351292595267296, 0.02049802988767624, 0.021676240488886833, 0.0, 0.0], [0.9529678225517273, 0.00855141133069992, 0.004359325394034386, 0.008064556866884232, 0.026056913658976555, 0.0], [0.9653593897819519, 0.008487647399306297, 0.003499280195683241, 0.002721576252952218, 0.0032828773837536573, 0.016649367287755013]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8630780577659607, 0.13692188262939453, 0.0, 0.0, 0.0, 0.0], [0.7696157097816467, 0.0851333811879158, 0.14525099098682404, 0.0, 0.0, 0.0], [0.7133337259292603, 0.10170899331569672, 0.11931268870830536, 0.06564456224441528, 0.0, 0.0], [0.7186222076416016, 0.05444284901022911, 0.01386815495789051, 0.07808027416467667, 0.13498654961585999, 0.0], [0.7990148663520813, 0.05805593729019165, 0.009447019547224045, 0.017770467326045036, 0.02113853208720684, 0.09457314014434814]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9518988728523254, 0.048101115971803665, 0.0, 0.0, 0.0, 0.0], [0.8580653071403503, 0.02944577857851982, 0.11248888075351715, 0.0, 0.0, 0.0], [0.6577738523483276, 0.08513449877500534, 0.1261308640241623, 0.1309608370065689, 0.0, 0.0], [0.8087368607521057, 0.0323016420006752, 0.01841817982494831, 0.06856140494346619, 0.07198194414377213, 0.0], [0.6683295965194702, 0.13281384110450745, 0.021880635991692543, 0.02787741646170616, 0.04923408478498459, 0.0998644009232521]]]], \"left_text\": [\"No\", \",\", \" I\", \" am\", \" your\", \" father\"], \"right_text\": [\"No\", \",\", \" I\", \" am\", \" your\", \" father\"]}], \"default_filter\": \"0\", \"display_mode\": \"dark\", \"root_div_id\": \"bertviz-300f38de2d1b4e66a8cc391d887f8db3\", \"include_layers\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], \"include_heads\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], \"total_heads\": 12} is a template marker that is replaced by actual params.\n",
       "        const config = {};\n",
       "\n",
       "        const MIN_X = 0;\n",
       "        const MIN_Y = 0;\n",
       "        const DIV_WIDTH = 970;\n",
       "        const THUMBNAIL_PADDING = 5;\n",
       "        const DETAIL_WIDTH = 300;\n",
       "        const DETAIL_ATTENTION_WIDTH = 140;\n",
       "        const DETAIL_BOX_WIDTH = 80;\n",
       "        const DETAIL_BOX_HEIGHT = 18;\n",
       "        const DETAIL_PADDING = 15;\n",
       "        const ATTN_PADDING = 0;\n",
       "        const DETAIL_HEADING_HEIGHT = 25;\n",
       "        const HEADING_TEXT_SIZE = 15;\n",
       "        const HEADING_PADDING = 5;\n",
       "        const TEXT_SIZE = 13;\n",
       "        const TEXT_PADDING = 5;\n",
       "        const LAYER_COLORS = d3.schemeCategory10;\n",
       "        const PALETTE = {\n",
       "            'light': {\n",
       "                'text': 'black',\n",
       "                'background': 'white',\n",
       "                'highlight': '#F5F5F5'\n",
       "            },\n",
       "            'dark': {\n",
       "                'text': '#ccc',\n",
       "                'background': 'black',\n",
       "                'highlight': '#222'\n",
       "            }\n",
       "        }\n",
       "\n",
       "        function render() {\n",
       "\n",
       "            // Set global state variables\n",
       "\n",
       "            var attData = config.attention[config.filter];\n",
       "            config.leftText = attData.left_text;\n",
       "            config.rightText = attData.right_text;\n",
       "            config.attn = attData.attn;\n",
       "            config.numLayers = config.attn.length;\n",
       "            config.numHeads = config.attn[0].length;\n",
       "            config.thumbnailBoxHeight = 7 * (12 / config.totalHeads);\n",
       "            const axisSize = HEADING_TEXT_SIZE + HEADING_PADDING + TEXT_SIZE + TEXT_PADDING;\n",
       "            config.thumbnailHeight = Math.max(config.leftText.length, config.rightText.length) * config.thumbnailBoxHeight + 2 * THUMBNAIL_PADDING;\n",
       "            config.thumbnailWidth = (DIV_WIDTH - axisSize) / config.totalHeads;\n",
       "            config.detailHeight = Math.max(config.leftText.length, config.rightText.length) * DETAIL_BOX_HEIGHT + 2 * DETAIL_PADDING + DETAIL_HEADING_HEIGHT;\n",
       "            config.divHeight = Math.max(config.numLayers * config.thumbnailHeight + axisSize, config.detailHeight);\n",
       "\n",
       "            const vis = $(`#${config.rootDivId} #vis`)\n",
       "            vis.empty();\n",
       "            vis.attr(\"height\", config.divHeight);\n",
       "            config.svg = d3.select(`#${config.rootDivId} #vis`)\n",
       "                .append('svg')\n",
       "                .attr(\"width\", DIV_WIDTH)\n",
       "                .attr(\"height\", config.divHeight)\n",
       "                .attr(\"fill\", getBackgroundColor());\n",
       "\n",
       "            renderAxisLabels();\n",
       "\n",
       "            var i;\n",
       "            var j;\n",
       "            for (i = 0; i < config.numLayers; i++) {\n",
       "                for (j = 0; j < config.numHeads; j++) {\n",
       "                    renderThumbnail(i, j);\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "\n",
       "        function renderAxisLabels() {\n",
       "            const axisSize = HEADING_TEXT_SIZE + HEADING_PADDING + TEXT_SIZE + TEXT_PADDING;\n",
       "            const tableWidth = config.thumbnailWidth * config.heads.length;\n",
       "            config.svg.append(\"text\")\n",
       "                .text(\"Heads\")\n",
       "                .attr(\"fill\", \"black\")\n",
       "                .attr(\"font-weight\", \"bold\")\n",
       "                .attr(\"font-size\", HEADING_TEXT_SIZE + \"px\")\n",
       "                .attr(\"x\", axisSize + tableWidth / 2)\n",
       "                .attr(\"text-anchor\", \"middle\")\n",
       "                .attr(\"y\", 0)\n",
       "                .attr(\"dy\", HEADING_TEXT_SIZE);\n",
       "            for (let i = 0; i < config.numHeads; i++) {\n",
       "                config.svg.append(\"text\")\n",
       "                    .text(config.heads[i])\n",
       "                    .attr(\"fill\", \"black\")\n",
       "                    .attr(\"font-size\", TEXT_SIZE + \"px\")\n",
       "                    .attr(\"x\", axisSize + (i + .5) * config.thumbnailWidth)\n",
       "                    .attr(\"text-anchor\", \"middle\")\n",
       "                    .attr(\"y\", HEADING_TEXT_SIZE + HEADING_PADDING)\n",
       "                    .attr(\"dy\", TEXT_SIZE);\n",
       "            }\n",
       "            let x = 0;\n",
       "            let y = axisSize + config.thumbnailHeight * config.layers.length / 2;\n",
       "            console.log(\"x\", x, y)\n",
       "            config.svg.append(\"text\")\n",
       "                .text(\"Layers\")\n",
       "                .attr(\"fill\", \"black\")\n",
       "                .attr(\"font-weight\", \"bold\")\n",
       "                .attr(\"transform\", \"rotate(270, \" + x  + \", \" + y + \")\")\n",
       "                .attr(\"font-size\", HEADING_TEXT_SIZE + \"px\")\n",
       "                .attr(\"x\", x)\n",
       "                .attr(\"text-anchor\", \"middle\")\n",
       "                .attr(\"y\", y)\n",
       "                .attr(\"dy\", HEADING_TEXT_SIZE);\n",
       "            for (let i = 0; i < config.numLayers; i++) {\n",
       "                x = HEADING_TEXT_SIZE + HEADING_PADDING + TEXT_SIZE; // HACK\n",
       "                y = axisSize + (i + .5) * config.thumbnailHeight;\n",
       "                config.svg.append(\"text\")\n",
       "                    .text(config.layers[i])\n",
       "                    .attr(\"fill\", \"black\")\n",
       "                    .attr(\"font-size\", TEXT_SIZE + \"px\")\n",
       "                    .attr(\"x\", x)\n",
       "                    .attr(\"text-anchor\", \"end\")\n",
       "                    .attr(\"y\", y)\n",
       "                    .attr(\"dy\", TEXT_SIZE / 2);\n",
       "            }\n",
       "        }\n",
       "\n",
       "\n",
       "        function renderThumbnail(layerIndex, headIndex) {\n",
       "            const axisSize = HEADING_TEXT_SIZE + HEADING_PADDING + TEXT_SIZE + TEXT_PADDING\n",
       "            const x = headIndex * config.thumbnailWidth + axisSize;\n",
       "            const y = layerIndex * config.thumbnailHeight + axisSize;\n",
       "            renderThumbnailAttn(x, y, config.attn[layerIndex][headIndex], layerIndex, headIndex);\n",
       "        }\n",
       "\n",
       "        function renderDetail(att, layerIndex, headIndex) {\n",
       "            const axisSize = TEXT_SIZE + HEADING_PADDING + TEXT_SIZE + TEXT_PADDING;\n",
       "            var xOffset = .8 * config.thumbnailWidth;\n",
       "            var maxX = DIV_WIDTH;\n",
       "            var maxY = config.divHeight - 3;\n",
       "            var leftPos = axisSize + headIndex * config.thumbnailWidth;\n",
       "            var x = leftPos + THUMBNAIL_PADDING + xOffset;\n",
       "            if (x < MIN_X) {\n",
       "                x = MIN_X;\n",
       "            } else if (x + DETAIL_WIDTH > maxX) {\n",
       "                x = leftPos + THUMBNAIL_PADDING - DETAIL_WIDTH + 8;\n",
       "            }\n",
       "            var posLeftText = x;\n",
       "            var posAttention = posLeftText + DETAIL_BOX_WIDTH;\n",
       "            var posRightText = posAttention + DETAIL_ATTENTION_WIDTH;\n",
       "            var thumbnailHeight = Math.max(config.leftText.length, config.rightText.length) * config.thumbnailBoxHeight + 2 * THUMBNAIL_PADDING;\n",
       "            var yOffset = 20;\n",
       "            var y = layerIndex * thumbnailHeight + THUMBNAIL_PADDING + yOffset;\n",
       "            if (y < MIN_Y) {\n",
       "                y = MIN_Y;\n",
       "            } else if (y + config.detailHeight > maxY) {\n",
       "                y = maxY - config.detailHeight;\n",
       "            }\n",
       "            renderDetailFrame(x, y, layerIndex);\n",
       "            y = y + DETAIL_PADDING;\n",
       "            renderDetailHeading(x, y, layerIndex, headIndex);\n",
       "            y = y + DETAIL_HEADING_HEIGHT;\n",
       "            renderDetailText(config.leftText, \"leftText\", posLeftText, y , layerIndex);\n",
       "            renderDetailAttn(posAttention, y, att, layerIndex, headIndex);\n",
       "            renderDetailText(config.rightText, \"rightText\", posRightText, y, layerIndex);\n",
       "        }\n",
       "\n",
       "        function renderDetailHeading(x, y, layerIndex, headIndex) {\n",
       "            var fillColor = getTextColor();\n",
       "            config.svg.append(\"text\")\n",
       "                .classed(\"detail\", true)\n",
       "                .text('Layer ' + config.layers[layerIndex] + \", Head \" + config.heads[headIndex])\n",
       "                .attr(\"font-size\", TEXT_SIZE + \"px\")\n",
       "                .attr(\"font-weight\", \"bold\")\n",
       "                .style(\"cursor\", \"default\")\n",
       "                .style(\"-webkit-user-select\", \"none\")\n",
       "                .attr(\"fill\", fillColor)\n",
       "                .attr(\"x\", x + DETAIL_WIDTH / 2)\n",
       "                .attr(\"text-anchor\", \"middle\")\n",
       "                .attr(\"y\", y)\n",
       "                .attr(\"height\", DETAIL_HEADING_HEIGHT)\n",
       "                .attr(\"width\", DETAIL_WIDTH)\n",
       "                .attr(\"dy\", HEADING_TEXT_SIZE);\n",
       "        }\n",
       "\n",
       "        function renderDetailText(text, id, x, y, layerIndex) {\n",
       "            var tokenContainer = config.svg.append(\"svg:g\")\n",
       "                .classed(\"detail\", true)\n",
       "                .selectAll(\"g\")\n",
       "                .data(text)\n",
       "                .enter()\n",
       "                .append(\"g\");\n",
       "\n",
       "            var fillColor = getTextColor();\n",
       "\n",
       "            tokenContainer.append(\"rect\")\n",
       "                .classed(\"highlight\", true)\n",
       "                .attr(\"fill\", fillColor)\n",
       "                .style(\"opacity\", 0.0)\n",
       "                .attr(\"height\", DETAIL_BOX_HEIGHT)\n",
       "                .attr(\"width\", DETAIL_BOX_WIDTH)\n",
       "                .attr(\"x\", x)\n",
       "                .attr(\"y\", function (d, i) {\n",
       "                    return y + i * DETAIL_BOX_HEIGHT;\n",
       "                });\n",
       "\n",
       "            var textContainer = tokenContainer.append(\"text\")\n",
       "                .classed(\"token\", true)\n",
       "                .text(function (d) {\n",
       "                    return d;\n",
       "                })\n",
       "                .attr(\"font-size\", TEXT_SIZE + \"px\")\n",
       "                .style(\"cursor\", \"default\")\n",
       "                .style(\"-webkit-user-select\", \"none\")\n",
       "                .attr(\"fill\", fillColor)\n",
       "                .attr(\"x\", x)\n",
       "                .attr(\"y\", function (d, i) {\n",
       "                    return i * DETAIL_BOX_HEIGHT + y;\n",
       "                })\n",
       "                .attr(\"height\", DETAIL_BOX_HEIGHT)\n",
       "                .attr(\"width\", DETAIL_BOX_WIDTH)\n",
       "                .attr(\"dy\", TEXT_SIZE);\n",
       "\n",
       "            if (id == \"leftText\") {\n",
       "                textContainer.style(\"text-anchor\", \"end\")\n",
       "                    .attr(\"dx\", DETAIL_BOX_WIDTH - 2);\n",
       "                tokenContainer.on(\"mouseover\", function (d, index) {\n",
       "                    highlightSelection(index);\n",
       "                });\n",
       "                tokenContainer.on(\"mouseleave\", function () {\n",
       "                    unhighlightSelection();\n",
       "                });\n",
       "            }\n",
       "        }\n",
       "\n",
       "        function highlightSelection(index) {\n",
       "            config.svg.select(\"#leftText\")\n",
       "                .selectAll(\".highlight\")\n",
       "                .style(\"opacity\", function (d, i) {\n",
       "                    return i == index ? 1.0 : 0.0;\n",
       "                });\n",
       "            config.svg.selectAll(\".attn-line-group\")\n",
       "                .style(\"opacity\", function (d, i) {\n",
       "                    return i == index ? 1.0 : 0.0;\n",
       "                });\n",
       "        }\n",
       "\n",
       "        function unhighlightSelection() {\n",
       "            config.svg.select(\"#leftText\")\n",
       "                .selectAll(\".highlight\")\n",
       "                .style(\"opacity\", 0.0);\n",
       "            config.svg.selectAll(\".attn-line-group\")\n",
       "                .style(\"opacity\", 1);\n",
       "        }\n",
       "\n",
       "        function renderThumbnailAttn(x, y, att, layerIndex, headIndex) {\n",
       "\n",
       "            var attnContainer = config.svg.append(\"svg:g\");\n",
       "\n",
       "            var attnBackground = attnContainer.append(\"rect\")\n",
       "                .attr(\"id\", 'attn_background_' + layerIndex + \"_\" + headIndex)\n",
       "                .classed(\"attn_background\", true)\n",
       "                .attr(\"x\", x)\n",
       "                .attr(\"y\", y)\n",
       "                .attr(\"height\", config.thumbnailHeight)\n",
       "                .attr(\"width\", config.thumbnailWidth)\n",
       "                .attr(\"stroke-width\", 2)\n",
       "                .attr(\"stroke\", getLayerColor(layerIndex))\n",
       "                .attr(\"stroke-opacity\", 0)\n",
       "                .attr(\"fill\", getBackgroundColor());\n",
       "            var x1 = x + THUMBNAIL_PADDING;\n",
       "            var x2 = x1 + config.thumbnailWidth - 14;\n",
       "            var y1 = y + THUMBNAIL_PADDING;\n",
       "\n",
       "            attnContainer.selectAll(\"g\")\n",
       "                .data(att)\n",
       "                .enter()\n",
       "                .append(\"g\") // Add group for each source token\n",
       "                .attr(\"source-index\", function (d, i) { // Save index of source token\n",
       "                    return i;\n",
       "                })\n",
       "                .selectAll(\"line\")\n",
       "                .data(function (d) { // Loop over all target tokens\n",
       "                    return d;\n",
       "                })\n",
       "                .enter() // When entering\n",
       "                .append(\"line\")\n",
       "                .attr(\"x1\", x1)\n",
       "                .attr(\"y1\", function (d) {\n",
       "                    var sourceIndex = +this.parentNode.getAttribute(\"source-index\");\n",
       "                    return y1 + (sourceIndex + .5) * config.thumbnailBoxHeight;\n",
       "                })\n",
       "                .attr(\"x2\", x2)\n",
       "                .attr(\"y2\", function (d, targetIndex) {\n",
       "                    return y1 + (targetIndex + .5) * config.thumbnailBoxHeight;\n",
       "                })\n",
       "                .attr(\"stroke-width\", 2.2)\n",
       "                .attr(\"stroke\", getLayerColor(layerIndex))\n",
       "                .attr(\"stroke-opacity\", function (d) {\n",
       "                    return d;\n",
       "                });\n",
       "\n",
       "            var clickRegion = attnContainer.append(\"rect\")\n",
       "                .attr(\"x\", x)\n",
       "                .attr(\"y\", y)\n",
       "                .attr(\"height\", config.thumbnailHeight)\n",
       "                .attr(\"width\", config.thumbnailWidth)\n",
       "                .style(\"opacity\", 0);\n",
       "\n",
       "            clickRegion.on(\"click\", function (d, index) {\n",
       "                var attnBackgroundOther = config.svg.selectAll(\".attn_background\");\n",
       "                attnBackgroundOther.attr(\"fill\", getBackgroundColor());\n",
       "                attnBackgroundOther.attr(\"stroke-opacity\", 0);\n",
       "\n",
       "                config.svg.selectAll(\".detail\").remove();\n",
       "                if (config.detail_layer != layerIndex || config.detail_head != headIndex) {\n",
       "                    renderDetail(att, layerIndex, headIndex);\n",
       "                    config.detail_layer = layerIndex;\n",
       "                    config.detail_head = headIndex;\n",
       "                    attnBackground.attr(\"fill\", getHighlightColor());\n",
       "                    attnBackground.attr(\"stroke-opacity\", .8);\n",
       "                } else {\n",
       "                    config.detail_layer = null;\n",
       "                    config.detail_head = null;\n",
       "                    attnBackground.attr(\"fill\", getBackgroundColor());\n",
       "                    attnBackground.attr(\"stroke-opacity\", 0);\n",
       "                }\n",
       "            });\n",
       "\n",
       "            clickRegion.on(\"mouseover\", function (d) {\n",
       "                d3.select(this).style(\"cursor\", \"pointer\");\n",
       "            });\n",
       "        }\n",
       "\n",
       "        function renderDetailFrame(x, y, layerIndex) {\n",
       "            var detailFrame = config.svg.append(\"rect\")\n",
       "                .classed(\"detail\", true)\n",
       "                .attr(\"x\", x)\n",
       "                .attr(\"y\", y)\n",
       "                .attr(\"height\", config.detailHeight)\n",
       "                .attr(\"width\", DETAIL_WIDTH)\n",
       "                .style(\"opacity\", 1)\n",
       "                .attr(\"stroke-width\", 1.5)\n",
       "                .attr(\"stroke-opacity\", 0.7)\n",
       "                .attr(\"stroke\", getLayerColor(layerIndex));\n",
       "        }\n",
       "\n",
       "        function renderDetailAttn(x, y, att, layerIndex) {\n",
       "            var attnContainer = config.svg.append(\"svg:g\")\n",
       "                .classed(\"detail\", true)\n",
       "                .attr(\"pointer-events\", \"none\");\n",
       "            attnContainer.selectAll(\"g\")\n",
       "                .data(att)\n",
       "                .enter()\n",
       "                .append(\"g\") // Add group for each source token\n",
       "                .classed('attn-line-group', true)\n",
       "                .attr(\"source-index\", function (d, i) { // Save index of source token\n",
       "                    return i;\n",
       "                })\n",
       "                .selectAll(\"line\")\n",
       "                .data(function (d) { // Loop over all target tokens\n",
       "                    return d;\n",
       "                })\n",
       "                .enter()\n",
       "                .append(\"line\")\n",
       "                .attr(\"x1\", x + ATTN_PADDING)\n",
       "                .attr(\"y1\", function (d) {\n",
       "                    var sourceIndex = +this.parentNode.getAttribute(\"source-index\");\n",
       "                    return y + (sourceIndex + .5) * DETAIL_BOX_HEIGHT;\n",
       "                })\n",
       "                .attr(\"x2\", x + DETAIL_ATTENTION_WIDTH - ATTN_PADDING)\n",
       "                .attr(\"y2\", function (d, targetIndex) {\n",
       "                    return y + (targetIndex + .5) * DETAIL_BOX_HEIGHT;\n",
       "                })\n",
       "                .attr(\"stroke-width\", 2.2)\n",
       "                .attr(\"stroke\", getLayerColor(layerIndex))\n",
       "                .attr(\"stroke-opacity\", function (d) {\n",
       "                    return d;\n",
       "                });\n",
       "        }\n",
       "\n",
       "        function getLayerColor(layer) {\n",
       "          return LAYER_COLORS[config.layers[layer] % 10];\n",
       "        }\n",
       "\n",
       "        function getTextColor() {\n",
       "            return PALETTE[config.mode]['text']\n",
       "        }\n",
       "\n",
       "        function getBackgroundColor() {\n",
       "           return PALETTE[config.mode]['background']\n",
       "        }\n",
       "\n",
       "        function getHighlightColor() {\n",
       "           return PALETTE[config.mode]['highlight']\n",
       "        }\n",
       "\n",
       "        function initialize() {\n",
       "            config.attention = params['attention'];\n",
       "            config.filter = params['default_filter'];\n",
       "            config.mode = params['display_mode'];\n",
       "            config.layers = params['include_layers']\n",
       "            config.heads = params['include_heads']\n",
       "            config.totalHeads = params['total_heads']\n",
       "            config.rootDivId = params['root_div_id'];\n",
       "            $(`#${config.rootDivId} #filter`).on('change', function (e) {\n",
       "                config.filter = e.currentTarget.value;\n",
       "                render();\n",
       "            });\n",
       "        }\n",
       "\n",
       "        initialize();\n",
       "        render();\n",
       "\n",
       "    });"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, utils, AutoModelForCausalLM\n",
    "\n",
    "from bertviz import model_view\n",
    "utils.logging.set_verbosity_error()  # Suppress standard warnings\n",
    "\n",
    "model_name = 'openai-community/gpt2'\n",
    "input_text = \"No, I am your father\"  \n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, output_attentions=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "inputs = tokenizer.encode(input_text, return_tensors='pt')  # Tokenize input text\n",
    "outputs = model(inputs)  # Run model\n",
    "attention = outputs[-1]  # Retrieve attention from model outputs\n",
    "tokens = tokenizer.convert_ids_to_tokens(inputs[0])  # Convert input ids to token strings\n",
    "model_view(attention, tokens)  # Display model view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positional encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IFq78-kjbrWp"
   },
   "source": [
    "Last week, Carlo discussed token embedding, which is when words are encoded into a vocabulary. Now, we just discussed attention mechanisms which account for context between words. Another question we should ask is how do we account for the order of words in an input sentence\n",
    "\n",
    "Consider the following two sentences to see why this is important:\n",
    "\n",
    "``The man ate the sandwich.``\n",
    "\n",
    "``The sandwich ate the man.``\n",
    "\n",
    "Clearly, these are two vastly different situations even though they have the same words. The Transformer can \n",
    "\n",
    "Transformers differentiate between these situations by adding a **Positional encoding** vector to each input embedding. These vectors follow a specific pattern that the model learns, which helps it determine the position of each word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/positional_encoding.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "Image credit: https://medium.com/@xuer.chen.human/llm-study-notes-positional-encoding-0639a1002ec0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set up positional encoding similarly as token embedding using the ``nn.Embedding`` tool. We use a simple embedding here but there are more complex positional encodings used such as sinusoidal. \n",
    "\n",
    "For an explanation of different positional encodings, refer to this post: https://machinelearningmastery.com/a-gentle-introduction-to-positional-encoding-in-transformer-models-part-1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 65\n",
    "n_embd = 64\n",
    "\n",
    "token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "block_size = 32 # what is the maximum context length for predictions?\n",
    "position_embedding_table = nn.Embedding(block_size, n_embd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will notice the positional encoding size is `(block_size, n_embed)` because it encodes for the postion of a token within the sequence of size `block_size`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, the position embedding used is simply added to the token embedding to apply positional embedding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at token embedding alone:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-9.6630e-05, -1.4031e+00,  6.1625e-01,  3.0717e-02,  1.2290e-01,\n",
      "        -4.0682e-01,  1.9496e+00,  1.1764e+00, -1.5591e+00,  7.2791e-02,\n",
      "        -2.3081e+00, -5.0737e-01, -6.9863e-01, -1.3517e+00, -2.1065e-02,\n",
      "        -9.5309e-01, -1.0516e+00,  7.7541e-02,  4.4402e-01,  8.8709e-01,\n",
      "         1.8823e-01,  7.1672e-02, -3.4917e-01, -5.7223e-01,  3.5027e-01,\n",
      "         7.1300e-01, -4.1757e-01,  1.2332e+00, -1.0018e+00,  6.6873e-01,\n",
      "         9.4601e-03, -1.8759e+00,  3.9894e-01,  6.6391e-01,  6.4071e-02,\n",
      "         1.6804e+00,  6.2182e-01, -1.6898e+00, -3.4645e-01, -3.1754e+00,\n",
      "         9.4335e-01,  1.7508e+00, -7.7534e-01, -8.0301e-01,  2.6676e+00,\n",
      "         3.1534e-01, -5.9224e-01,  4.7193e-01,  6.4641e-01,  4.3199e-01,\n",
      "         1.4329e+00, -1.0546e+00,  1.6986e+00, -1.2204e+00, -1.2765e-02,\n",
      "        -1.3485e+00, -4.3946e-01, -1.3725e-01,  4.2354e-01, -4.0840e-01,\n",
      "        -7.1900e-01, -6.6362e-01, -8.9380e-02,  1.4980e-01],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1,3,15,4,7,1,4,9])\n",
    "x = token_embedding_table(x)\n",
    "print(x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And token + positional embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.6103, -1.1454,  0.2832, -0.5627, -0.7867, -0.7475,  1.6190,  0.4168,\n",
      "        -2.4363,  0.1630, -2.2069,  0.1004,  0.3215, -0.9887, -0.2308,  0.1534,\n",
      "        -1.2566, -0.2798, -0.0496, -0.0997,  0.9740,  0.4581,  0.7802, -0.1746,\n",
      "         0.0531, -1.5154,  0.3336,  2.4084, -1.0335,  1.3728, -1.2628, -0.5919,\n",
      "         0.2460, -0.2431,  2.1009,  0.5958, -0.4106, -2.4724, -1.7571, -3.5932,\n",
      "         0.4605,  0.8671, -1.9192, -3.0066,  1.6024, -1.5752,  0.7494,  0.8431,\n",
      "         2.0244,  1.0557,  0.2076,  0.2220,  0.2793, -2.0823,  0.6992, -1.1937,\n",
      "        -0.3509,  0.8347,  1.0244,  0.5620, -0.3641, -1.3770, -0.1733, -1.4676],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1,3,15,4,7,1,4,9])\n",
    "x= position_embedding_table(x) + token_embedding_table(x)\n",
    "print(x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see a clear offset between these two embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the training process, these embeddings will be learned to best encode the token and positional embeddings of the sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iF1HzH9xNJ7S"
   },
   "source": [
    "## Output layers\n",
    "\n",
    "At the end of our Transformer model, we are left with a vector, so how do we turn this into a word?\n",
    "\n",
    "<img src=\"images/transformer-decoder-intro.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "Using a final Linear layer and a Softmax Layer.\n",
    "The Linear layer projects the vector produced by the stack of decoders, into a larger vector called a logits vector.\n",
    "\n",
    "If our model knows 10,000 unique English words learned from its training dataset the logits vector is 10,000 cells wide ‚Äì each cell corresponds to the score of a unique word.\n",
    "\n",
    "The softmax layer turns those scores into probabilities. The cell with the highest probability is chosen, and the word associated with it is produced as the output for this time step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/transformer_decoder_output_softmax.png\" alt=\"Drawing\" style=\"width: 450px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HS6r-z8dN_RV"
   },
   "source": [
    "Image credit: https://jalammar.github.io/illustrated-transformer/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XK8q67P03yr4"
   },
   "source": [
    "## Training\n",
    "\n",
    "How does an LLM improve over time?\n",
    "We want to compare the probabilitiy distribution for each token generated by our model to the ground truths. \n",
    "Our model produces a probability distribution for each token. We want to compare these probability distributions to the ground truths. \n",
    "For example, when translating the sentence: ‚Äúje suis √©tudiant‚Äù into ‚Äúi am a student‚Äù as can be seen in the example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/output_target_probability_distributions.png\" alt=\"Drawing\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HS6r-z8dN_RV"
   },
   "source": [
    "Image credit: https://jalammar.github.io/illustrated-transformer/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model can calculate the loss between the vector it generates and the ground truth vector seen in this example. A commonly used loss function is cross entropy loss:\n",
    "\n",
    "$CE = -\\sum_{x \\in X} p(x) log q(x)$\n",
    "\n",
    "where p(x) represents the true distribution and q(x) represents the predicted distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9119)\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import functional as F\n",
    "logits = torch.tensor([0.5, 0.1, 0.3])\n",
    "targets = torch.tensor([1.0, 0.0, 0.0])\n",
    "loss = F.cross_entropy(logits, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another important metric commonly used in LLMs is **perplexity**.\n",
    "\n",
    "Intuitively, perplexity means to be surprised. We measure how much the model is surprised by seeing new data. The lower the perplexity, the better the training is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mathematically, perplexity is just the exponent of the negative cross entropy loss:\n",
    "\n",
    "$\\text{perplexity} = exp(\\text{CE})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.4891)\n"
     ]
    }
   ],
   "source": [
    "perplexity = torch.exp(loss)\n",
    "print(perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we are using cross entropy loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's train a mini-LLM from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "batch_size = 16 # how many independent sequences will we process in parallel?\n",
    "block_size = 32 # what is the maximum context length for predictions?\n",
    "max_iters = 5000\n",
    "eval_interval = 10\n",
    "learning_rate = 1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embd = 64\n",
    "n_head = 4 ## so head_size = 16\n",
    "n_layer = 4\n",
    "dropout = 0.0\n",
    "# ------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in data and create train and test datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to be using the tiny Shakespeare dataset. \n",
    "Data is tokenized according to a simple character based tokenizer.\n",
    "Data is split into a train and test set so we have something to test after performing training (9:1 split)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset/input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# here are all the unique characters that occur in this text\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "# create a mapping from characters to integers\n",
    "stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "itos = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
    "\n",
    "# Train and test splits\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "# data loading\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the components of the Decoder block: \n",
    "* MultiHeadAttention\n",
    "* FeedForward Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    \"\"\" one head of self-attention \"\"\"\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)   # (B,T,C) 16,32,16\n",
    "        q = self.query(x) # (B,T,C)\n",
    "        # compute attention scores (\"affinities\")\n",
    "        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
    "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "        wei = self.dropout(wei)\n",
    "        # perform the weighted aggregation of the values\n",
    "        v = self.value(x) # (B,T,C)\n",
    "        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
    "        return out\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
    "\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(n_embd, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out\n",
    "\n",
    "class FeedFoward(nn.Module):\n",
    "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd), # Projection layer going back into the residual pathway\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine components into the Decoder block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedFoward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x))    # Communication\n",
    "        x = x + self.ffwd(self.ln2(x))  # Computation\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the full Transformer model \n",
    "This is a combination of the Token embeddings, Positional embeddings, a stack of Transformer blocks and an output block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# super simple language model\n",
    "class LanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "\n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
    "        x = tok_emb + pos_emb # (B,T,C)\n",
    "        x = self.blocks(x) # (B,T,C)\n",
    "        x = self.ln_f(x) # (B,T,C)\n",
    "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop idx to the last block_size tokens\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx_cond)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be training a larger LLM on distributed resources in session 6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework\n",
    "\n",
    "1. In this notebook, we learned the various components of an LLM. \n",
    "    Your homework this week is to take the mini LLM we created from scratch and run your own training loop. Show how the training and validation perplexity change over the steps.\n",
    "      \n",
    "    Hint: this function might be useful for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss(model):\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            \n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop():\n",
    "    model = LanguageModel().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    epoch_list = []\n",
    "    \n",
    "    for i in range(max_iters):\n",
    "        bx, by = get_batch('train')\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits, loss = model(bx,by)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        if i % (eval_interval*10) == 0:\n",
    "            out = estimate_loss(model)\n",
    "            train_loss = out['train']\n",
    "            val_loss = out['val']\n",
    "            \n",
    "            train_losses.append(torch.exp(train_loss))\n",
    "            val_losses.append(torch.exp(val_loss))\n",
    "            epoch_list.append(i)\n",
    "            \n",
    "            print(f\"Epoch {i} --- Train Perp: {train_losses[-1]}  Test Perp: {val_losses[-1]}\")\n",
    "    \n",
    "    return epoch_list, train_losses, val_losses\n",
    "\n",
    "def plot_losses(epoch_list, train_losses, val_losses):\n",
    "    plt.plot(epoch_list, train_losses, label=\"Training\")\n",
    "    plt.plot(epoch_list, val_losses, label=\"Test\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Perplexity\")\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "ep, train, val = train_loop()\n",
    "plot_losses(ep, train, val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Run the same training loop but modify one of the hyperparameters from this list: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "n_embd = 64\n",
    "n_head = 4 ## so head_size = 16\n",
    "n_layer = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this at least 4 times with a different value and plot each perplexity over training step. Write a sentence on how the perplexity changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Layers: 4\n",
      "Epoch 0 --- Train Perp: 62.6646728515625  Test Perp: 63.28291702270508\n",
      "Epoch 100 --- Train Perp: 14.17832088470459  Test Perp: 14.58409595489502\n",
      "Epoch 200 --- Train Perp: 12.23057746887207  Test Perp: 12.426261901855469\n",
      "Epoch 300 --- Train Perp: 11.323020935058594  Test Perp: 11.49283218383789\n",
      "Epoch 400 --- Train Perp: 10.497087478637695  Test Perp: 10.64255428314209\n",
      "Epoch 500 --- Train Perp: 9.939477920532227  Test Perp: 10.053887367248535\n",
      "Epoch 600 --- Train Perp: 9.418521881103516  Test Perp: 9.606573104858398\n",
      "Epoch 700 --- Train Perp: 9.181197166442871  Test Perp: 9.319085121154785\n",
      "Epoch 800 --- Train Perp: 8.659531593322754  Test Perp: 8.937132835388184\n",
      "Epoch 900 --- Train Perp: 8.281464576721191  Test Perp: 8.638931274414062\n",
      "Epoch 1000 --- Train Perp: 8.17470932006836  Test Perp: 8.449678421020508\n",
      "Epoch 1100 --- Train Perp: 7.836300373077393  Test Perp: 8.229340553283691\n",
      "Epoch 1200 --- Train Perp: 7.517809867858887  Test Perp: 7.975499629974365\n",
      "Epoch 1300 --- Train Perp: 7.329225063323975  Test Perp: 7.901793956756592\n",
      "Epoch 1400 --- Train Perp: 7.204476833343506  Test Perp: 7.726705074310303\n",
      "Epoch 1500 --- Train Perp: 7.048234462738037  Test Perp: 7.5564398765563965\n",
      "Epoch 1600 --- Train Perp: 6.884546279907227  Test Perp: 7.481169700622559\n",
      "Epoch 1700 --- Train Perp: 6.763359546661377  Test Perp: 7.431771278381348\n",
      "Epoch 1800 --- Train Perp: 6.678088665008545  Test Perp: 7.354753017425537\n",
      "Epoch 1900 --- Train Perp: 6.55177640914917  Test Perp: 7.244131565093994\n",
      "Epoch 2000 --- Train Perp: 6.41046142578125  Test Perp: 7.124107837677002\n",
      "Epoch 2100 --- Train Perp: 6.322437763214111  Test Perp: 6.997826099395752\n",
      "Epoch 2200 --- Train Perp: 6.278186798095703  Test Perp: 7.0215044021606445\n",
      "Epoch 2300 --- Train Perp: 6.171290874481201  Test Perp: 7.056551456451416\n",
      "Epoch 2400 --- Train Perp: 6.143257141113281  Test Perp: 6.943428993225098\n",
      "Epoch 2500 --- Train Perp: 6.093334197998047  Test Perp: 6.870474815368652\n",
      "Epoch 2600 --- Train Perp: 5.949706554412842  Test Perp: 6.80783224105835\n",
      "Epoch 2700 --- Train Perp: 5.848403453826904  Test Perp: 6.697311878204346\n",
      "Epoch 2800 --- Train Perp: 5.8951263427734375  Test Perp: 6.760860919952393\n",
      "Epoch 2900 --- Train Perp: 5.805454254150391  Test Perp: 6.67186164855957\n",
      "Epoch 3000 --- Train Perp: 5.766582489013672  Test Perp: 6.589973449707031\n",
      "Epoch 3100 --- Train Perp: 5.683067321777344  Test Perp: 6.572364330291748\n",
      "Epoch 3200 --- Train Perp: 5.670646667480469  Test Perp: 6.484847545623779\n",
      "Epoch 3300 --- Train Perp: 5.583474159240723  Test Perp: 6.543373107910156\n",
      "Epoch 3400 --- Train Perp: 5.6054887771606445  Test Perp: 6.530683994293213\n",
      "Epoch 3500 --- Train Perp: 5.576643943786621  Test Perp: 6.431475639343262\n",
      "Epoch 3600 --- Train Perp: 5.55242395401001  Test Perp: 6.529257774353027\n",
      "Epoch 3700 --- Train Perp: 5.50276517868042  Test Perp: 6.403440952301025\n",
      "Epoch 3800 --- Train Perp: 5.517085552215576  Test Perp: 6.340120792388916\n",
      "Epoch 3900 --- Train Perp: 5.435598850250244  Test Perp: 6.2576003074646\n",
      "Epoch 4000 --- Train Perp: 5.387420177459717  Test Perp: 6.210463523864746\n",
      "Epoch 4100 --- Train Perp: 5.393703460693359  Test Perp: 6.292214393615723\n",
      "Epoch 4200 --- Train Perp: 5.344047546386719  Test Perp: 6.273039817810059\n",
      "Epoch 4300 --- Train Perp: 5.346268653869629  Test Perp: 6.210695266723633\n",
      "Epoch 4400 --- Train Perp: 5.253614902496338  Test Perp: 6.216073989868164\n",
      "Epoch 4500 --- Train Perp: 5.284797191619873  Test Perp: 6.2684125900268555\n",
      "Epoch 4600 --- Train Perp: 5.24763822555542  Test Perp: 6.192677974700928\n",
      "Epoch 4700 --- Train Perp: 5.268322944641113  Test Perp: 6.327769756317139\n",
      "Epoch 4800 --- Train Perp: 5.242857933044434  Test Perp: 6.140303611755371\n",
      "Epoch 4900 --- Train Perp: 5.166266441345215  Test Perp: 6.112650394439697\n",
      "Number of Layers: 6\n",
      "Epoch 0 --- Train Perp: 57.1407470703125  Test Perp: 57.7691650390625\n",
      "Epoch 100 --- Train Perp: 14.076549530029297  Test Perp: 14.282295227050781\n",
      "Epoch 200 --- Train Perp: 12.336846351623535  Test Perp: 12.584779739379883\n",
      "Epoch 300 --- Train Perp: 11.117805480957031  Test Perp: 11.18266487121582\n",
      "Epoch 400 --- Train Perp: 10.562085151672363  Test Perp: 10.582562446594238\n",
      "Epoch 500 --- Train Perp: 9.928434371948242  Test Perp: 10.073079109191895\n",
      "Epoch 600 --- Train Perp: 9.318471908569336  Test Perp: 9.400958061218262\n",
      "Epoch 700 --- Train Perp: 8.88178825378418  Test Perp: 9.2367582321167\n",
      "Epoch 800 --- Train Perp: 8.544432640075684  Test Perp: 8.808159828186035\n",
      "Epoch 900 --- Train Perp: 8.154260635375977  Test Perp: 8.552955627441406\n",
      "Epoch 1000 --- Train Perp: 7.905206203460693  Test Perp: 8.276314735412598\n",
      "Epoch 1100 --- Train Perp: 7.574150085449219  Test Perp: 8.084565162658691\n",
      "Epoch 1200 --- Train Perp: 7.431869029998779  Test Perp: 7.959954738616943\n",
      "Epoch 1300 --- Train Perp: 7.233989238739014  Test Perp: 7.901916027069092\n",
      "Epoch 1400 --- Train Perp: 7.007028579711914  Test Perp: 7.559955596923828\n",
      "Epoch 1500 --- Train Perp: 6.884907245635986  Test Perp: 7.577367305755615\n",
      "Epoch 1600 --- Train Perp: 6.859104633331299  Test Perp: 7.440621852874756\n",
      "Epoch 1700 --- Train Perp: 6.664443492889404  Test Perp: 7.425174236297607\n",
      "Epoch 1800 --- Train Perp: 6.588590145111084  Test Perp: 7.233083724975586\n",
      "Epoch 1900 --- Train Perp: 6.454014301300049  Test Perp: 7.198014259338379\n",
      "Epoch 2000 --- Train Perp: 6.2908244132995605  Test Perp: 7.134547233581543\n",
      "Epoch 2100 --- Train Perp: 6.232407569885254  Test Perp: 7.123890399932861\n",
      "Epoch 2200 --- Train Perp: 6.211516380310059  Test Perp: 7.00585412979126\n",
      "Epoch 2300 --- Train Perp: 6.124101161956787  Test Perp: 6.83456563949585\n",
      "Epoch 2400 --- Train Perp: 6.041421890258789  Test Perp: 6.9341888427734375\n",
      "Epoch 2500 --- Train Perp: 5.8840837478637695  Test Perp: 6.725855350494385\n",
      "Epoch 2600 --- Train Perp: 5.9279890060424805  Test Perp: 6.761299133300781\n",
      "Epoch 2700 --- Train Perp: 5.812873840332031  Test Perp: 6.63484001159668\n",
      "Epoch 2800 --- Train Perp: 5.804350852966309  Test Perp: 6.639675140380859\n",
      "Epoch 2900 --- Train Perp: 5.725232124328613  Test Perp: 6.621963024139404\n",
      "Epoch 3000 --- Train Perp: 5.658923625946045  Test Perp: 6.563601493835449\n",
      "Epoch 3100 --- Train Perp: 5.684294700622559  Test Perp: 6.395493984222412\n",
      "Epoch 3200 --- Train Perp: 5.595730781555176  Test Perp: 6.459945201873779\n",
      "Epoch 3300 --- Train Perp: 5.58756160736084  Test Perp: 6.50610876083374\n",
      "Epoch 3400 --- Train Perp: 5.443187236785889  Test Perp: 6.385011196136475\n",
      "Epoch 3500 --- Train Perp: 5.472522735595703  Test Perp: 6.4230055809021\n",
      "Epoch 3600 --- Train Perp: 5.478725910186768  Test Perp: 6.357879161834717\n",
      "Epoch 3700 --- Train Perp: 5.405990123748779  Test Perp: 6.3099493980407715\n",
      "Epoch 3800 --- Train Perp: 5.414539813995361  Test Perp: 6.359522342681885\n",
      "Epoch 3900 --- Train Perp: 5.341894149780273  Test Perp: 6.293862342834473\n",
      "Epoch 4000 --- Train Perp: 5.411255359649658  Test Perp: 6.323853015899658\n",
      "Epoch 4100 --- Train Perp: 5.288541316986084  Test Perp: 6.225681304931641\n",
      "Epoch 4200 --- Train Perp: 5.276479721069336  Test Perp: 6.175309658050537\n",
      "Epoch 4300 --- Train Perp: 5.258493900299072  Test Perp: 6.157350063323975\n",
      "Epoch 4400 --- Train Perp: 5.196770668029785  Test Perp: 6.11549186706543\n",
      "Epoch 4500 --- Train Perp: 5.221604347229004  Test Perp: 6.1475300788879395\n",
      "Epoch 4600 --- Train Perp: 5.201578617095947  Test Perp: 6.1073455810546875\n",
      "Epoch 4700 --- Train Perp: 5.140805244445801  Test Perp: 6.12062931060791\n",
      "Epoch 4800 --- Train Perp: 5.1776533126831055  Test Perp: 6.0157012939453125\n",
      "Epoch 4900 --- Train Perp: 5.09923791885376  Test Perp: 6.045420169830322\n",
      "Number of Layers: 8\n",
      "Epoch 0 --- Train Perp: 57.15793991088867  Test Perp: 57.60090637207031\n",
      "Epoch 100 --- Train Perp: 13.901959419250488  Test Perp: 13.710770606994629\n",
      "Epoch 200 --- Train Perp: 12.066749572753906  Test Perp: 12.072078704833984\n",
      "Epoch 300 --- Train Perp: 10.979764938354492  Test Perp: 11.008745193481445\n",
      "Epoch 400 --- Train Perp: 10.300392150878906  Test Perp: 10.221932411193848\n",
      "Epoch 500 --- Train Perp: 9.625221252441406  Test Perp: 9.752045631408691\n",
      "Epoch 600 --- Train Perp: 9.141128540039062  Test Perp: 9.322334289550781\n",
      "Epoch 700 --- Train Perp: 8.783147811889648  Test Perp: 8.976937294006348\n",
      "Epoch 800 --- Train Perp: 8.360631942749023  Test Perp: 8.624119758605957\n",
      "Epoch 900 --- Train Perp: 8.06513500213623  Test Perp: 8.48891544342041\n",
      "Epoch 1000 --- Train Perp: 7.7030229568481445  Test Perp: 8.178563117980957\n",
      "Epoch 1100 --- Train Perp: 7.550656795501709  Test Perp: 7.988282203674316\n",
      "Epoch 1200 --- Train Perp: 7.290389060974121  Test Perp: 7.819727420806885\n",
      "Epoch 1300 --- Train Perp: 7.0995378494262695  Test Perp: 7.6315388679504395\n",
      "Epoch 1400 --- Train Perp: 6.922231197357178  Test Perp: 7.543398380279541\n",
      "Epoch 1500 --- Train Perp: 6.799095153808594  Test Perp: 7.358243465423584\n",
      "Epoch 1600 --- Train Perp: 6.645611763000488  Test Perp: 7.235358715057373\n",
      "Epoch 1700 --- Train Perp: 6.542775630950928  Test Perp: 7.213982582092285\n",
      "Epoch 1800 --- Train Perp: 6.354478359222412  Test Perp: 7.011874198913574\n",
      "Epoch 1900 --- Train Perp: 6.264719009399414  Test Perp: 6.994429111480713\n",
      "Epoch 2000 --- Train Perp: 6.095600128173828  Test Perp: 6.811107158660889\n",
      "Epoch 2100 --- Train Perp: 6.196163177490234  Test Perp: 6.9425950050354\n",
      "Epoch 2200 --- Train Perp: 6.004449367523193  Test Perp: 6.69711446762085\n",
      "Epoch 2300 --- Train Perp: 5.957270622253418  Test Perp: 6.900439262390137\n",
      "Epoch 2400 --- Train Perp: 5.887825012207031  Test Perp: 6.686182022094727\n",
      "Epoch 2500 --- Train Perp: 5.8101019859313965  Test Perp: 6.6756134033203125\n",
      "Epoch 2600 --- Train Perp: 5.779932022094727  Test Perp: 6.516626834869385\n",
      "Epoch 2700 --- Train Perp: 5.655529499053955  Test Perp: 6.575327396392822\n",
      "Epoch 2800 --- Train Perp: 5.681305408477783  Test Perp: 6.587491512298584\n",
      "Epoch 2900 --- Train Perp: 5.642127513885498  Test Perp: 6.461538791656494\n",
      "Epoch 3000 --- Train Perp: 5.5650129318237305  Test Perp: 6.3950676918029785\n",
      "Epoch 3100 --- Train Perp: 5.427882194519043  Test Perp: 6.313998222351074\n",
      "Epoch 3200 --- Train Perp: 5.388686656951904  Test Perp: 6.37080192565918\n",
      "Epoch 3300 --- Train Perp: 5.376599311828613  Test Perp: 6.3806352615356445\n",
      "Epoch 3400 --- Train Perp: 5.403779983520508  Test Perp: 6.257448673248291\n",
      "Epoch 3500 --- Train Perp: 5.408468723297119  Test Perp: 6.228776454925537\n",
      "Epoch 3600 --- Train Perp: 5.351105690002441  Test Perp: 6.2046685218811035\n",
      "Epoch 3700 --- Train Perp: 5.2634124755859375  Test Perp: 6.136177062988281\n",
      "Epoch 3800 --- Train Perp: 5.2249436378479  Test Perp: 6.205983638763428\n",
      "Epoch 3900 --- Train Perp: 5.294772148132324  Test Perp: 6.156801223754883\n",
      "Epoch 4000 --- Train Perp: 5.142838478088379  Test Perp: 6.198951244354248\n",
      "Epoch 4100 --- Train Perp: 5.196242332458496  Test Perp: 6.097767353057861\n",
      "Epoch 4200 --- Train Perp: 5.117753028869629  Test Perp: 6.0402512550354\n",
      "Epoch 4300 --- Train Perp: 5.130209445953369  Test Perp: 5.9956817626953125\n",
      "Epoch 4400 --- Train Perp: 5.126286029815674  Test Perp: 6.099870204925537\n",
      "Epoch 4500 --- Train Perp: 5.113502025604248  Test Perp: 6.122107028961182\n",
      "Epoch 4600 --- Train Perp: 5.029573917388916  Test Perp: 5.990104675292969\n",
      "Epoch 4700 --- Train Perp: 5.07002592086792  Test Perp: 6.010334491729736\n",
      "Epoch 4800 --- Train Perp: 5.0222907066345215  Test Perp: 6.015813827514648\n",
      "Epoch 4900 --- Train Perp: 5.005112171173096  Test Perp: 5.913806915283203\n",
      "Number of Layers: 10\n",
      "Epoch 0 --- Train Perp: 56.03116226196289  Test Perp: 55.87491989135742\n",
      "Epoch 100 --- Train Perp: 13.774843215942383  Test Perp: 13.889982223510742\n",
      "Epoch 200 --- Train Perp: 11.915839195251465  Test Perp: 11.829947471618652\n",
      "Epoch 300 --- Train Perp: 10.80415153503418  Test Perp: 10.922739028930664\n",
      "Epoch 400 --- Train Perp: 10.184173583984375  Test Perp: 10.303019523620605\n",
      "Epoch 500 --- Train Perp: 9.602877616882324  Test Perp: 9.726391792297363\n",
      "Epoch 600 --- Train Perp: 9.091886520385742  Test Perp: 9.243799209594727\n",
      "Epoch 700 --- Train Perp: 8.75465202331543  Test Perp: 9.008164405822754\n",
      "Epoch 800 --- Train Perp: 8.288107872009277  Test Perp: 8.54625129699707\n",
      "Epoch 900 --- Train Perp: 7.955795764923096  Test Perp: 8.252398490905762\n",
      "Epoch 1000 --- Train Perp: 7.595057964324951  Test Perp: 8.001594543457031\n",
      "Epoch 1100 --- Train Perp: 7.398960113525391  Test Perp: 7.881274223327637\n",
      "Epoch 1200 --- Train Perp: 7.223559379577637  Test Perp: 7.768193244934082\n",
      "Epoch 1300 --- Train Perp: 6.967103958129883  Test Perp: 7.57846212387085\n",
      "Epoch 1400 --- Train Perp: 6.848993301391602  Test Perp: 7.483424663543701\n",
      "Epoch 1500 --- Train Perp: 6.691795825958252  Test Perp: 7.451435089111328\n",
      "Epoch 1600 --- Train Perp: 6.537111759185791  Test Perp: 7.238915920257568\n",
      "Epoch 1700 --- Train Perp: 6.477217674255371  Test Perp: 7.253159046173096\n",
      "Epoch 1800 --- Train Perp: 6.322394847869873  Test Perp: 6.993437767028809\n",
      "Epoch 1900 --- Train Perp: 6.248168468475342  Test Perp: 7.024805545806885\n",
      "Epoch 2000 --- Train Perp: 6.155976295471191  Test Perp: 6.908811569213867\n",
      "Epoch 2100 --- Train Perp: 5.989165306091309  Test Perp: 6.898439884185791\n",
      "Epoch 2200 --- Train Perp: 5.935509204864502  Test Perp: 6.832814693450928\n",
      "Epoch 2300 --- Train Perp: 5.836270332336426  Test Perp: 6.74327278137207\n",
      "Epoch 2400 --- Train Perp: 5.826322078704834  Test Perp: 6.709621429443359\n",
      "Epoch 2500 --- Train Perp: 5.715613842010498  Test Perp: 6.6504740715026855\n",
      "Epoch 2600 --- Train Perp: 5.6900739669799805  Test Perp: 6.715642929077148\n",
      "Epoch 2700 --- Train Perp: 5.62729549407959  Test Perp: 6.5629143714904785\n",
      "Epoch 2800 --- Train Perp: 5.662295341491699  Test Perp: 6.483513355255127\n",
      "Epoch 2900 --- Train Perp: 5.533565521240234  Test Perp: 6.360790252685547\n",
      "Epoch 3000 --- Train Perp: 5.430428981781006  Test Perp: 6.401205539703369\n",
      "Epoch 3100 --- Train Perp: 5.443902969360352  Test Perp: 6.343123435974121\n",
      "Epoch 3200 --- Train Perp: 5.428902626037598  Test Perp: 6.353745460510254\n",
      "Epoch 3300 --- Train Perp: 5.343721389770508  Test Perp: 6.242519378662109\n",
      "Epoch 3400 --- Train Perp: 5.276627063751221  Test Perp: 6.227121353149414\n",
      "Epoch 3500 --- Train Perp: 5.330493450164795  Test Perp: 6.149962425231934\n",
      "Epoch 3600 --- Train Perp: 5.246528148651123  Test Perp: 6.293123245239258\n",
      "Epoch 3700 --- Train Perp: 5.313950061798096  Test Perp: 6.0895538330078125\n",
      "Epoch 3800 --- Train Perp: 5.296028137207031  Test Perp: 6.107209205627441\n",
      "Epoch 3900 --- Train Perp: 5.2208333015441895  Test Perp: 6.098440647125244\n",
      "Epoch 4000 --- Train Perp: 5.146753787994385  Test Perp: 6.019758701324463\n",
      "Epoch 4100 --- Train Perp: 5.119976997375488  Test Perp: 6.017735958099365\n",
      "Epoch 4200 --- Train Perp: 5.1378679275512695  Test Perp: 6.011068820953369\n",
      "Epoch 4300 --- Train Perp: 5.087639808654785  Test Perp: 5.890439987182617\n",
      "Epoch 4400 --- Train Perp: 5.10098934173584  Test Perp: 5.93394136428833\n",
      "Epoch 4500 --- Train Perp: 5.030614852905273  Test Perp: 5.923624515533447\n",
      "Epoch 4600 --- Train Perp: 5.032931804656982  Test Perp: 5.9900221824646\n",
      "Epoch 4700 --- Train Perp: 4.9488396644592285  Test Perp: 5.906566143035889\n",
      "Epoch 4800 --- Train Perp: 4.980459690093994  Test Perp: 5.816715240478516\n",
      "Epoch 4900 --- Train Perp: 4.951154708862305  Test Perp: 5.919734477996826\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2000x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "num_layers = [4, 6, 8, 10]\n",
    "\n",
    "fig, axs =plt.subplots(1, 2, figsize=(20,10))\n",
    "\n",
    "axs[0].set_title(\"Training Perplexity\")\n",
    "axs[0].set_xlabel(\"Epochs\")\n",
    "axs[0].set_ylabel(\"Perplexity\")\n",
    "\n",
    "axs[1].set_title(\"Testing Perplexity\")\n",
    "axs[1].set_xlabel(\"Epochs\")\n",
    "axs[1].set_ylabel(\"Perplexity\")\n",
    "\n",
    "for layer_size in num_layers:\n",
    "    n_layer = layer_size\n",
    "    print(f\"Number of Layers: {n_layer}\")\n",
    "    ep, train, val = train_loop()\n",
    "    axs[0].plot(ep, train, label=f\"{n_layer} Layers\")\n",
    "    axs[1].plot(ep, val, label=f\"{n_layer} Layers\")\n",
    "\n",
    "    \n",
    "plt.legend()\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bonus 1: output some generated text from each model you trained. Did the output make more sense with some hyperparameters than others? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bonus 2: We saw a cool visualization of attention mechanisms with BertViz. Take a more complicated model than GPT2 such as \"meta-llama/Llama-2-7b-chat-hf\" and see how the attention mechanisms are different "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nDXLTusqxXHf"
   },
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some recommendations for further reading and additional code for review.\n",
    "\n",
    "* \"The Illustrated Transformer\" by Jay Alammar\n",
    "* \"Visualizing A Neural Machine Translation Model (Mechanics of Seq2seq Models With Attention)\"\n",
    "* \"The Illustrated GPT-2 (Visualizing Transformer Language Models)\"\n",
    "* \"A gentle introduction to positional encoding\"\n",
    "* \"LLM Tutorial Workshop (Argonne National Laboratory)\"\n",
    "* \"LLM Tutorial Workshop Part 2 (Argonne National Laboratory)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "datascience/conda-2023-01-10",
   "language": "python",
   "name": "conda-2023-01-10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
